{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "API_KEY = []\n",
    "API_KEY.append(os.getenv(\"API_GPT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"kokujin/prompts_1\"\n",
    "model_name = \"GPT4-o-mini\"\n",
    "output_dir = f\"./results/{model_name}/\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {API_KEY[0]}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "opt = model_name\n",
    "dic = {opt: []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "log_filename = f\"logsgpt.txt\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Example log messages\n",
    "logging.info(\"Started processing the dataset.\")\n",
    "logging.info(f\"Dataset name: {dataset_name}\")\n",
    "logging.info(f\"Model name: {model_name}\")\n",
    "logging.info(\"Finished processing the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2399it [3:37:17,  5.43s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "opt_ = 0\n",
    "for i, prompt in tqdm(enumerate(test)):\n",
    "    \n",
    "    url = f'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    tmp = {\n",
    "        \"Prompt\": \"\",\n",
    "        \"Original\": \"\",\n",
    "        \"Prediction\": \"\"\n",
    "    }\n",
    "    resp = prompt[\"Text\"].split('### Output: ')\n",
    "    prompt = resp[0]\n",
    "    payload = {\"model\": \"gpt-4o-mini\",\"messages\": [{\"role\": \"system\", \"content\": prompt}]}\n",
    "    #print(payload)\n",
    "\n",
    "    res = requests.post(url, json=payload, headers=headers)\n",
    "    logging.info(f\"Prompt: {res}\")\n",
    "    resp_ = json.loads(res.text)\n",
    "    logging.info(f\"Prompt: {resp_}\")\n",
    "    #print(resp_['candidates'][0]['content']['parts'][0]['text'])\n",
    "    result = resp_['choices'][0]['message']['content']\n",
    "    tmp[\"Prompt\"] = prompt\n",
    "    tmp[\"Original\"] = resp[1]\n",
    "    tmp[\"Prediction\"] = result\n",
    "    dic[opt].append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Prompt\": [],\n",
    "    \"Original\": [],\n",
    "    \"Prediction\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(val):\n",
    "    val = val.replace(\"'\", '\"')\n",
    "    #    val = '\"' + val + '\"'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 [2, 9, 10, 21, 22, 35, 43, 64, 66, 75, 96, 107, 124, 150, 167, 194, 205, 228, 248, 250, 278, 279, 282, 304, 330, 339, 357, 360, 393, 405, 423, 444, 454, 462, 465, 470, 473, 479, 499, 534, 561, 585, 592, 599, 621, 633, 639, 648, 677, 693, 695, 707, 727, 729, 731, 776, 804, 844, 852, 859, 899, 903, 930, 946, 989, 997, 1038, 1043, 1070, 1084, 1117, 1160, 1164, 1167, 1205, 1212, 1214, 1229, 1252, 1282, 1309, 1335, 1352, 1370, 1382, 1402, 1431, 1441, 1450, 1456, 1466, 1481, 1487, 1494, 1508, 1520, 1525, 1528, 1530, 1539, 1543, 1550, 1568, 1577, 1580, 1584, 1610, 1619, 1632, 1635, 1636, 1659, 1660, 1661, 1686, 1698, 1782, 1819, 1836, 1860, 1862, 1868, 1893, 1917, 1921, 1934, 1959, 1966, 1984, 1991, 1998, 1999, 2010, 2011, 2058, 2079, 2081, 2092, 2094, 2102, 2114, 2151, 2183, 2194, 2227, 2263, 2265, 2308, 2324, 2329, 2345, 2346, 2348, 2352, 2379, 2382, 2384, 2389]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ommited = []\n",
    "a = []\n",
    "for i, t in enumerate(dic[opt]):\n",
    "    try:\n",
    "        val_p = t[\"Prediction\"]\n",
    "\n",
    "        val_p = json.loads(\"}\".join(('{' + \"{\".join(val_p.split('{')[1:])).split('}')[:-1]) + '}')\n",
    "        \n",
    "        #print(val_p, '\\n aca termina la review')\n",
    "        #val_p = format(val_p)\n",
    "        #val_p = val_p + \"\\\"}\" if \"\\\"}\" not in val_p else val_p\n",
    "\n",
    "        val = t[\"Original\"]\n",
    "        val = format(val)\n",
    "        val = json.loads(val)\n",
    "        #print(val, '\\n aca termina la review')\n",
    "        results[\"Prediction\"].append(val_p)\n",
    "        results[\"Original\"].append(val)\n",
    "        results[\"Prompt\"].append(t[\"Prompt\"])\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        ommited.append(i)\n",
    "        #print(e)\n",
    "        a.append(t[\"Prediction\"])\n",
    "\n",
    "print(len(ommited), ommited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241\n"
     ]
    }
   ],
   "source": [
    "print(len(results['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Outputs/{model_name}/{model_name}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
