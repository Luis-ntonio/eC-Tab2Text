{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./Llama-2-7b-hf-luis\"\n",
    "\n",
    "dataset_name = \"kokujin/prompts_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset(dataset_name, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_name.split(\"./\")[1]\n",
    "dic = {opt: []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name + \"_tokenizer\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "for prompt in tqdm(test):\n",
    "    tmp = {\n",
    "        \"Prompt\": \"\",\n",
    "        \"Original\": \"\",\n",
    "        \"Prediction\": \"\"\n",
    "    }\n",
    "    resp = prompt[\"Text\"].split('### Output: ')\n",
    "    prompt = resp[0]\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=5000)\n",
    "    result = pipe(f\"{prompt}'### Output':\")\n",
    "    result = result[0]['generated_text']\n",
    "    tmp[\"Prompt\"] = prompt\n",
    "    tmp[\"Original\"] = resp[1]\n",
    "    tmp[\"Prediction\"] = result\n",
    "    dic[opt].append(tmp)\n",
    "    \n",
    "del model\n",
    "del tokenizer\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Prompt\": [],\n",
    "    \"Original\": [],\n",
    "    \"Prediction\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(val):\n",
    "    val = val.replace(\"':\", \"\\\":\")\n",
    "    val = val.replace(\"{'\", \"{\\\"\")\n",
    "    val = val.replace(\"',\", \"\\\",\")\n",
    "    val = val.replace(\"'}\", \"\\\"}\")\n",
    "    val = val.replace(\": '\", \": \\\"\")\n",
    "    val = val.replace(\", '\", \", \\\"\")\n",
    "    val = val.replace(\"}}\", \"}\")\n",
    "    val = val.replace(\"\\n}\", \"\")\n",
    "    val = val.replace(\"\\n\\n\", \"\\\",\\\"\")\n",
    "    val = val.replace(\"\\n\", \"\")\n",
    "    val = val.replace(\"\\\"t\", \"'t\")\n",
    "    val = val.replace(\"\\\"s\", \"'s\")\n",
    "    val = val.replace(\"\\\\\", \"/\")\n",
    "    val = re.sub(\"\\d+\\\" \", \"d'\", val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ommited = []\n",
    "a = []\n",
    "for i, t in enumerate(dic[opt]):\n",
    "    try:\n",
    "        val_p = t[\"Prediction\"].split(\"'### Output': \")[1].replace(\"\\\"\", \"'\").split(\"### Keys:\")[0]\n",
    "        if \"llama\" in model_name.lower():\n",
    "            if len(val_p.split(\"### Output: \")) > 1:\n",
    "                val_p = val_p.split(\"### Output: \")[1]\n",
    "        else:\n",
    "             val_p = val_p.split(\"### Output: \")\n",
    "        val_p = \"{\\\"Overview\\\": \" + val_p if \"{\\\"\" not in val_p and \"{'\" not in val_p else val_p        \n",
    "        val_p = format(val_p)\n",
    "        val_p = val_p + \"\\\"}\" if \"\\\"}\" not in val_p else val_p\n",
    "\n",
    "        val = t[\"Original\"].replace(\"\\\"\", \"'\")\n",
    "        val = format(val)\n",
    "        print(val_p)\n",
    "        results[\"Prediction\"].append(json.loads(val_p))\n",
    "        results[\"Original\"].append(json.loads(val))\n",
    "        results[\"Prompt\"].append(t[\"Prompt\"])\n",
    "\n",
    "    except:\n",
    "        ommited.append(i)\n",
    "        a.append(val_p)\n",
    "\n",
    "print(len(ommited), ommited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 6, 10, 11, 13, 18, 21, 22, 25, 26, 27, 32, 33, 36, 37, 38, 39, 40, 44, 47, 48, 54, 55, 56, 57, 58, 61, 63, 64, 65, 66, 67, 68, 69, 80, 82, 84, 86, 89, 90, 91, 98, 101, 103, 105, 106, 107, 108, 109, 111, 112, 116, 118, 119, 120, 121, 123, 126, 127, 129, 133, 134, 139, 140, 143, 144, 145, 146, 149, 150, 151, 152, 154, 155, 157, 158, 159, 161, 162, 163, 164, 167, 168, 171, 173, 174, 181, 183, 187, 188, 189, 190, 192, 193, 195, 198, 201, 202, 203, 204, 206, 207, 208, 210, 215, 216, 217, 218, 219, 221, 224, 225, 228, 229, 231, 232, 233, 235, 236, 238, 239, 240, 243, 245, 246, 248, 250, 251, 254, 256, 259, 260, 261, 263, 265, 267, 268, 270, 271, 273, 274, 275, 276, 278, 280, 281, 282, 284, 285, 287, 288, 289, 290, 292, 294, 295, 296, 298, 299, 301, 302, 304, 306, 307, 309, 310, 311, 312, 314, 315, 316, 317, 321, 322, 323, 329, 330, 331, 332, 335, 336, 337, 339, 342, 343, 345, 347, 350, 351, 353, 355, 356, 357, 358, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 374, 376, 377, 378, 379, 380, 383, 386, 390, 392, 394, 395, 396, 397, 399, 400, 402, 404, 405, 406, 409, 410, 412, 413, 414, 416, 418, 419, 421, 423, 424, 425, 428, 429, 431, 432, 433, 434, 436, 437, 439, 441, 442, 443, 445, 446, 447, 448, 449, 451, 456, 457, 458, 459, 462, 464, 465, 468, 469, 470, 471, 472, 473, 474, 475, 477, 479, 481, 482, 483, 484, 487, 489, 492, 499, 500, 501, 502, 504, 508, 510, 511, 513, 517, 519, 523, 525, 527, 529, 530, 531, 532, 534, 535, 537, 538, 541, 542, 543, 544, 545, 551, 552, 553, 554, 555, 557, 559, 560, 561, 562, 564, 565, 568, 569, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 586, 587, 588, 589, 591, 592, 593, 595, 596, 597, 598, 601, 603, 604, 605, 608, 609, 610, 612, 614, 615, 616, 617, 620, 621, 622, 625, 626, 627, 628, 630, 631, 633, 634, 635, 636, 637, 638, 640, 642, 643, 644, 647, 649, 650, 651, 656, 657, 659, 660, 661, 663, 665, 667, 668, 672, 673, 676, 677, 678, 679, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 693, 696, 701, 702, 703, 704, 705, 707, 708, 709, 710, 711, 713, 715, 716, 717, 719, 721, 727, 730, 731, 732, 734, 736, 738, 740, 741, 743, 747, 749, 750, 752, 754, 756, 757, 758, 760, 767, 769, 772, 774, 775, 776, 777, 778, 779, 781, 782, 784, 785, 786, 788, 789, 790, 791, 792, 794, 795, 798, 799, 800, 801, 803, 804, 805, 808, 811, 812, 818, 819, 820, 821, 822, 824, 828, 830, 832, 833, 835, 838, 840, 842, 843, 844, 849, 850, 852, 853, 855, 856, 857, 859, 860, 861, 862, 863, 865, 866, 867, 873, 874, 876, 880, 881, 883, 885, 886, 888, 889, 890, 892, 894, 895, 896, 899, 901, 903, 905, 907, 909, 910, 911, 912, 913, 914, 915, 917, 918, 919, 920, 923, 924, 927, 928, 930, 931, 932, 934, 935, 936, 938, 940, 941, 942, 945, 947, 948, 949, 950, 951, 952, 954, 956, 960, 961, 962, 963, 964, 965, 967, 968, 969, 970, 971, 975, 977, 978, 982, 983, 984, 985, 986, 987, 990, 993, 995, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1011, 1013, 1014, 1015, 1016, 1024, 1026, 1027, 1029, 1030, 1032, 1034, 1035, 1036, 1038, 1039, 1040, 1042, 1048, 1049, 1054, 1055, 1056, 1058, 1059, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1071, 1072, 1075, 1078, 1081, 1083, 1084, 1085, 1088, 1089, 1091, 1093, 1095, 1096, 1098, 1099, 1100, 1101, 1102, 1106, 1107, 1112, 1113, 1114, 1116, 1117, 1118, 1120, 1121, 1123, 1124, 1126, 1129, 1130, 1132, 1135, 1137, 1138, 1139, 1143, 1150, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1170, 1171, 1173, 1175, 1176, 1178, 1182, 1183, 1184, 1185, 1187, 1188, 1189, 1192, 1193, 1197, 1200, 1201, 1202, 1203, 1204, 1207, 1208, 1210, 1212, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1232, 1234, 1236, 1238, 1239, 1241, 1244, 1245, 1249, 1250, 1251, 1252, 1254, 1255, 1256, 1258, 1260, 1263, 1264, 1265, 1266, 1267, 1268, 1270, 1271, 1272, 1274, 1278, 1280, 1283, 1284, 1285, 1289, 1290, 1291, 1293, 1295, 1296, 1297, 1299, 1300, 1301, 1302, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1316, 1317, 1318, 1319, 1321, 1322, 1323, 1327, 1328, 1329, 1330, 1332, 1335, 1336, 1337, 1338, 1340, 1343, 1344, 1347, 1348, 1349, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1362, 1365, 1367, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1382, 1383, 1385, 1391, 1392, 1396, 1397, 1399, 1402, 1405, 1406, 1408, 1409, 1410, 1411, 1412, 1414, 1416, 1418, 1419, 1420, 1423, 1424, 1425, 1426, 1427, 1428, 1432, 1433, 1434, 1435, 1436, 1438, 1439, 1441, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1453, 1454, 1455, 1456, 1457, 1459, 1461, 1464, 1465, 1468, 1469, 1471, 1473, 1474, 1475, 1478, 1481, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1500, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1510, 1513, 1515, 1516, 1517, 1521, 1524, 1526, 1528, 1530, 1531, 1533, 1535, 1538, 1539, 1540, 1541, 1542, 1543, 1545, 1547, 1548, 1551, 1552, 1554, 1556, 1557, 1558, 1561, 1563, 1564, 1566, 1569, 1570, 1573, 1578, 1581, 1582, 1584, 1586, 1589, 1590, 1592, 1594, 1595, 1596, 1597, 1599, 1600, 1602, 1605, 1609, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1622, 1624, 1625, 1626, 1628, 1629, 1631, 1632, 1635, 1636, 1637, 1638, 1641, 1643, 1645, 1648, 1651, 1654, 1655, 1658, 1660, 1661, 1662, 1663, 1665, 1666, 1668, 1671, 1673, 1675, 1678, 1682, 1683, 1687, 1688, 1689, 1690, 1692, 1693, 1694, 1697, 1698, 1699, 1701, 1703, 1704, 1708, 1709, 1710, 1712, 1713, 1714, 1716, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1731, 1733, 1734, 1735, 1738, 1739, 1741, 1742, 1744, 1747, 1749, 1750, 1752, 1753, 1754, 1755, 1759, 1761, 1763, 1764, 1766, 1767, 1770, 1771, 1772, 1774, 1775, 1776, 1777, 1782, 1785, 1786, 1788, 1789, 1791, 1792, 1794, 1795, 1798, 1800, 1801, 1802, 1805, 1806, 1808, 1809, 1810, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1820, 1821, 1823, 1826, 1827, 1829, 1830, 1834, 1838, 1839, 1840, 1841, 1844, 1845, 1848, 1852, 1854, 1856, 1857, 1859, 1861, 1864, 1865, 1867, 1868, 1869, 1871, 1874, 1876, 1879, 1880, 1881, 1882, 1883, 1888, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1900, 1901, 1904, 1906, 1907, 1908, 1910, 1912, 1914, 1916, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1927, 1928, 1929, 1931, 1932, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1942, 1943, 1944, 1945, 1946, 1947, 1951, 1953, 1954, 1960, 1962, 1964, 1965, 1967, 1970, 1972, 1973, 1974, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1986, 1987, 1991, 1993, 1996, 1999, 2001, 2002, 2005, 2006, 2007, 2010, 2012, 2013, 2014, 2018, 2019, 2024, 2025, 2026, 2031, 2032, 2033, 2035, 2036, 2037, 2039, 2040, 2041, 2042, 2045, 2048, 2049, 2050, 2052, 2053, 2062, 2063, 2064, 2065, 2066, 2069, 2070, 2072, 2074, 2075, 2076, 2077, 2080, 2081, 2083, 2086, 2087, 2089, 2091, 2096, 2098, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2108, 2109, 2110, 2112, 2113, 2114, 2115, 2120, 2122, 2123, 2128, 2130, 2132, 2133, 2134, 2137, 2139, 2142, 2145, 2147, 2148, 2149, 2151, 2152, 2153, 2154, 2155, 2156, 2158, 2159, 2161, 2162, 2163, 2164, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2176, 2177, 2180, 2183, 2184, 2185, 2189, 2191, 2192, 2196, 2197, 2199, 2200, 2201, 2202, 2203, 2205, 2207, 2208, 2212, 2213, 2215, 2217, 2220, 2222, 2223, 2224, 2225, 2226, 2227, 2230, 2232, 2233, 2234, 2237, 2239, 2240, 2242, 2243, 2245, 2246, 2248, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2259, 2261, 2262, 2264, 2265, 2273, 2274, 2276, 2277, 2278, 2282, 2284, 2286, 2287, 2288, 2290, 2292, 2293, 2294, 2296, 2298, 2299, 2301, 2302, 2305, 2307, 2309, 2310, 2314, 2316, 2317, 2319, 2321, 2323, 2327, 2331, 2332, 2333, 2337, 2340, 2341, 2342, 2344, 2346, 2347, 2348, 2356, 2358, 2359, 2366, 2367, 2368, 2370, 2371, 2376, 2378, 2379, 2383, 2384, 2385, 2386, 2388, 2390, 2391, 2392, 2393, 2394, 2395, 2397, 2398] 1377\n"
     ]
    }
   ],
   "source": [
    "print(ommited, len(ommited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022 1022 1022\n"
     ]
    }
   ],
   "source": [
    "print(len(results[\"Original\"]),len(results[\"Prompt\"]),len(results[\"Prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Outputs/Llama-2-7b-hf/a.json', 'w') as f:\n",
    "    json.dump(a, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
