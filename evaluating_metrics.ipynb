{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Outputs/StructLm-7B/StructLm-7B.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(org, pred, metric_, value_):\n",
    "    dict_metric = {}\n",
    "    metric = evaluate.load(metric_)\n",
    "    metric_per_review = 0\n",
    "    idx = 0\n",
    "    for i in tqdm(range(len(org))):\n",
    "        review_org = org[i]\n",
    "        review_pred = pred[i]\n",
    "        try:\n",
    "            for key, val in review_org.items():\n",
    "                if key not in dict_metric:\n",
    "                    dict_metric[key] = [0, 0] \n",
    "                val_pred = [str(review_pred[key])]\n",
    "                if metric_ == 'bleu':        \n",
    "                    score = metric.compute(references=[str(val)], predictions=val_pred, max_order=2, smooth=True)[value_]\n",
    "                else:\n",
    "                    score = metric.compute(references=[str(val)], predictions=val_pred)[value_]\n",
    "                dict_metric[key][0] += score\n",
    "                dict_metric[key][1] += 1\n",
    "                idx += 1\n",
    "        except:\n",
    "            idx += 1\n",
    "    sum = 0\n",
    "    rest = 0\n",
    "    for key in dict_metric.keys():\n",
    "        if dict_metric[key][1] != 0:\n",
    "            dict_metric[key][0] = round((dict_metric[key][0]/dict_metric[key][1])*100, 2)\n",
    "        else:\n",
    "            rest += 1\n",
    "        sum += dict_metric[key][0]\n",
    "    if len(dict_metric.keys()) - rest == 0:\n",
    "\n",
    "        dict_metric[\"Total\"] = [0]\n",
    "    dict_metric[\"Total\"] = [round(sum/(len(dict_metric.keys()) - rest), 2), len(dict_metric.keys()) - rest]\n",
    "    return dict_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4978/4978 [00:20<00:00, 244.48it/s]\n",
      "100%|██████████| 4978/4978 [09:02<00:00,  9.17it/s]\n",
      "100%|██████████| 4978/4978 [08:56<00:00,  9.28it/s]\n",
      "100%|██████████| 4978/4978 [08:55<00:00,  9.29it/s]\n",
      "100%|██████████| 4978/4978 [08:54<00:00,  9.32it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab32ac8375434cb2a4dd74fb7f4a12df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/luis/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /home/luis/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /home/luis/nltk_data...\n",
      "100%|██████████| 4978/4978 [00:31<00:00, 156.66it/s]\n"
     ]
    }
   ],
   "source": [
    "Original = data['Original']\n",
    "Pred = data['Prediction']\n",
    "bleu = evaluating(Original, Pred, 'bleu', 'bleu')\n",
    "rougeL = evaluating(Original, Pred, \"rouge\", \"rougeL\")\n",
    "rouge1 = evaluating(Original, Pred, \"rouge\", \"rouge1\")\n",
    "rouge2 = evaluating(Original, Pred, \"rouge\", \"rouge2\")\n",
    "rougeLsum = evaluating(Original, Pred, \"rouge\", \"rougeLsum\")\n",
    "meteor = evaluating(Original, Pred, \"meteor\", \"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"bleu\" : bleu,\n",
    "    \"rouge1\" : rouge1,\n",
    "    \"rouge2\" : rouge2,\n",
    "    \"rougeL\" : rougeL,\n",
    "    \"rougeLsum\" : rougeLsum,\n",
    "    \"meteor\" : meteor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./metrics/StructLm-7B/StructLm-7B.json\", 'w+') as f:\n",
    "    json.dump(metrics, f, indent=4 ,ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
