{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model_name = \"TIGER-Lab/StructLM-7B\"\n",
    "#model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "dataset_name = \"yale-nlp/QTSumm\"\n",
    "\n",
    "new_model = \"StructLM-7B-luis-QTSUMM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 8-bit precision base model loading\n",
    "use_8bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_8bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = f\"./results/{model_name}/\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 2\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 1\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 3\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 500\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sequence length to use\n",
    "max_seq_length = 1000\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6035fecfbec640e38ffbb5ed243d6c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset (you can process it here)\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "# Create a new column 'prompt' in the dataset\n",
    "dataset = dataset.add_column(\"prompt\", [f\"\"\"Given following json that contains specifications of a product, generate a review of the key characteristics with json format. Follow the values on {{Keys}} to write the Output\n",
    "    ### Product: {x[\"table\"]}\n",
    "    ### Keys: {x[\"query\"]}\n",
    "    ### Output: {x[\"summary\"]}\"\"\" for x in dataset])\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_8bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_8bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_8bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fbf52d29fb4d26a49bd711b53b4bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4981 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:412: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e86b9611d24924bfc92a7eaca7a8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.379, 'grad_norm': 0.2961890697479248, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
      "{'loss': 1.4167, 'grad_norm': 0.6636962294578552, 'learning_rate': 0.0001, 'epoch': 0.03}\n",
      "{'loss': 1.0197, 'grad_norm': 0.21651805937290192, 'learning_rate': 0.00015000000000000001, 'epoch': 0.05}\n",
      "{'loss': 1.0776, 'grad_norm': 0.1863177865743637, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
      "{'loss': 0.9272, 'grad_norm': 0.097108393907547, 'learning_rate': 0.00019997025482747441, 'epoch': 0.08}\n",
      "{'loss': 1.0311, 'grad_norm': 0.17452095448970795, 'learning_rate': 0.00019988103700540344, 'epoch': 0.09}\n",
      "{'loss': 0.9086, 'grad_norm': 0.10890351235866547, 'learning_rate': 0.0001997323996097772, 'epoch': 0.11}\n",
      "{'loss': 1.0017, 'grad_norm': 0.3654226064682007, 'learning_rate': 0.00019952443106549533, 'epoch': 0.12}\n",
      "{'loss': 0.9648, 'grad_norm': 0.10100015252828598, 'learning_rate': 0.00019925725509376235, 'epoch': 0.14}\n",
      "{'loss': 0.991, 'grad_norm': 0.1506478190422058, 'learning_rate': 0.0001989310306384858, 'epoch': 0.15}\n",
      "{'loss': 0.9349, 'grad_norm': 0.11695495247840881, 'learning_rate': 0.00019854595177171968, 'epoch': 0.17}\n",
      "{'loss': 0.9823, 'grad_norm': 0.18351790308952332, 'learning_rate': 0.00019810224757821064, 'epoch': 0.18}\n",
      "{'loss': 0.9479, 'grad_norm': 0.09779483824968338, 'learning_rate': 0.00019760018201911433, 'epoch': 0.2}\n",
      "{'loss': 0.9969, 'grad_norm': 0.16228154301643372, 'learning_rate': 0.0001970400537749643, 'epoch': 0.21}\n",
      "{'loss': 0.941, 'grad_norm': 0.1045755073428154, 'learning_rate': 0.00019642219606798566, 'epoch': 0.23}\n",
      "{'loss': 0.9642, 'grad_norm': 0.1740424782037735, 'learning_rate': 0.00019574697646386027, 'epoch': 0.24}\n",
      "{'loss': 0.928, 'grad_norm': 0.14508551359176636, 'learning_rate': 0.00019501479665306047, 'epoch': 0.26}\n",
      "{'loss': 0.9982, 'grad_norm': 0.14822742342948914, 'learning_rate': 0.00019422609221188207, 'epoch': 0.27}\n",
      "{'loss': 0.9278, 'grad_norm': 0.10625546425580978, 'learning_rate': 0.0001933813323433186, 'epoch': 0.29}\n",
      "{'loss': 0.9541, 'grad_norm': 0.18999390304088593, 'learning_rate': 0.00019248101959793066, 'epoch': 0.3}\n",
      "{'loss': 0.9557, 'grad_norm': 0.10875333845615387, 'learning_rate': 0.00019152568957487708, 'epoch': 0.32}\n",
      "{'loss': 0.9875, 'grad_norm': 0.17320197820663452, 'learning_rate': 0.00019051591060328496, 'epoch': 0.33}\n",
      "{'loss': 0.8763, 'grad_norm': 0.10924995690584183, 'learning_rate': 0.0001894522834041487, 'epoch': 0.35}\n",
      "{'loss': 1.0123, 'grad_norm': 0.17118243873119354, 'learning_rate': 0.00018833544073295917, 'epoch': 0.36}\n",
      "{'loss': 0.8976, 'grad_norm': 0.1365085393190384, 'learning_rate': 0.00018716604700327514, 'epoch': 0.38}\n",
      "{'loss': 0.9742, 'grad_norm': 0.14629442989826202, 'learning_rate': 0.00018594479789146138, 'epoch': 0.39}\n",
      "{'loss': 0.9144, 'grad_norm': 0.1184087023139, 'learning_rate': 0.00018467241992282843, 'epoch': 0.41}\n",
      "{'loss': 0.9126, 'grad_norm': 0.14778879284858704, 'learning_rate': 0.0001833496700394202, 'epoch': 0.42}\n",
      "{'loss': 0.9024, 'grad_norm': 0.13982625305652618, 'learning_rate': 0.00018197733514970654, 'epoch': 0.44}\n",
      "{'loss': 0.8939, 'grad_norm': 0.19106797873973846, 'learning_rate': 0.00018055623166044854, 'epoch': 0.45}\n",
      "{'loss': 0.908, 'grad_norm': 0.1282384991645813, 'learning_rate': 0.0001790872049910155, 'epoch': 0.47}\n",
      "{'loss': 0.9319, 'grad_norm': 0.1433194875717163, 'learning_rate': 0.000177571129070442, 'epoch': 0.48}\n",
      "{'loss': 0.8449, 'grad_norm': 0.13306665420532227, 'learning_rate': 0.00017600890581752435, 'epoch': 0.5}\n",
      "{'loss': 0.9463, 'grad_norm': 0.20412631332874298, 'learning_rate': 0.0001744014646042663, 'epoch': 0.51}\n",
      "{'loss': 0.8409, 'grad_norm': 0.11858269572257996, 'learning_rate': 0.00017274976170299198, 'epoch': 0.53}\n",
      "{'loss': 0.9119, 'grad_norm': 0.1924513727426529, 'learning_rate': 0.00017105477971745666, 'epoch': 0.54}\n",
      "{'loss': 0.8816, 'grad_norm': 0.1166309118270874, 'learning_rate': 0.00016931752699829208, 'epoch': 0.56}\n",
      "{'loss': 0.9523, 'grad_norm': 0.17298103868961334, 'learning_rate': 0.00016753903704313527, 'epoch': 0.57}\n",
      "{'loss': 0.8832, 'grad_norm': 0.1646077185869217, 'learning_rate': 0.00016572036788179727, 'epoch': 0.59}\n",
      "{'loss': 0.946, 'grad_norm': 0.2023872435092926, 'learning_rate': 0.00016386260144683745, 'epoch': 0.6}\n",
      "{'loss': 0.8679, 'grad_norm': 0.1416621208190918, 'learning_rate': 0.00016196684292991826, 'epoch': 0.62}\n",
      "{'loss': 0.8826, 'grad_norm': 0.16117389500141144, 'learning_rate': 0.00016003422012432275, 'epoch': 0.63}\n",
      "{'loss': 0.8674, 'grad_norm': 0.12506458163261414, 'learning_rate': 0.0001580658827540265, 'epoch': 0.65}\n",
      "{'loss': 0.8971, 'grad_norm': 0.2026461809873581, 'learning_rate': 0.00015606300178972287, 'epoch': 0.66}\n",
      "{'loss': 0.887, 'grad_norm': 0.15363118052482605, 'learning_rate': 0.00015402676875220846, 'epoch': 0.68}\n",
      "{'loss': 0.9476, 'grad_norm': 0.2032802402973175, 'learning_rate': 0.00015195839500354335, 'epoch': 0.69}\n",
      "{'loss': 0.8052, 'grad_norm': 0.13772650063037872, 'learning_rate': 0.00014985911102640762, 'epoch': 0.71}\n",
      "{'loss': 0.9406, 'grad_norm': 0.15616199374198914, 'learning_rate': 0.00014773016569208283, 'epoch': 0.72}\n",
      "{'loss': 0.8766, 'grad_norm': 0.13323275744915009, 'learning_rate': 0.00014557282551749427, 'epoch': 0.74}\n",
      "{'loss': 0.9281, 'grad_norm': 0.1934213787317276, 'learning_rate': 0.00014338837391175582, 'epoch': 0.75}\n",
      "{'loss': 0.8373, 'grad_norm': 0.14100565016269684, 'learning_rate': 0.00014117811041266517, 'epoch': 0.77}\n",
      "{'loss': 0.9116, 'grad_norm': 0.1811005026102066, 'learning_rate': 0.00013894334991360448, 'epoch': 0.78}\n",
      "{'loss': 0.8609, 'grad_norm': 0.13991102576255798, 'learning_rate': 0.00013668542188130566, 'epoch': 0.8}\n",
      "{'loss': 0.919, 'grad_norm': 0.20529428124427795, 'learning_rate': 0.0001344056695649462, 'epoch': 0.81}\n",
      "{'loss': 0.8718, 'grad_norm': 0.13550446927547455, 'learning_rate': 0.0001321054491970454, 'epoch': 0.83}\n",
      "{'loss': 0.875, 'grad_norm': 0.18698446452617645, 'learning_rate': 0.000129786129186637, 'epoch': 0.84}\n",
      "{'loss': 0.8737, 'grad_norm': 0.12764360010623932, 'learning_rate': 0.0001274490893051981, 'epoch': 0.86}\n",
      "{'loss': 0.8983, 'grad_norm': 0.1777505725622177, 'learning_rate': 0.00012509571986581814, 'epoch': 0.87}\n",
      "{'loss': 0.8742, 'grad_norm': 0.13159339129924774, 'learning_rate': 0.00012272742089609694, 'epoch': 0.89}\n",
      "{'loss': 0.887, 'grad_norm': 0.18094375729560852, 'learning_rate': 0.0001203456013052634, 'epoch': 0.9}\n",
      "{'loss': 0.8497, 'grad_norm': 0.13028877973556519, 'learning_rate': 0.00011795167804601061, 'epoch': 0.92}\n",
      "{'loss': 0.8922, 'grad_norm': 0.19536074995994568, 'learning_rate': 0.0001155470752715458, 'epoch': 0.93}\n",
      "{'loss': 0.8672, 'grad_norm': 0.13831555843353271, 'learning_rate': 0.00011313322348835658, 'epoch': 0.95}\n",
      "{'loss': 0.8999, 'grad_norm': 0.23589330911636353, 'learning_rate': 0.00011071155870519777, 'epoch': 0.96}\n",
      "{'loss': 0.8537, 'grad_norm': 0.11648174375295639, 'learning_rate': 0.00010828352157880488, 'epoch': 0.98}\n",
      "{'loss': 0.8811, 'grad_norm': 0.21864713728427887, 'learning_rate': 0.0001058505565568424, 'epoch': 0.99}\n",
      "{'loss': 0.7987, 'grad_norm': 0.11655538529157639, 'learning_rate': 0.00010341411101859679, 'epoch': 1.01}\n",
      "{'loss': 0.8628, 'grad_norm': 0.15366236865520477, 'learning_rate': 0.00010097563441392581, 'epoch': 1.02}\n",
      "{'loss': 0.829, 'grad_norm': 0.12200002372264862, 'learning_rate': 9.853657740097558e-05, 'epoch': 1.04}\n",
      "{'loss': 0.8578, 'grad_norm': 0.16997253894805908, 'learning_rate': 9.6098390983179e-05, 'epoch': 1.05}\n",
      "{'loss': 0.7821, 'grad_norm': 0.13481763005256653, 'learning_rate': 9.366252564604913e-05, 'epoch': 1.07}\n",
      "{'loss': 0.8117, 'grad_norm': 0.14238467812538147, 'learning_rate': 9.123043049427995e-05, 'epoch': 1.08}\n",
      "{'loss': 0.8182, 'grad_norm': 0.14123357832431793, 'learning_rate': 8.880355238966923e-05, 'epoch': 1.1}\n",
      "{'loss': 0.8107, 'grad_norm': 0.17640164494514465, 'learning_rate': 8.638333509037536e-05, 'epoch': 1.11}\n",
      "{'loss': 0.8171, 'grad_norm': 0.1663886159658432, 'learning_rate': 8.39712183920207e-05, 'epoch': 1.13}\n",
      "{'loss': 0.9097, 'grad_norm': 0.16230948269367218, 'learning_rate': 8.156863727115211e-05, 'epoch': 1.14}\n",
      "{'loss': 0.8354, 'grad_norm': 0.15511223673820496, 'learning_rate': 7.91770210315685e-05, 'epoch': 1.16}\n",
      "{'loss': 0.8227, 'grad_norm': 0.18210750818252563, 'learning_rate': 7.679779245402321e-05, 'epoch': 1.17}\n",
      "{'loss': 0.8229, 'grad_norm': 0.15813834965229034, 'learning_rate': 7.443236694980649e-05, 'epoch': 1.19}\n",
      "{'loss': 0.8381, 'grad_norm': 0.21685752272605896, 'learning_rate': 7.208215171871277e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8254, 'grad_norm': 0.15697121620178223, 'learning_rate': 6.974854491189243e-05, 'epoch': 1.22}\n",
      "{'loss': 0.8422, 'grad_norm': 0.16922031342983246, 'learning_rate': 6.743293480008702e-05, 'epoch': 1.23}\n",
      "{'loss': 0.8072, 'grad_norm': 0.14199766516685486, 'learning_rate': 6.513669894774209e-05, 'epoch': 1.25}\n",
      "{'loss': 0.7935, 'grad_norm': 0.18612296879291534, 'learning_rate': 6.286120339348935e-05, 'epoch': 1.26}\n",
      "{'loss': 0.8233, 'grad_norm': 0.13075241446495056, 'learning_rate': 6.060780183748567e-05, 'epoch': 1.28}\n",
      "{'loss': 0.8147, 'grad_norm': 0.18149437010288239, 'learning_rate': 5.8377834836092136e-05, 'epoch': 1.29}\n",
      "{'loss': 0.8132, 'grad_norm': 0.1835154891014099, 'learning_rate': 5.617262900437239e-05, 'epoch': 1.31}\n",
      "{'loss': 0.8202, 'grad_norm': 0.1953057050704956, 'learning_rate': 5.399349622688479e-05, 'epoch': 1.33}\n",
      "{'loss': 0.8105, 'grad_norm': 0.14253491163253784, 'learning_rate': 5.184173287723781e-05, 'epoch': 1.34}\n",
      "{'loss': 0.8153, 'grad_norm': 0.20112018287181854, 'learning_rate': 4.9718619046872825e-05, 'epoch': 1.36}\n",
      "{'loss': 0.7961, 'grad_norm': 0.18404234945774078, 'learning_rate': 4.762541778353337e-05, 'epoch': 1.37}\n",
      "{'loss': 0.8449, 'grad_norm': 0.18910712003707886, 'learning_rate': 4.556337433987359e-05, 'epoch': 1.39}\n",
      "{'loss': 0.8409, 'grad_norm': 0.15517272055149078, 'learning_rate': 4.35337154326532e-05, 'epoch': 1.4}\n",
      "{'loss': 0.8155, 'grad_norm': 0.19545353949069977, 'learning_rate': 4.153764851295954e-05, 'epoch': 1.42}\n",
      "{'loss': 0.7745, 'grad_norm': 0.15216684341430664, 'learning_rate': 3.9576361047890554e-05, 'epoch': 1.43}\n",
      "{'loss': 0.8245, 'grad_norm': 0.2118316888809204, 'learning_rate': 3.7651019814126654e-05, 'epoch': 1.45}\n",
      "{'loss': 0.7775, 'grad_norm': 0.1459702104330063, 'learning_rate': 3.5762770203811225e-05, 'epoch': 1.46}\n",
      "{'loss': 0.8474, 'grad_norm': 0.2232191413640976, 'learning_rate': 3.3912735543152864e-05, 'epoch': 1.48}\n",
      "{'loss': 0.801, 'grad_norm': 0.14688050746917725, 'learning_rate': 3.2102016424154766e-05, 'epoch': 1.49}\n",
      "{'loss': 0.8058, 'grad_norm': 0.19938841462135315, 'learning_rate': 3.033169004986873e-05, 'epoch': 1.51}\n",
      "{'loss': 0.7847, 'grad_norm': 0.13868874311447144, 'learning_rate': 2.8602809593563364e-05, 'epoch': 1.52}\n",
      "{'loss': 0.7906, 'grad_norm': 0.16181352734565735, 'learning_rate': 2.691640357218759e-05, 'epoch': 1.54}\n",
      "{'loss': 0.7636, 'grad_norm': 0.16018016636371613, 'learning_rate': 2.5273475234502565e-05, 'epoch': 1.55}\n",
      "{'loss': 0.8252, 'grad_norm': 0.17814849317073822, 'learning_rate': 2.367500196424529e-05, 'epoch': 1.57}\n",
      "{'loss': 0.7923, 'grad_norm': 0.1486576795578003, 'learning_rate': 2.212193469867979e-05, 'epoch': 1.58}\n",
      "{'loss': 0.8027, 'grad_norm': 0.20669296383857727, 'learning_rate': 2.0615197362881234e-05, 'epoch': 1.6}\n",
      "{'loss': 0.8083, 'grad_norm': 0.15332527458667755, 'learning_rate': 1.9155686320089684e-05, 'epoch': 1.61}\n",
      "{'loss': 0.7835, 'grad_norm': 0.23270639777183533, 'learning_rate': 1.774426983846058e-05, 'epoch': 1.63}\n",
      "{'loss': 0.8086, 'grad_norm': 0.15028224885463715, 'learning_rate': 1.638178757452894e-05, 'epoch': 1.64}\n",
      "{'loss': 0.8212, 'grad_norm': 0.18271537125110626, 'learning_rate': 1.5069050073694813e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7731, 'grad_norm': 0.16216376423835754, 'learning_rate': 1.3806838288027113e-05, 'epoch': 1.67}\n",
      "{'loss': 0.8273, 'grad_norm': 0.1994326263666153, 'learning_rate': 1.259590311167238e-05, 'epoch': 1.69}\n",
      "{'loss': 0.8398, 'grad_norm': 0.17495936155319214, 'learning_rate': 1.1436964934145389e-05, 'epoch': 1.7}\n",
      "{'loss': 0.8277, 'grad_norm': 0.20191985368728638, 'learning_rate': 1.0330713211766863e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7539, 'grad_norm': 0.14184322953224182, 'learning_rate': 9.27780605750359e-06, 'epoch': 1.73}\n",
      "{'loss': 0.8014, 'grad_norm': 0.27268797159194946, 'learning_rate': 8.278869849454718e-06, 'epoch': 1.75}\n",
      "{'loss': 0.8076, 'grad_norm': 0.1434682309627533, 'learning_rate': 7.3344988582172315e-06, 'epoch': 1.76}\n",
      "{'loss': 0.8086, 'grad_norm': 0.200864776968956, 'learning_rate': 6.4452548933523815e-06, 'epoch': 1.78}\n",
      "{'loss': 0.7439, 'grad_norm': 0.15919099748134613, 'learning_rate': 5.611666969163243e-06, 'epoch': 1.79}\n",
      "{'loss': 0.8097, 'grad_norm': 0.21835172176361084, 'learning_rate': 4.834230989982213e-06, 'epoch': 1.81}\n",
      "{'loss': 0.7575, 'grad_norm': 0.16167479753494263, 'learning_rate': 4.113409455155837e-06, 'epoch': 1.82}\n",
      "{'loss': 0.8161, 'grad_norm': 0.17669419944286346, 'learning_rate': 3.449631183902413e-06, 'epoch': 1.84}\n",
      "{'loss': 0.7966, 'grad_norm': 0.15163554251194, 'learning_rate': 2.843291060205855e-06, 'epoch': 1.85}\n",
      "{'loss': 0.8047, 'grad_norm': 0.214816153049469, 'learning_rate': 2.294749797897955e-06, 'epoch': 1.87}\n",
      "{'loss': 0.8169, 'grad_norm': 0.15083792805671692, 'learning_rate': 1.8043337260684078e-06, 'epoch': 1.88}\n",
      "{'loss': 0.8301, 'grad_norm': 0.18312731385231018, 'learning_rate': 1.3723345949305245e-06, 'epoch': 1.9}\n",
      "{'loss': 0.7987, 'grad_norm': 0.18561044335365295, 'learning_rate': 9.990094022580332e-07, 'epoch': 1.91}\n",
      "{'loss': 0.8103, 'grad_norm': 0.2121542990207672, 'learning_rate': 6.845802404962243e-07, 'epoch': 1.93}\n",
      "{'loss': 0.8197, 'grad_norm': 0.15226717293262482, 'learning_rate': 4.2923416463838126e-07, 'epoch': 1.94}\n",
      "{'loss': 0.8448, 'grad_norm': 0.16625230014324188, 'learning_rate': 2.3312308094607382e-07, 'epoch': 1.96}\n",
      "{'loss': 0.7825, 'grad_norm': 0.15572890639305115, 'learning_rate': 9.636365657971214e-08, 'epoch': 1.97}\n",
      "{'loss': 0.775, 'grad_norm': 0.2140963077545166, 'learning_rate': 1.9037250192732726e-08, 'epoch': 1.99}\n",
      "{'train_runtime': 11753.4763, 'train_samples_per_second': 0.848, 'train_steps_per_second': 0.282, 'train_loss': 0.8723331979958407, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3320, training_loss=0.8723331979958407, metrics={'train_runtime': 11753.4763, 'train_samples_per_second': 0.848, 'train_steps_per_second': 0.282, 'total_flos': 2.862100968710308e+17, 'train_loss': 0.8723331979958407, 'epoch': 1.9995984742019675})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train(resume_from_checkpoint = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(\"./qtsumm/\" + new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizers/StructLM-7B-luis-QTSUMM_tokenizer/tokenizer_config.json',\n",
       " './tokenizers/StructLM-7B-luis-QTSUMM_tokenizer/special_tokens_map.json',\n",
       " './tokenizers/StructLM-7B-luis-QTSUMM_tokenizer/tokenizer.model',\n",
       " './tokenizers/StructLM-7B-luis-QTSUMM_tokenizer/added_tokens.json',\n",
       " './tokenizers/StructLM-7B-luis-QTSUMM_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./tokenizers/' + new_model + \"_tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
