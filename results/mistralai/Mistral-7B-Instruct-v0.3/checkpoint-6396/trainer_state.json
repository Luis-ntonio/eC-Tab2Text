{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9997915581031789,
  "eval_steps": 500,
  "global_step": 6396,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007816571130797291,
      "grad_norm": 0.3715257942676544,
      "learning_rate": 2.604166666666667e-05,
      "loss": 1.0361,
      "step": 25
    },
    {
      "epoch": 0.015633142261594582,
      "grad_norm": 0.9048253893852234,
      "learning_rate": 5.208333333333334e-05,
      "loss": 0.8629,
      "step": 50
    },
    {
      "epoch": 0.02344971339239187,
      "grad_norm": 0.626203715801239,
      "learning_rate": 7.8125e-05,
      "loss": 0.3976,
      "step": 75
    },
    {
      "epoch": 0.031266284523189164,
      "grad_norm": 1.2425174713134766,
      "learning_rate": 0.00010416666666666667,
      "loss": 0.272,
      "step": 100
    },
    {
      "epoch": 0.03908285565398645,
      "grad_norm": 0.34642747044563293,
      "learning_rate": 0.00013020833333333333,
      "loss": 0.204,
      "step": 125
    },
    {
      "epoch": 0.04689942678478374,
      "grad_norm": 0.9093351364135742,
      "learning_rate": 0.00015625,
      "loss": 0.1951,
      "step": 150
    },
    {
      "epoch": 0.05471599791558103,
      "grad_norm": 0.2559562921524048,
      "learning_rate": 0.00018229166666666667,
      "loss": 0.1572,
      "step": 175
    },
    {
      "epoch": 0.06253256904637833,
      "grad_norm": 0.42944344878196716,
      "learning_rate": 0.00019999917944905216,
      "loss": 0.2016,
      "step": 200
    },
    {
      "epoch": 0.07034914017717561,
      "grad_norm": 0.23466379940509796,
      "learning_rate": 0.00019998603811858571,
      "loss": 0.1573,
      "step": 225
    },
    {
      "epoch": 0.0781657113079729,
      "grad_norm": 0.3496451675891876,
      "learning_rate": 0.00019995687283209658,
      "loss": 0.1921,
      "step": 250
    },
    {
      "epoch": 0.0859822824387702,
      "grad_norm": 0.2484898716211319,
      "learning_rate": 0.00019991168826367011,
      "loss": 0.1386,
      "step": 275
    },
    {
      "epoch": 0.09379885356956748,
      "grad_norm": 0.29783809185028076,
      "learning_rate": 0.00019985049165467257,
      "loss": 0.1586,
      "step": 300
    },
    {
      "epoch": 0.10161542470036478,
      "grad_norm": 0.1712491810321808,
      "learning_rate": 0.00019977329281259108,
      "loss": 0.1272,
      "step": 325
    },
    {
      "epoch": 0.10943199583116206,
      "grad_norm": 0.3634892702102661,
      "learning_rate": 0.00019968010410946154,
      "loss": 0.1653,
      "step": 350
    },
    {
      "epoch": 0.11724856696195936,
      "grad_norm": 0.18681398034095764,
      "learning_rate": 0.00019957094047988582,
      "loss": 0.1241,
      "step": 375
    },
    {
      "epoch": 0.12506513809275666,
      "grad_norm": 0.3389054536819458,
      "learning_rate": 0.00019944581941863857,
      "loss": 0.1393,
      "step": 400
    },
    {
      "epoch": 0.13288170922355394,
      "grad_norm": 0.22925116121768951,
      "learning_rate": 0.00019930476097786327,
      "loss": 0.1172,
      "step": 425
    },
    {
      "epoch": 0.14069828035435122,
      "grad_norm": 0.4825553596019745,
      "learning_rate": 0.0001991477877638587,
      "loss": 0.1513,
      "step": 450
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 0.2592446804046631,
      "learning_rate": 0.00019897492493345598,
      "loss": 0.1237,
      "step": 475
    },
    {
      "epoch": 0.1563314226159458,
      "grad_norm": 0.2628246247768402,
      "learning_rate": 0.00019878620018998696,
      "loss": 0.1357,
      "step": 500
    },
    {
      "epoch": 0.1641479937467431,
      "grad_norm": 0.20936407148838043,
      "learning_rate": 0.00019858164377884436,
      "loss": 0.1091,
      "step": 525
    },
    {
      "epoch": 0.1719645648775404,
      "grad_norm": 0.1933692991733551,
      "learning_rate": 0.00019836128848263465,
      "loss": 0.1337,
      "step": 550
    },
    {
      "epoch": 0.17978113600833767,
      "grad_norm": 0.27440977096557617,
      "learning_rate": 0.0001981251696159241,
      "loss": 0.1028,
      "step": 575
    },
    {
      "epoch": 0.18759770713913496,
      "grad_norm": 0.27333107590675354,
      "learning_rate": 0.00019787332501957941,
      "loss": 0.1333,
      "step": 600
    },
    {
      "epoch": 0.19541427826993227,
      "grad_norm": 0.18744760751724243,
      "learning_rate": 0.0001976057950547031,
      "loss": 0.1097,
      "step": 625
    },
    {
      "epoch": 0.20323084940072955,
      "grad_norm": 0.18898768723011017,
      "learning_rate": 0.00019732262259616523,
      "loss": 0.145,
      "step": 650
    },
    {
      "epoch": 0.21104742053152684,
      "grad_norm": 0.21582496166229248,
      "learning_rate": 0.0001970238530257322,
      "loss": 0.095,
      "step": 675
    },
    {
      "epoch": 0.21886399166232412,
      "grad_norm": 0.14941897988319397,
      "learning_rate": 0.00019670953422479368,
      "loss": 0.1054,
      "step": 700
    },
    {
      "epoch": 0.2266805627931214,
      "grad_norm": 0.18502603471279144,
      "learning_rate": 0.00019637971656668918,
      "loss": 0.0847,
      "step": 725
    },
    {
      "epoch": 0.23449713392391872,
      "grad_norm": 0.3501814305782318,
      "learning_rate": 0.0001960344529086351,
      "loss": 0.12,
      "step": 750
    },
    {
      "epoch": 0.242313705054716,
      "grad_norm": 0.20063604414463043,
      "learning_rate": 0.00019567379858325356,
      "loss": 0.0965,
      "step": 775
    },
    {
      "epoch": 0.2501302761855133,
      "grad_norm": 0.30999451875686646,
      "learning_rate": 0.000195297811389705,
      "loss": 0.1151,
      "step": 800
    },
    {
      "epoch": 0.25794684731631057,
      "grad_norm": 0.22625909745693207,
      "learning_rate": 0.00019490655158442484,
      "loss": 0.0952,
      "step": 825
    },
    {
      "epoch": 0.2657634184471079,
      "grad_norm": 0.30245867371559143,
      "learning_rate": 0.00019450008187146684,
      "loss": 0.1085,
      "step": 850
    },
    {
      "epoch": 0.27357998957790514,
      "grad_norm": 0.3024768829345703,
      "learning_rate": 0.00019407846739245415,
      "loss": 0.0977,
      "step": 875
    },
    {
      "epoch": 0.28139656070870245,
      "grad_norm": 0.20998148620128632,
      "learning_rate": 0.00019364177571613926,
      "loss": 0.1109,
      "step": 900
    },
    {
      "epoch": 0.28921313183949976,
      "grad_norm": 0.17439192533493042,
      "learning_rate": 0.00019319007682757556,
      "loss": 0.0867,
      "step": 925
    },
    {
      "epoch": 0.297029702970297,
      "grad_norm": 0.2674555778503418,
      "learning_rate": 0.0001927234431169014,
      "loss": 0.0938,
      "step": 950
    },
    {
      "epoch": 0.30484627410109433,
      "grad_norm": 0.1859060376882553,
      "learning_rate": 0.00019224194936773853,
      "loss": 0.0737,
      "step": 975
    },
    {
      "epoch": 0.3126628452318916,
      "grad_norm": 0.32896485924720764,
      "learning_rate": 0.00019174567274520728,
      "loss": 0.0828,
      "step": 1000
    },
    {
      "epoch": 0.3204794163626889,
      "grad_norm": 0.15164466202259064,
      "learning_rate": 0.00019123469278355985,
      "loss": 0.0664,
      "step": 1025
    },
    {
      "epoch": 0.3282959874934862,
      "grad_norm": 0.2480175644159317,
      "learning_rate": 0.00019070909137343408,
      "loss": 0.0875,
      "step": 1050
    },
    {
      "epoch": 0.33611255862428346,
      "grad_norm": 0.2269286960363388,
      "learning_rate": 0.0001901689527487294,
      "loss": 0.0661,
      "step": 1075
    },
    {
      "epoch": 0.3439291297550808,
      "grad_norm": 0.21628433465957642,
      "learning_rate": 0.0001896143634731074,
      "loss": 0.0854,
      "step": 1100
    },
    {
      "epoch": 0.3517457008858781,
      "grad_norm": 0.27746009826660156,
      "learning_rate": 0.00018904541242611902,
      "loss": 0.0765,
      "step": 1125
    },
    {
      "epoch": 0.35956227201667534,
      "grad_norm": 0.259750097990036,
      "learning_rate": 0.00018846219078896037,
      "loss": 0.0971,
      "step": 1150
    },
    {
      "epoch": 0.36737884314747266,
      "grad_norm": 0.18180161714553833,
      "learning_rate": 0.00018786479202986006,
      "loss": 0.0724,
      "step": 1175
    },
    {
      "epoch": 0.3751954142782699,
      "grad_norm": 0.25816211104393005,
      "learning_rate": 0.0001872533118890997,
      "loss": 0.0914,
      "step": 1200
    },
    {
      "epoch": 0.3830119854090672,
      "grad_norm": 0.20802262425422668,
      "learning_rate": 0.00018662784836367028,
      "loss": 0.0683,
      "step": 1225
    },
    {
      "epoch": 0.39082855653986454,
      "grad_norm": 0.24180841445922852,
      "learning_rate": 0.00018598850169156722,
      "loss": 0.0879,
      "step": 1250
    },
    {
      "epoch": 0.3986451276706618,
      "grad_norm": 0.16083268821239471,
      "learning_rate": 0.00018533537433572581,
      "loss": 0.0677,
      "step": 1275
    },
    {
      "epoch": 0.4064616988014591,
      "grad_norm": 0.24377408623695374,
      "learning_rate": 0.00018466857096760046,
      "loss": 0.084,
      "step": 1300
    },
    {
      "epoch": 0.41427826993225636,
      "grad_norm": 0.2606008052825928,
      "learning_rate": 0.00018398819845038972,
      "loss": 0.0732,
      "step": 1325
    },
    {
      "epoch": 0.42209484106305367,
      "grad_norm": 0.43135368824005127,
      "learning_rate": 0.0001832943658219103,
      "loss": 0.0889,
      "step": 1350
    },
    {
      "epoch": 0.429911412193851,
      "grad_norm": 0.2756401002407074,
      "learning_rate": 0.00018258718427712238,
      "loss": 0.0664,
      "step": 1375
    },
    {
      "epoch": 0.43772798332464824,
      "grad_norm": 0.36994820833206177,
      "learning_rate": 0.00018186676715030924,
      "loss": 0.0808,
      "step": 1400
    },
    {
      "epoch": 0.44554455445544555,
      "grad_norm": 0.17359623312950134,
      "learning_rate": 0.0001811332298969142,
      "loss": 0.0641,
      "step": 1425
    },
    {
      "epoch": 0.4533611255862428,
      "grad_norm": 0.27655839920043945,
      "learning_rate": 0.0001803866900750376,
      "loss": 0.0933,
      "step": 1450
    },
    {
      "epoch": 0.4611776967170401,
      "grad_norm": 0.14252501726150513,
      "learning_rate": 0.0001796272673265963,
      "loss": 0.0655,
      "step": 1475
    },
    {
      "epoch": 0.46899426784783743,
      "grad_norm": 0.18642756342887878,
      "learning_rate": 0.00017885508335815014,
      "loss": 0.0717,
      "step": 1500
    },
    {
      "epoch": 0.4768108389786347,
      "grad_norm": 0.265768438577652,
      "learning_rate": 0.0001780702619213967,
      "loss": 0.0646,
      "step": 1525
    },
    {
      "epoch": 0.484627410109432,
      "grad_norm": 0.26595669984817505,
      "learning_rate": 0.0001772729287933387,
      "loss": 0.0744,
      "step": 1550
    },
    {
      "epoch": 0.4924439812402293,
      "grad_norm": 0.1489591896533966,
      "learning_rate": 0.00017646321175612668,
      "loss": 0.0661,
      "step": 1575
    },
    {
      "epoch": 0.5002605523710266,
      "grad_norm": 0.36603328585624695,
      "learning_rate": 0.00017564124057658056,
      "loss": 0.0854,
      "step": 1600
    },
    {
      "epoch": 0.5080771235018239,
      "grad_norm": 0.18838918209075928,
      "learning_rate": 0.00017480714698539266,
      "loss": 0.0533,
      "step": 1625
    },
    {
      "epoch": 0.5158936946326211,
      "grad_norm": 0.387383371591568,
      "learning_rate": 0.00017396106465601663,
      "loss": 0.0732,
      "step": 1650
    },
    {
      "epoch": 0.5237102657634184,
      "grad_norm": 0.15802884101867676,
      "learning_rate": 0.0001731031291832444,
      "loss": 0.0635,
      "step": 1675
    },
    {
      "epoch": 0.5315268368942158,
      "grad_norm": 0.2513883709907532,
      "learning_rate": 0.0001722334780614756,
      "loss": 0.0794,
      "step": 1700
    },
    {
      "epoch": 0.539343408025013,
      "grad_norm": 0.19691778719425201,
      "learning_rate": 0.00017135225066268255,
      "loss": 0.0566,
      "step": 1725
    },
    {
      "epoch": 0.5471599791558103,
      "grad_norm": 0.3959238529205322,
      "learning_rate": 0.00017045958821407405,
      "loss": 0.0823,
      "step": 1750
    },
    {
      "epoch": 0.5549765502866076,
      "grad_norm": 0.1837705373764038,
      "learning_rate": 0.00016955563377546207,
      "loss": 0.066,
      "step": 1775
    },
    {
      "epoch": 0.5627931214174049,
      "grad_norm": 0.26655009388923645,
      "learning_rate": 0.0001686405322163349,
      "loss": 0.075,
      "step": 1800
    },
    {
      "epoch": 0.5706096925482022,
      "grad_norm": 0.20359095931053162,
      "learning_rate": 0.00016771443019263983,
      "loss": 0.0505,
      "step": 1825
    },
    {
      "epoch": 0.5784262636789995,
      "grad_norm": 0.33158689737319946,
      "learning_rate": 0.00016677747612327997,
      "loss": 0.0714,
      "step": 1850
    },
    {
      "epoch": 0.5862428348097968,
      "grad_norm": 0.14876769483089447,
      "learning_rate": 0.00016582982016632818,
      "loss": 0.055,
      "step": 1875
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 0.19468384981155396,
      "learning_rate": 0.00016487161419496263,
      "loss": 0.0643,
      "step": 1900
    },
    {
      "epoch": 0.6018759770713914,
      "grad_norm": 0.24525055289268494,
      "learning_rate": 0.00016390301177312722,
      "loss": 0.0483,
      "step": 1925
    },
    {
      "epoch": 0.6096925482021887,
      "grad_norm": 0.22415503859519958,
      "learning_rate": 0.00016292416813092105,
      "loss": 0.08,
      "step": 1950
    },
    {
      "epoch": 0.6175091193329859,
      "grad_norm": 0.28034576773643494,
      "learning_rate": 0.00016193524013972114,
      "loss": 0.0612,
      "step": 1975
    },
    {
      "epoch": 0.6253256904637832,
      "grad_norm": 0.40281274914741516,
      "learning_rate": 0.00016093638628704167,
      "loss": 0.0764,
      "step": 2000
    },
    {
      "epoch": 0.6331422615945805,
      "grad_norm": 0.24748602509498596,
      "learning_rate": 0.0001599277666511347,
      "loss": 0.045,
      "step": 2025
    },
    {
      "epoch": 0.6409588327253778,
      "grad_norm": 0.28065794706344604,
      "learning_rate": 0.00015890954287533555,
      "loss": 0.0676,
      "step": 2050
    },
    {
      "epoch": 0.648775403856175,
      "grad_norm": 0.15673571825027466,
      "learning_rate": 0.00015788187814215764,
      "loss": 0.0464,
      "step": 2075
    },
    {
      "epoch": 0.6565919749869724,
      "grad_norm": 0.2873454689979553,
      "learning_rate": 0.00015684493714714047,
      "loss": 0.0736,
      "step": 2100
    },
    {
      "epoch": 0.6644085461177697,
      "grad_norm": 0.22378423810005188,
      "learning_rate": 0.00015579888607245517,
      "loss": 0.0411,
      "step": 2125
    },
    {
      "epoch": 0.6722251172485669,
      "grad_norm": 0.27076515555381775,
      "learning_rate": 0.000154743892560272,
      "loss": 0.0733,
      "step": 2150
    },
    {
      "epoch": 0.6800416883793643,
      "grad_norm": 0.1413268744945526,
      "learning_rate": 0.00015368012568589342,
      "loss": 0.0418,
      "step": 2175
    },
    {
      "epoch": 0.6878582595101616,
      "grad_norm": 0.3359984755516052,
      "learning_rate": 0.00015260775593065802,
      "loss": 0.0639,
      "step": 2200
    },
    {
      "epoch": 0.6956748306409588,
      "grad_norm": 0.17849086225032806,
      "learning_rate": 0.00015152695515461865,
      "loss": 0.0419,
      "step": 2225
    },
    {
      "epoch": 0.7034914017717562,
      "grad_norm": 0.23173880577087402,
      "learning_rate": 0.00015043789656899988,
      "loss": 0.0704,
      "step": 2250
    },
    {
      "epoch": 0.7113079729025534,
      "grad_norm": 0.1129363551735878,
      "learning_rate": 0.00014934075470843887,
      "loss": 0.0393,
      "step": 2275
    },
    {
      "epoch": 0.7191245440333507,
      "grad_norm": 0.27609822154045105,
      "learning_rate": 0.00014823570540301408,
      "loss": 0.064,
      "step": 2300
    },
    {
      "epoch": 0.7269411151641479,
      "grad_norm": 0.1481596678495407,
      "learning_rate": 0.00014712292575006633,
      "loss": 0.0464,
      "step": 2325
    },
    {
      "epoch": 0.7347576862949453,
      "grad_norm": 0.31291964650154114,
      "learning_rate": 0.00014600259408581687,
      "loss": 0.0753,
      "step": 2350
    },
    {
      "epoch": 0.7425742574257426,
      "grad_norm": 0.2423887699842453,
      "learning_rate": 0.00014487488995678708,
      "loss": 0.0419,
      "step": 2375
    },
    {
      "epoch": 0.7503908285565398,
      "grad_norm": 0.14828327298164368,
      "learning_rate": 0.00014373999409102362,
      "loss": 0.0552,
      "step": 2400
    },
    {
      "epoch": 0.7582073996873372,
      "grad_norm": 0.1671355962753296,
      "learning_rate": 0.00014259808836913492,
      "loss": 0.0404,
      "step": 2425
    },
    {
      "epoch": 0.7660239708181344,
      "grad_norm": 0.35629069805145264,
      "learning_rate": 0.00014144935579514246,
      "loss": 0.0767,
      "step": 2450
    },
    {
      "epoch": 0.7738405419489317,
      "grad_norm": 0.21464824676513672,
      "learning_rate": 0.00014029398046715223,
      "loss": 0.0449,
      "step": 2475
    },
    {
      "epoch": 0.7816571130797291,
      "grad_norm": 0.2231532335281372,
      "learning_rate": 0.00013913214754785095,
      "loss": 0.0494,
      "step": 2500
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.16294214129447937,
      "learning_rate": 0.00013796404323483132,
      "loss": 0.044,
      "step": 2525
    },
    {
      "epoch": 0.7972902553413236,
      "grad_norm": 0.1532847136259079,
      "learning_rate": 0.00013678985473075176,
      "loss": 0.0504,
      "step": 2550
    },
    {
      "epoch": 0.805106826472121,
      "grad_norm": 0.1304529458284378,
      "learning_rate": 0.00013560977021333497,
      "loss": 0.0448,
      "step": 2575
    },
    {
      "epoch": 0.8129233976029182,
      "grad_norm": 0.27236923575401306,
      "learning_rate": 0.00013442397880521008,
      "loss": 0.0653,
      "step": 2600
    },
    {
      "epoch": 0.8207399687337155,
      "grad_norm": 0.2117595672607422,
      "learning_rate": 0.0001332326705436037,
      "loss": 0.0427,
      "step": 2625
    },
    {
      "epoch": 0.8285565398645127,
      "grad_norm": 0.22144165635108948,
      "learning_rate": 0.00013203603634988386,
      "loss": 0.0596,
      "step": 2650
    },
    {
      "epoch": 0.8363731109953101,
      "grad_norm": 0.173106849193573,
      "learning_rate": 0.000130834267998963,
      "loss": 0.0489,
      "step": 2675
    },
    {
      "epoch": 0.8441896821261073,
      "grad_norm": 0.3698328733444214,
      "learning_rate": 0.00012962755808856342,
      "loss": 0.0532,
      "step": 2700
    },
    {
      "epoch": 0.8520062532569046,
      "grad_norm": 0.17032617330551147,
      "learning_rate": 0.00012841610000835125,
      "loss": 0.0402,
      "step": 2725
    },
    {
      "epoch": 0.859822824387702,
      "grad_norm": 0.27817198634147644,
      "learning_rate": 0.00012720008790894366,
      "loss": 0.0558,
      "step": 2750
    },
    {
      "epoch": 0.8676393955184992,
      "grad_norm": 0.21134985983371735,
      "learning_rate": 0.00012597971667079361,
      "loss": 0.0378,
      "step": 2775
    },
    {
      "epoch": 0.8754559666492965,
      "grad_norm": 0.6946887373924255,
      "learning_rate": 0.0001247551818729582,
      "loss": 0.053,
      "step": 2800
    },
    {
      "epoch": 0.8832725377800938,
      "grad_norm": 0.18278084695339203,
      "learning_rate": 0.0001235266797617545,
      "loss": 0.0359,
      "step": 2825
    },
    {
      "epoch": 0.8910891089108911,
      "grad_norm": 0.22802993655204773,
      "learning_rate": 0.00012229440721930906,
      "loss": 0.051,
      "step": 2850
    },
    {
      "epoch": 0.8989056800416884,
      "grad_norm": 0.2101507931947708,
      "learning_rate": 0.00012105856173200498,
      "loss": 0.0341,
      "step": 2875
    },
    {
      "epoch": 0.9067222511724856,
      "grad_norm": 0.21445123851299286,
      "learning_rate": 0.00011981934135883237,
      "loss": 0.0545,
      "step": 2900
    },
    {
      "epoch": 0.914538822303283,
      "grad_norm": 0.21165607869625092,
      "learning_rate": 0.00011857694469964715,
      "loss": 0.0528,
      "step": 2925
    },
    {
      "epoch": 0.9223553934340802,
      "grad_norm": 0.28440016508102417,
      "learning_rate": 0.00011733157086334294,
      "loss": 0.0461,
      "step": 2950
    },
    {
      "epoch": 0.9301719645648775,
      "grad_norm": 0.0914030522108078,
      "learning_rate": 0.0001160834194359416,
      "loss": 0.0342,
      "step": 2975
    },
    {
      "epoch": 0.9379885356956749,
      "grad_norm": 0.27181386947631836,
      "learning_rate": 0.00011483269044860705,
      "loss": 0.0705,
      "step": 3000
    },
    {
      "epoch": 0.9458051068264721,
      "grad_norm": 0.1452869474887848,
      "learning_rate": 0.000113579584345588,
      "loss": 0.0389,
      "step": 3025
    },
    {
      "epoch": 0.9536216779572694,
      "grad_norm": 0.23519569635391235,
      "learning_rate": 0.0001123243019520942,
      "loss": 0.0549,
      "step": 3050
    },
    {
      "epoch": 0.9614382490880667,
      "grad_norm": 0.08609326183795929,
      "learning_rate": 0.00011106704444211207,
      "loss": 0.0369,
      "step": 3075
    },
    {
      "epoch": 0.969254820218864,
      "grad_norm": 0.2778990566730499,
      "learning_rate": 0.000109808013306164,
      "loss": 0.0484,
      "step": 3100
    },
    {
      "epoch": 0.9770713913496613,
      "grad_norm": 0.2629532814025879,
      "learning_rate": 0.00010854741031901703,
      "loss": 0.038,
      "step": 3125
    },
    {
      "epoch": 0.9848879624804586,
      "grad_norm": 0.2715413272380829,
      "learning_rate": 0.00010728543750734622,
      "loss": 0.0684,
      "step": 3150
    },
    {
      "epoch": 0.9927045336112559,
      "grad_norm": 0.19750192761421204,
      "learning_rate": 0.00010602229711735726,
      "loss": 0.0352,
      "step": 3175
    },
    {
      "epoch": 1.0005211047420532,
      "grad_norm": 0.19653365015983582,
      "learning_rate": 0.00010475819158237425,
      "loss": 0.0492,
      "step": 3200
    },
    {
      "epoch": 1.0083376758728504,
      "grad_norm": 0.16222123801708221,
      "learning_rate": 0.0001034933234903973,
      "loss": 0.0291,
      "step": 3225
    },
    {
      "epoch": 1.0161542470036478,
      "grad_norm": 0.20708639919757843,
      "learning_rate": 0.0001022278955516354,
      "loss": 0.047,
      "step": 3250
    },
    {
      "epoch": 1.0239708181344451,
      "grad_norm": 0.1643044799566269,
      "learning_rate": 0.00010096211056601958,
      "loss": 0.0394,
      "step": 3275
    },
    {
      "epoch": 1.0317873892652423,
      "grad_norm": 0.13272717595100403,
      "learning_rate": 9.969617139070202e-05,
      "loss": 0.0458,
      "step": 3300
    },
    {
      "epoch": 1.0396039603960396,
      "grad_norm": 0.18296131491661072,
      "learning_rate": 9.84302809075455e-05,
      "loss": 0.0272,
      "step": 3325
    },
    {
      "epoch": 1.047420531526837,
      "grad_norm": 0.20088638365268707,
      "learning_rate": 9.716464199060946e-05,
      "loss": 0.0453,
      "step": 3350
    },
    {
      "epoch": 1.0552371026576342,
      "grad_norm": 0.14927376806735992,
      "learning_rate": 9.589945747363667e-05,
      "loss": 0.0313,
      "step": 3375
    },
    {
      "epoch": 1.0630536737884315,
      "grad_norm": 0.19226379692554474,
      "learning_rate": 9.463493011754706e-05,
      "loss": 0.0467,
      "step": 3400
    },
    {
      "epoch": 1.0708702449192287,
      "grad_norm": 0.14430613815784454,
      "learning_rate": 9.337126257794255e-05,
      "loss": 0.0216,
      "step": 3425
    },
    {
      "epoch": 1.078686816050026,
      "grad_norm": 0.25263434648513794,
      "learning_rate": 9.210865737262924e-05,
      "loss": 0.0389,
      "step": 3450
    },
    {
      "epoch": 1.0865033871808234,
      "grad_norm": 0.198201984167099,
      "learning_rate": 9.084731684916151e-05,
      "loss": 0.0331,
      "step": 3475
    },
    {
      "epoch": 1.0943199583116205,
      "grad_norm": 0.026809802278876305,
      "learning_rate": 8.958744315241341e-05,
      "loss": 0.041,
      "step": 3500
    },
    {
      "epoch": 1.102136529442418,
      "grad_norm": 0.10379711538553238,
      "learning_rate": 8.832923819218238e-05,
      "loss": 0.0349,
      "step": 3525
    },
    {
      "epoch": 1.1099531005732153,
      "grad_norm": 0.09186951816082001,
      "learning_rate": 8.707290361083107e-05,
      "loss": 0.0366,
      "step": 3550
    },
    {
      "epoch": 1.1177696717040124,
      "grad_norm": 0.25562307238578796,
      "learning_rate": 8.581864075097144e-05,
      "loss": 0.0299,
      "step": 3575
    },
    {
      "epoch": 1.1255862428348098,
      "grad_norm": 0.05680067464709282,
      "learning_rate": 8.456665062319742e-05,
      "loss": 0.0351,
      "step": 3600
    },
    {
      "epoch": 1.1334028139656072,
      "grad_norm": 0.1409057229757309,
      "learning_rate": 8.33171338738706e-05,
      "loss": 0.038,
      "step": 3625
    },
    {
      "epoch": 1.1412193850964043,
      "grad_norm": 0.11576171964406967,
      "learning_rate": 8.207029075296392e-05,
      "loss": 0.0436,
      "step": 3650
    },
    {
      "epoch": 1.1490359562272017,
      "grad_norm": 0.20560188591480255,
      "learning_rate": 8.082632108196969e-05,
      "loss": 0.0322,
      "step": 3675
    },
    {
      "epoch": 1.156852527357999,
      "grad_norm": 0.13039858639240265,
      "learning_rate": 7.958542422187538e-05,
      "loss": 0.0415,
      "step": 3700
    },
    {
      "epoch": 1.1646690984887962,
      "grad_norm": 0.1456974297761917,
      "learning_rate": 7.834779904121399e-05,
      "loss": 0.0295,
      "step": 3725
    },
    {
      "epoch": 1.1724856696195936,
      "grad_norm": 0.17588438093662262,
      "learning_rate": 7.711364388419278e-05,
      "loss": 0.0413,
      "step": 3750
    },
    {
      "epoch": 1.180302240750391,
      "grad_norm": 0.19113951921463013,
      "learning_rate": 7.588315653890629e-05,
      "loss": 0.028,
      "step": 3775
    },
    {
      "epoch": 1.188118811881188,
      "grad_norm": 0.15354913473129272,
      "learning_rate": 7.465653420563845e-05,
      "loss": 0.0333,
      "step": 3800
    },
    {
      "epoch": 1.1959353830119854,
      "grad_norm": 0.1852371096611023,
      "learning_rate": 7.343397346525888e-05,
      "loss": 0.025,
      "step": 3825
    },
    {
      "epoch": 1.2037519541427826,
      "grad_norm": 0.12720173597335815,
      "learning_rate": 7.221567024771849e-05,
      "loss": 0.0396,
      "step": 3850
    },
    {
      "epoch": 1.21156852527358,
      "grad_norm": 0.10735008865594864,
      "learning_rate": 7.100181980064937e-05,
      "loss": 0.0254,
      "step": 3875
    },
    {
      "epoch": 1.2193850964043773,
      "grad_norm": 0.19253745675086975,
      "learning_rate": 6.979261665807389e-05,
      "loss": 0.0414,
      "step": 3900
    },
    {
      "epoch": 1.2272016675351747,
      "grad_norm": 0.03230956196784973,
      "learning_rate": 6.858825460922849e-05,
      "loss": 0.0276,
      "step": 3925
    },
    {
      "epoch": 1.2350182386659718,
      "grad_norm": 0.23311646282672882,
      "learning_rate": 6.738892666750651e-05,
      "loss": 0.04,
      "step": 3950
    },
    {
      "epoch": 1.2428348097967692,
      "grad_norm": 0.1685890108346939,
      "learning_rate": 6.619482503952559e-05,
      "loss": 0.0197,
      "step": 3975
    },
    {
      "epoch": 1.2506513809275663,
      "grad_norm": 0.0479617714881897,
      "learning_rate": 6.500614109432419e-05,
      "loss": 0.0386,
      "step": 4000
    },
    {
      "epoch": 1.2584679520583637,
      "grad_norm": 0.04361303523182869,
      "learning_rate": 6.382306533269238e-05,
      "loss": 0.0302,
      "step": 4025
    },
    {
      "epoch": 1.266284523189161,
      "grad_norm": 0.1347581446170807,
      "learning_rate": 6.264578735664194e-05,
      "loss": 0.0372,
      "step": 4050
    },
    {
      "epoch": 1.2741010943199584,
      "grad_norm": 0.08843477815389633,
      "learning_rate": 6.147449583902036e-05,
      "loss": 0.0241,
      "step": 4075
    },
    {
      "epoch": 1.2819176654507556,
      "grad_norm": 0.1639636904001236,
      "learning_rate": 6.030937849327356e-05,
      "loss": 0.0324,
      "step": 4100
    },
    {
      "epoch": 1.289734236581553,
      "grad_norm": 0.057000093162059784,
      "learning_rate": 5.91506220433629e-05,
      "loss": 0.0236,
      "step": 4125
    },
    {
      "epoch": 1.29755080771235,
      "grad_norm": 0.10412025451660156,
      "learning_rate": 5.79984121938401e-05,
      "loss": 0.0473,
      "step": 4150
    },
    {
      "epoch": 1.3053673788431475,
      "grad_norm": 0.09578315913677216,
      "learning_rate": 5.6852933600086125e-05,
      "loss": 0.0266,
      "step": 4175
    },
    {
      "epoch": 1.3131839499739448,
      "grad_norm": 0.1010938212275505,
      "learning_rate": 5.5714369838717874e-05,
      "loss": 0.0379,
      "step": 4200
    },
    {
      "epoch": 1.321000521104742,
      "grad_norm": 0.2028610110282898,
      "learning_rate": 5.4582903378167716e-05,
      "loss": 0.0352,
      "step": 4225
    },
    {
      "epoch": 1.3288170922355393,
      "grad_norm": 0.15233872830867767,
      "learning_rate": 5.3458715549440984e-05,
      "loss": 0.0463,
      "step": 4250
    },
    {
      "epoch": 1.3366336633663367,
      "grad_norm": 0.2081560641527176,
      "learning_rate": 5.234198651705527e-05,
      "loss": 0.0329,
      "step": 4275
    },
    {
      "epoch": 1.3444502344971339,
      "grad_norm": 0.09243500977754593,
      "learning_rate": 5.12328952501671e-05,
      "loss": 0.0286,
      "step": 4300
    },
    {
      "epoch": 1.3522668056279312,
      "grad_norm": 0.058443717658519745,
      "learning_rate": 5.013161949388993e-05,
      "loss": 0.0305,
      "step": 4325
    },
    {
      "epoch": 1.3600833767587286,
      "grad_norm": 0.07097695767879486,
      "learning_rate": 4.903833574080825e-05,
      "loss": 0.0342,
      "step": 4350
    },
    {
      "epoch": 1.3678999478895257,
      "grad_norm": 0.2500014901161194,
      "learning_rate": 4.795321920269279e-05,
      "loss": 0.0226,
      "step": 4375
    },
    {
      "epoch": 1.375716519020323,
      "grad_norm": 0.1649225503206253,
      "learning_rate": 4.687644378242044e-05,
      "loss": 0.0341,
      "step": 4400
    },
    {
      "epoch": 1.3835330901511202,
      "grad_norm": 0.14892566204071045,
      "learning_rate": 4.580818204610458e-05,
      "loss": 0.0256,
      "step": 4425
    },
    {
      "epoch": 1.3913496612819176,
      "grad_norm": 0.09151675552129745,
      "learning_rate": 4.4748605195438976e-05,
      "loss": 0.0407,
      "step": 4450
    },
    {
      "epoch": 1.399166232412715,
      "grad_norm": 0.07278190553188324,
      "learning_rate": 4.36978830402608e-05,
      "loss": 0.0266,
      "step": 4475
    },
    {
      "epoch": 1.4069828035435124,
      "grad_norm": 0.15508148074150085,
      "learning_rate": 4.265618397133674e-05,
      "loss": 0.0422,
      "step": 4500
    },
    {
      "epoch": 1.4147993746743095,
      "grad_norm": 0.0909937247633934,
      "learning_rate": 4.162367493337601e-05,
      "loss": 0.0224,
      "step": 4525
    },
    {
      "epoch": 1.4226159458051069,
      "grad_norm": 0.08767227828502655,
      "learning_rate": 4.060052139827582e-05,
      "loss": 0.0326,
      "step": 4550
    },
    {
      "epoch": 1.430432516935904,
      "grad_norm": 0.1602378934621811,
      "learning_rate": 3.958688733860237e-05,
      "loss": 0.0199,
      "step": 4575
    },
    {
      "epoch": 1.4382490880667014,
      "grad_norm": 0.2317967414855957,
      "learning_rate": 3.858293520131221e-05,
      "loss": 0.0262,
      "step": 4600
    },
    {
      "epoch": 1.4460656591974987,
      "grad_norm": 0.023075230419635773,
      "learning_rate": 3.758882588171837e-05,
      "loss": 0.0252,
      "step": 4625
    },
    {
      "epoch": 1.453882230328296,
      "grad_norm": 0.05247706174850464,
      "learning_rate": 3.660471869770474e-05,
      "loss": 0.0279,
      "step": 4650
    },
    {
      "epoch": 1.4616988014590933,
      "grad_norm": 0.1419275552034378,
      "learning_rate": 3.563077136419373e-05,
      "loss": 0.0242,
      "step": 4675
    },
    {
      "epoch": 1.4695153725898906,
      "grad_norm": 0.1773480474948883,
      "learning_rate": 3.466713996787039e-05,
      "loss": 0.0332,
      "step": 4700
    },
    {
      "epoch": 1.4773319437206878,
      "grad_norm": 0.18459045886993408,
      "learning_rate": 3.371397894216766e-05,
      "loss": 0.0254,
      "step": 4725
    },
    {
      "epoch": 1.4851485148514851,
      "grad_norm": 0.09970437735319138,
      "learning_rate": 3.277144104251669e-05,
      "loss": 0.0304,
      "step": 4750
    },
    {
      "epoch": 1.4929650859822825,
      "grad_norm": 0.22677859663963318,
      "learning_rate": 3.183967732186582e-05,
      "loss": 0.0196,
      "step": 4775
    },
    {
      "epoch": 1.5007816571130799,
      "grad_norm": 0.0915369838476181,
      "learning_rate": 3.0918837106472686e-05,
      "loss": 0.0358,
      "step": 4800
    },
    {
      "epoch": 1.508598228243877,
      "grad_norm": 0.13343112170696259,
      "learning_rate": 3.0009067971972716e-05,
      "loss": 0.021,
      "step": 4825
    },
    {
      "epoch": 1.5164147993746742,
      "grad_norm": 0.19207358360290527,
      "learning_rate": 2.9110515719728594e-05,
      "loss": 0.0396,
      "step": 4850
    },
    {
      "epoch": 1.5242313705054715,
      "grad_norm": 0.06222647801041603,
      "learning_rate": 2.8223324353463644e-05,
      "loss": 0.0238,
      "step": 4875
    },
    {
      "epoch": 1.532047941636269,
      "grad_norm": 0.14597944915294647,
      "learning_rate": 2.73476360561837e-05,
      "loss": 0.0365,
      "step": 4900
    },
    {
      "epoch": 1.5398645127670663,
      "grad_norm": 0.05296514928340912,
      "learning_rate": 2.6483591167390407e-05,
      "loss": 0.0211,
      "step": 4925
    },
    {
      "epoch": 1.5476810838978636,
      "grad_norm": 0.03366486728191376,
      "learning_rate": 2.5631328160590318e-05,
      "loss": 0.0375,
      "step": 4950
    },
    {
      "epoch": 1.5554976550286608,
      "grad_norm": 0.15603026747703552,
      "learning_rate": 2.479098362110267e-05,
      "loss": 0.0199,
      "step": 4975
    },
    {
      "epoch": 1.563314226159458,
      "grad_norm": 0.17754268646240234,
      "learning_rate": 2.3962692224170114e-05,
      "loss": 0.0203,
      "step": 5000
    },
    {
      "epoch": 1.5711307972902553,
      "grad_norm": 0.07745020091533661,
      "learning_rate": 2.3146586713375395e-05,
      "loss": 0.0224,
      "step": 5025
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.03380246460437775,
      "learning_rate": 2.2342797879367418e-05,
      "loss": 0.0389,
      "step": 5050
    },
    {
      "epoch": 1.58676393955185,
      "grad_norm": 0.026049425825476646,
      "learning_rate": 2.155145453890076e-05,
      "loss": 0.0265,
      "step": 5075
    },
    {
      "epoch": 1.5945805106826472,
      "grad_norm": 0.05505313724279404,
      "learning_rate": 2.0772683514191004e-05,
      "loss": 0.0389,
      "step": 5100
    },
    {
      "epoch": 1.6023970818134445,
      "grad_norm": 0.10674291104078293,
      "learning_rate": 2.0006609612590142e-05,
      "loss": 0.0251,
      "step": 5125
    },
    {
      "epoch": 1.6102136529442417,
      "grad_norm": 0.25286248326301575,
      "learning_rate": 1.9253355606584655e-05,
      "loss": 0.0348,
      "step": 5150
    },
    {
      "epoch": 1.618030224075039,
      "grad_norm": 0.06316901743412018,
      "learning_rate": 1.851304221411967e-05,
      "loss": 0.0254,
      "step": 5175
    },
    {
      "epoch": 1.6258467952058364,
      "grad_norm": 0.10090920329093933,
      "learning_rate": 1.778578807925253e-05,
      "loss": 0.0318,
      "step": 5200
    },
    {
      "epoch": 1.6336633663366338,
      "grad_norm": 0.14331893622875214,
      "learning_rate": 1.707170975313879e-05,
      "loss": 0.0254,
      "step": 5225
    },
    {
      "epoch": 1.641479937467431,
      "grad_norm": 0.17967621982097626,
      "learning_rate": 1.6370921675353223e-05,
      "loss": 0.0285,
      "step": 5250
    },
    {
      "epoch": 1.6492965085982283,
      "grad_norm": 0.24462537467479706,
      "learning_rate": 1.568353615554985e-05,
      "loss": 0.0194,
      "step": 5275
    },
    {
      "epoch": 1.6571130797290254,
      "grad_norm": 0.10611876100301743,
      "learning_rate": 1.5009663355462655e-05,
      "loss": 0.0344,
      "step": 5300
    },
    {
      "epoch": 1.6649296508598228,
      "grad_norm": 0.08899326622486115,
      "learning_rate": 1.4349411271251134e-05,
      "loss": 0.0179,
      "step": 5325
    },
    {
      "epoch": 1.6727462219906202,
      "grad_norm": 0.20975565910339355,
      "learning_rate": 1.3702885716192348e-05,
      "loss": 0.0208,
      "step": 5350
    },
    {
      "epoch": 1.6805627931214175,
      "grad_norm": 0.023059310391545296,
      "learning_rate": 1.3070190303723352e-05,
      "loss": 0.0205,
      "step": 5375
    },
    {
      "epoch": 1.6883793642522147,
      "grad_norm": 0.12308897078037262,
      "learning_rate": 1.2451426430835733e-05,
      "loss": 0.0255,
      "step": 5400
    },
    {
      "epoch": 1.6961959353830118,
      "grad_norm": 0.2202647179365158,
      "learning_rate": 1.1846693261825525e-05,
      "loss": 0.0198,
      "step": 5425
    },
    {
      "epoch": 1.7040125065138092,
      "grad_norm": 0.20158152282238007,
      "learning_rate": 1.1256087712401087e-05,
      "loss": 0.0352,
      "step": 5450
    },
    {
      "epoch": 1.7118290776446066,
      "grad_norm": 0.0767163634300232,
      "learning_rate": 1.0679704434151016e-05,
      "loss": 0.0213,
      "step": 5475
    },
    {
      "epoch": 1.719645648775404,
      "grad_norm": 0.22335465252399445,
      "learning_rate": 1.0117635799375291e-05,
      "loss": 0.0308,
      "step": 5500
    },
    {
      "epoch": 1.7274622199062013,
      "grad_norm": 0.17198410630226135,
      "learning_rate": 9.569971886281392e-06,
      "loss": 0.0193,
      "step": 5525
    },
    {
      "epoch": 1.7352787910369984,
      "grad_norm": 0.17353568971157074,
      "learning_rate": 9.036800464548157e-06,
      "loss": 0.0267,
      "step": 5550
    },
    {
      "epoch": 1.7430953621677956,
      "grad_norm": 0.08238823711872101,
      "learning_rate": 8.51820698125979e-06,
      "loss": 0.0243,
      "step": 5575
    },
    {
      "epoch": 1.750911933298593,
      "grad_norm": 0.23704172670841217,
      "learning_rate": 8.014274547211808e-06,
      "loss": 0.028,
      "step": 5600
    },
    {
      "epoch": 1.7587285044293903,
      "grad_norm": 0.12837642431259155,
      "learning_rate": 7.525083923591592e-06,
      "loss": 0.0243,
      "step": 5625
    },
    {
      "epoch": 1.7665450755601877,
      "grad_norm": 0.03588886186480522,
      "learning_rate": 7.050713509035478e-06,
      "loss": 0.0249,
      "step": 5650
    },
    {
      "epoch": 1.7743616466909848,
      "grad_norm": 0.14019536972045898,
      "learning_rate": 6.591239327064391e-06,
      "loss": 0.0208,
      "step": 5675
    },
    {
      "epoch": 1.7821782178217822,
      "grad_norm": 0.02937931939959526,
      "learning_rate": 6.146735013900173e-06,
      "loss": 0.031,
      "step": 5700
    },
    {
      "epoch": 1.7899947889525794,
      "grad_norm": 0.12394514679908752,
      "learning_rate": 5.717271806664559e-06,
      "loss": 0.0261,
      "step": 5725
    },
    {
      "epoch": 1.7978113600833767,
      "grad_norm": 0.031466539949178696,
      "learning_rate": 5.302918531962464e-06,
      "loss": 0.0246,
      "step": 5750
    },
    {
      "epoch": 1.805627931214174,
      "grad_norm": 0.027209661900997162,
      "learning_rate": 4.903741594851841e-06,
      "loss": 0.0139,
      "step": 5775
    },
    {
      "epoch": 1.8134445023449715,
      "grad_norm": 0.18120719492435455,
      "learning_rate": 4.519804968201313e-06,
      "loss": 0.0307,
      "step": 5800
    },
    {
      "epoch": 1.8212610734757686,
      "grad_norm": 0.13488014042377472,
      "learning_rate": 4.151170182437924e-06,
      "loss": 0.0202,
      "step": 5825
    },
    {
      "epoch": 1.829077644606566,
      "grad_norm": 0.028063567355275154,
      "learning_rate": 3.7978963156860446e-06,
      "loss": 0.0299,
      "step": 5850
    },
    {
      "epoch": 1.8368942157373631,
      "grad_norm": 0.0646483302116394,
      "learning_rate": 3.4600399842994237e-06,
      "loss": 0.0183,
      "step": 5875
    },
    {
      "epoch": 1.8447107868681605,
      "grad_norm": 0.10572118312120438,
      "learning_rate": 3.13765533378777e-06,
      "loss": 0.0256,
      "step": 5900
    },
    {
      "epoch": 1.8525273579989578,
      "grad_norm": 0.18584172427654266,
      "learning_rate": 2.8307940301392164e-06,
      "loss": 0.0167,
      "step": 5925
    },
    {
      "epoch": 1.8603439291297552,
      "grad_norm": 0.028159258887171745,
      "learning_rate": 2.539505251540353e-06,
      "loss": 0.0322,
      "step": 5950
    },
    {
      "epoch": 1.8681605002605524,
      "grad_norm": 0.16383618116378784,
      "learning_rate": 2.263835680494686e-06,
      "loss": 0.02,
      "step": 5975
    },
    {
      "epoch": 1.8759770713913495,
      "grad_norm": 0.1757473349571228,
      "learning_rate": 2.003829496341325e-06,
      "loss": 0.0325,
      "step": 6000
    },
    {
      "epoch": 1.8837936425221469,
      "grad_norm": 0.037028055638074875,
      "learning_rate": 1.7595283681746678e-06,
      "loss": 0.0199,
      "step": 6025
    },
    {
      "epoch": 1.8916102136529442,
      "grad_norm": 0.1590198278427124,
      "learning_rate": 1.5309714481664183e-06,
      "loss": 0.0258,
      "step": 6050
    },
    {
      "epoch": 1.8994267847837416,
      "grad_norm": 0.04241291433572769,
      "learning_rate": 1.3181953652910305e-06,
      "loss": 0.0191,
      "step": 6075
    },
    {
      "epoch": 1.907243355914539,
      "grad_norm": 0.13229146599769592,
      "learning_rate": 1.121234219455447e-06,
      "loss": 0.0203,
      "step": 6100
    },
    {
      "epoch": 1.9150599270453361,
      "grad_norm": 0.15318424999713898,
      "learning_rate": 9.401195760341708e-07,
      "loss": 0.0205,
      "step": 6125
    },
    {
      "epoch": 1.9228764981761333,
      "grad_norm": 0.22884990274906158,
      "learning_rate": 7.748804608105675e-07,
      "loss": 0.0242,
      "step": 6150
    },
    {
      "epoch": 1.9306930693069306,
      "grad_norm": 0.03139727562665939,
      "learning_rate": 6.255433553250978e-07,
      "loss": 0.0236,
      "step": 6175
    },
    {
      "epoch": 1.938509640437728,
      "grad_norm": 0.13683681190013885,
      "learning_rate": 4.921321926313893e-07,
      "loss": 0.022,
      "step": 6200
    },
    {
      "epoch": 1.9463262115685254,
      "grad_norm": 0.13990086317062378,
      "learning_rate": 3.746683534606277e-07,
      "loss": 0.0128,
      "step": 6225
    },
    {
      "epoch": 1.9541427826993225,
      "grad_norm": 0.24335864186286926,
      "learning_rate": 2.7317066279506363e-07,
      "loss": 0.0302,
      "step": 6250
    },
    {
      "epoch": 1.9619593538301199,
      "grad_norm": 0.200803741812706,
      "learning_rate": 1.8765538685108218e-07,
      "loss": 0.0229,
      "step": 6275
    },
    {
      "epoch": 1.969775924960917,
      "grad_norm": 0.02536185458302498,
      "learning_rate": 1.1813623047236544e-07,
      "loss": 0.0295,
      "step": 6300
    },
    {
      "epoch": 1.9775924960917144,
      "grad_norm": 0.1315106302499771,
      "learning_rate": 6.462433493347187e-08,
      "loss": 0.019,
      "step": 6325
    },
    {
      "epoch": 1.9854090672225118,
      "grad_norm": 0.05901605635881424,
      "learning_rate": 2.712827615437563e-08,
      "loss": 0.0301,
      "step": 6350
    },
    {
      "epoch": 1.9932256383533091,
      "grad_norm": 0.11585033684968948,
      "learning_rate": 5.654063326032688e-09,
      "loss": 0.0253,
      "step": 6375
    }
  ],
  "logging_steps": 25,
  "max_steps": 6396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.049339626815488e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
