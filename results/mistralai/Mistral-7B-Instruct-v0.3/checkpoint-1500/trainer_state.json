{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.903433045573178,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015057217426219635,
      "grad_norm": 0.6162276268005371,
      "learning_rate": 5e-05,
      "loss": 1.2342,
      "step": 25
    },
    {
      "epoch": 0.03011443485243927,
      "grad_norm": 1.0356897115707397,
      "learning_rate": 0.0001,
      "loss": 1.1408,
      "step": 50
    },
    {
      "epoch": 0.0451716522786589,
      "grad_norm": 0.4946366846561432,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.8149,
      "step": 75
    },
    {
      "epoch": 0.06022886970487854,
      "grad_norm": 0.5982633829116821,
      "learning_rate": 0.0002,
      "loss": 0.9018,
      "step": 100
    },
    {
      "epoch": 0.07528608713109818,
      "grad_norm": 0.39302748441696167,
      "learning_rate": 0.00019997025482747441,
      "loss": 0.7677,
      "step": 125
    },
    {
      "epoch": 0.0903433045573178,
      "grad_norm": 0.6856028437614441,
      "learning_rate": 0.00019988103700540344,
      "loss": 0.8717,
      "step": 150
    },
    {
      "epoch": 0.10540052198353744,
      "grad_norm": 0.4370080828666687,
      "learning_rate": 0.0001997323996097772,
      "loss": 0.7241,
      "step": 175
    },
    {
      "epoch": 0.12045773940975708,
      "grad_norm": 0.5582774877548218,
      "learning_rate": 0.00019952443106549533,
      "loss": 0.8307,
      "step": 200
    },
    {
      "epoch": 0.13551495683597672,
      "grad_norm": 0.36045923829078674,
      "learning_rate": 0.00019925725509376235,
      "loss": 0.7786,
      "step": 225
    },
    {
      "epoch": 0.15057217426219635,
      "grad_norm": 0.4299575984477997,
      "learning_rate": 0.0001989310306384858,
      "loss": 0.8202,
      "step": 250
    },
    {
      "epoch": 0.16562939168841598,
      "grad_norm": 0.41750669479370117,
      "learning_rate": 0.00019854595177171968,
      "loss": 0.755,
      "step": 275
    },
    {
      "epoch": 0.1806866091146356,
      "grad_norm": 0.48091232776641846,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.8124,
      "step": 300
    },
    {
      "epoch": 0.19574382654085526,
      "grad_norm": 0.2549595236778259,
      "learning_rate": 0.00019760018201911433,
      "loss": 0.7799,
      "step": 325
    },
    {
      "epoch": 0.21080104396707489,
      "grad_norm": 0.41178855299949646,
      "learning_rate": 0.0001970400537749643,
      "loss": 0.8301,
      "step": 350
    },
    {
      "epoch": 0.2258582613932945,
      "grad_norm": 0.39922034740448,
      "learning_rate": 0.00019642219606798566,
      "loss": 0.7393,
      "step": 375
    },
    {
      "epoch": 0.24091547881951417,
      "grad_norm": 0.45461681485176086,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.8039,
      "step": 400
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 0.38354846835136414,
      "learning_rate": 0.00019501479665306047,
      "loss": 0.7497,
      "step": 425
    },
    {
      "epoch": 0.27102991367195345,
      "grad_norm": 0.4555087685585022,
      "learning_rate": 0.00019422609221188207,
      "loss": 0.8298,
      "step": 450
    },
    {
      "epoch": 0.2860871310981731,
      "grad_norm": 0.25949835777282715,
      "learning_rate": 0.0001933813323433186,
      "loss": 0.7481,
      "step": 475
    },
    {
      "epoch": 0.3011443485243927,
      "grad_norm": 0.6082090735435486,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.7936,
      "step": 500
    },
    {
      "epoch": 0.31620156595061233,
      "grad_norm": 0.30319806933403015,
      "learning_rate": 0.00019152568957487708,
      "loss": 0.7491,
      "step": 525
    },
    {
      "epoch": 0.33125878337683196,
      "grad_norm": 0.45306825637817383,
      "learning_rate": 0.00019051591060328496,
      "loss": 0.8326,
      "step": 550
    },
    {
      "epoch": 0.3463160008030516,
      "grad_norm": 0.3380299210548401,
      "learning_rate": 0.0001894522834041487,
      "loss": 0.7194,
      "step": 575
    },
    {
      "epoch": 0.3613732182292712,
      "grad_norm": 0.49608349800109863,
      "learning_rate": 0.00018833544073295917,
      "loss": 0.8459,
      "step": 600
    },
    {
      "epoch": 0.3764304356554909,
      "grad_norm": 0.4230700731277466,
      "learning_rate": 0.00018716604700327514,
      "loss": 0.6925,
      "step": 625
    },
    {
      "epoch": 0.3914876530817105,
      "grad_norm": 0.42088788747787476,
      "learning_rate": 0.00018594479789146138,
      "loss": 0.8106,
      "step": 650
    },
    {
      "epoch": 0.40654487050793015,
      "grad_norm": 0.3935295343399048,
      "learning_rate": 0.00018467241992282843,
      "loss": 0.7128,
      "step": 675
    },
    {
      "epoch": 0.42160208793414977,
      "grad_norm": 0.3600609600543976,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.742,
      "step": 700
    },
    {
      "epoch": 0.4366593053603694,
      "grad_norm": 0.34269994497299194,
      "learning_rate": 0.00018197733514970654,
      "loss": 0.7172,
      "step": 725
    },
    {
      "epoch": 0.451716522786589,
      "grad_norm": 0.47201913595199585,
      "learning_rate": 0.00018055623166044854,
      "loss": 0.7472,
      "step": 750
    },
    {
      "epoch": 0.46677374021280865,
      "grad_norm": 0.3148924708366394,
      "learning_rate": 0.0001790872049910155,
      "loss": 0.7321,
      "step": 775
    },
    {
      "epoch": 0.48183095763902833,
      "grad_norm": 0.43999090790748596,
      "learning_rate": 0.000177571129070442,
      "loss": 0.7834,
      "step": 800
    },
    {
      "epoch": 0.49688817506524796,
      "grad_norm": 0.4194824695587158,
      "learning_rate": 0.00017600890581752435,
      "loss": 0.6581,
      "step": 825
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 0.4583726227283478,
      "learning_rate": 0.0001744014646042663,
      "loss": 0.7854,
      "step": 850
    },
    {
      "epoch": 0.5270026099176872,
      "grad_norm": 0.2520162761211395,
      "learning_rate": 0.00017274976170299198,
      "loss": 0.6637,
      "step": 875
    },
    {
      "epoch": 0.5420598273439069,
      "grad_norm": 0.46145275235176086,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.7509,
      "step": 900
    },
    {
      "epoch": 0.5571170447701265,
      "grad_norm": 0.30375978350639343,
      "learning_rate": 0.00016931752699829208,
      "loss": 0.6896,
      "step": 925
    },
    {
      "epoch": 0.5721742621963462,
      "grad_norm": 0.46191680431365967,
      "learning_rate": 0.00016753903704313527,
      "loss": 0.7882,
      "step": 950
    },
    {
      "epoch": 0.5872314796225657,
      "grad_norm": 0.40148255228996277,
      "learning_rate": 0.00016572036788179727,
      "loss": 0.6728,
      "step": 975
    },
    {
      "epoch": 0.6022886970487854,
      "grad_norm": 0.5263965725898743,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.771,
      "step": 1000
    },
    {
      "epoch": 0.617345914475005,
      "grad_norm": 0.385874480009079,
      "learning_rate": 0.00016196684292991826,
      "loss": 0.6828,
      "step": 1025
    },
    {
      "epoch": 0.6324031319012247,
      "grad_norm": 0.4954039752483368,
      "learning_rate": 0.00016003422012432275,
      "loss": 0.7115,
      "step": 1050
    },
    {
      "epoch": 0.6474603493274443,
      "grad_norm": 0.29986849427223206,
      "learning_rate": 0.0001580658827540265,
      "loss": 0.6861,
      "step": 1075
    },
    {
      "epoch": 0.6625175667536639,
      "grad_norm": 0.48803430795669556,
      "learning_rate": 0.00015606300178972287,
      "loss": 0.7315,
      "step": 1100
    },
    {
      "epoch": 0.6775747841798836,
      "grad_norm": 0.3735501170158386,
      "learning_rate": 0.00015402676875220846,
      "loss": 0.7029,
      "step": 1125
    },
    {
      "epoch": 0.6926320016061032,
      "grad_norm": 0.5172023773193359,
      "learning_rate": 0.00015195839500354335,
      "loss": 0.763,
      "step": 1150
    },
    {
      "epoch": 0.7076892190323228,
      "grad_norm": 0.38778504729270935,
      "learning_rate": 0.00014985911102640762,
      "loss": 0.615,
      "step": 1175
    },
    {
      "epoch": 0.7227464364585424,
      "grad_norm": 0.3866846561431885,
      "learning_rate": 0.00014773016569208283,
      "loss": 0.7814,
      "step": 1200
    },
    {
      "epoch": 0.7378036538847621,
      "grad_norm": 0.4158984124660492,
      "learning_rate": 0.00014557282551749427,
      "loss": 0.6891,
      "step": 1225
    },
    {
      "epoch": 0.7528608713109818,
      "grad_norm": 0.5229365825653076,
      "learning_rate": 0.00014338837391175582,
      "loss": 0.7381,
      "step": 1250
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 0.311139851808548,
      "learning_rate": 0.00014117811041266517,
      "loss": 0.615,
      "step": 1275
    },
    {
      "epoch": 0.782975306163421,
      "grad_norm": 0.5279902219772339,
      "learning_rate": 0.00013894334991360448,
      "loss": 0.7193,
      "step": 1300
    },
    {
      "epoch": 0.7980325235896406,
      "grad_norm": 0.3422825336456299,
      "learning_rate": 0.00013668542188130566,
      "loss": 0.6435,
      "step": 1325
    },
    {
      "epoch": 0.8130897410158603,
      "grad_norm": 0.650327205657959,
      "learning_rate": 0.0001344056695649462,
      "loss": 0.764,
      "step": 1350
    },
    {
      "epoch": 0.8281469584420799,
      "grad_norm": 0.36654260754585266,
      "learning_rate": 0.0001321054491970454,
      "loss": 0.6562,
      "step": 1375
    },
    {
      "epoch": 0.8432041758682995,
      "grad_norm": 0.506408154964447,
      "learning_rate": 0.000129786129186637,
      "loss": 0.7126,
      "step": 1400
    },
    {
      "epoch": 0.8582613932945192,
      "grad_norm": 0.40229061245918274,
      "learning_rate": 0.0001274490893051981,
      "loss": 0.6676,
      "step": 1425
    },
    {
      "epoch": 0.8733186107207388,
      "grad_norm": 0.528476357460022,
      "learning_rate": 0.00012509571986581814,
      "loss": 0.7277,
      "step": 1450
    },
    {
      "epoch": 0.8883758281469585,
      "grad_norm": 0.44124242663383484,
      "learning_rate": 0.00012272742089609694,
      "loss": 0.6719,
      "step": 1475
    },
    {
      "epoch": 0.903433045573178,
      "grad_norm": 0.5476202964782715,
      "learning_rate": 0.0001203456013052634,
      "loss": 0.6976,
      "step": 1500
    }
  ],
  "logging_steps": 25,
  "max_steps": 3320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.380498994956288e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
