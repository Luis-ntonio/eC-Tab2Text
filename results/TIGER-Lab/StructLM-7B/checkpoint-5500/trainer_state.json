{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.719645648775404,
  "eval_steps": 500,
  "global_step": 5500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007816571130797291,
      "grad_norm": 0.14594127237796783,
      "learning_rate": 2.604166666666667e-05,
      "loss": 1.423,
      "step": 25
    },
    {
      "epoch": 0.015633142261594582,
      "grad_norm": 0.19861209392547607,
      "learning_rate": 5.208333333333334e-05,
      "loss": 1.3581,
      "step": 50
    },
    {
      "epoch": 0.02344971339239187,
      "grad_norm": 0.1769675761461258,
      "learning_rate": 7.8125e-05,
      "loss": 0.9733,
      "step": 75
    },
    {
      "epoch": 0.031266284523189164,
      "grad_norm": 0.602828323841095,
      "learning_rate": 0.00010416666666666667,
      "loss": 0.4944,
      "step": 100
    },
    {
      "epoch": 0.03908285565398645,
      "grad_norm": 0.14405296742916107,
      "learning_rate": 0.00013020833333333333,
      "loss": 0.3355,
      "step": 125
    },
    {
      "epoch": 0.04689942678478374,
      "grad_norm": 0.3482108414173126,
      "learning_rate": 0.00015625,
      "loss": 0.3074,
      "step": 150
    },
    {
      "epoch": 0.05471599791558103,
      "grad_norm": 0.13975800573825836,
      "learning_rate": 0.00018229166666666667,
      "loss": 0.2652,
      "step": 175
    },
    {
      "epoch": 0.06253256904637833,
      "grad_norm": 0.18033498525619507,
      "learning_rate": 0.00019999917944905216,
      "loss": 0.2844,
      "step": 200
    },
    {
      "epoch": 0.07034914017717561,
      "grad_norm": 0.1609336882829666,
      "learning_rate": 0.00019998603811858571,
      "loss": 0.2417,
      "step": 225
    },
    {
      "epoch": 0.0781657113079729,
      "grad_norm": 0.19641198217868805,
      "learning_rate": 0.00019995687283209658,
      "loss": 0.2604,
      "step": 250
    },
    {
      "epoch": 0.0859822824387702,
      "grad_norm": 0.13977476954460144,
      "learning_rate": 0.00019991168826367011,
      "loss": 0.2171,
      "step": 275
    },
    {
      "epoch": 0.09379885356956748,
      "grad_norm": 0.18794649839401245,
      "learning_rate": 0.00019985049165467257,
      "loss": 0.235,
      "step": 300
    },
    {
      "epoch": 0.10161542470036478,
      "grad_norm": 0.16783398389816284,
      "learning_rate": 0.00019977329281259108,
      "loss": 0.2178,
      "step": 325
    },
    {
      "epoch": 0.10943199583116206,
      "grad_norm": 0.18690411746501923,
      "learning_rate": 0.00019968010410946154,
      "loss": 0.2348,
      "step": 350
    },
    {
      "epoch": 0.11724856696195936,
      "grad_norm": 0.11034905910491943,
      "learning_rate": 0.00019957094047988582,
      "loss": 0.1994,
      "step": 375
    },
    {
      "epoch": 0.12506513809275666,
      "grad_norm": 0.16415157914161682,
      "learning_rate": 0.00019944581941863857,
      "loss": 0.2166,
      "step": 400
    },
    {
      "epoch": 0.13288170922355394,
      "grad_norm": 0.11332754790782928,
      "learning_rate": 0.00019930476097786327,
      "loss": 0.1838,
      "step": 425
    },
    {
      "epoch": 0.14069828035435122,
      "grad_norm": 0.2497699111700058,
      "learning_rate": 0.0001991477877638587,
      "loss": 0.2274,
      "step": 450
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 0.11457492411136627,
      "learning_rate": 0.00019897492493345598,
      "loss": 0.194,
      "step": 475
    },
    {
      "epoch": 0.1563314226159458,
      "grad_norm": 0.11682303994894028,
      "learning_rate": 0.00019878620018998696,
      "loss": 0.2042,
      "step": 500
    },
    {
      "epoch": 0.1641479937467431,
      "grad_norm": 0.14507901668548584,
      "learning_rate": 0.00019858164377884436,
      "loss": 0.178,
      "step": 525
    },
    {
      "epoch": 0.1719645648775404,
      "grad_norm": 0.13055486977100372,
      "learning_rate": 0.00019836128848263465,
      "loss": 0.2004,
      "step": 550
    },
    {
      "epoch": 0.17978113600833767,
      "grad_norm": 0.11945588886737823,
      "learning_rate": 0.0001981251696159241,
      "loss": 0.1848,
      "step": 575
    },
    {
      "epoch": 0.18759770713913496,
      "grad_norm": 0.15185748040676117,
      "learning_rate": 0.00019787332501957941,
      "loss": 0.1953,
      "step": 600
    },
    {
      "epoch": 0.19541427826993227,
      "grad_norm": 0.12302836030721664,
      "learning_rate": 0.0001976057950547031,
      "loss": 0.1693,
      "step": 625
    },
    {
      "epoch": 0.20323084940072955,
      "grad_norm": 0.11295034736394882,
      "learning_rate": 0.00019732262259616523,
      "loss": 0.2142,
      "step": 650
    },
    {
      "epoch": 0.21104742053152684,
      "grad_norm": 0.1161443367600441,
      "learning_rate": 0.0001970238530257322,
      "loss": 0.1579,
      "step": 675
    },
    {
      "epoch": 0.21886399166232412,
      "grad_norm": 0.09841138124465942,
      "learning_rate": 0.00019670953422479368,
      "loss": 0.1841,
      "step": 700
    },
    {
      "epoch": 0.2266805627931214,
      "grad_norm": 0.14099529385566711,
      "learning_rate": 0.00019637971656668918,
      "loss": 0.1512,
      "step": 725
    },
    {
      "epoch": 0.23449713392391872,
      "grad_norm": 0.2477014660835266,
      "learning_rate": 0.0001960344529086351,
      "loss": 0.1759,
      "step": 750
    },
    {
      "epoch": 0.242313705054716,
      "grad_norm": 0.12504464387893677,
      "learning_rate": 0.00019567379858325356,
      "loss": 0.1653,
      "step": 775
    },
    {
      "epoch": 0.2501302761855133,
      "grad_norm": 0.3727221190929413,
      "learning_rate": 0.000195297811389705,
      "loss": 0.1738,
      "step": 800
    },
    {
      "epoch": 0.25794684731631057,
      "grad_norm": 0.12596112489700317,
      "learning_rate": 0.00019490655158442484,
      "loss": 0.1564,
      "step": 825
    },
    {
      "epoch": 0.2657634184471079,
      "grad_norm": 0.1295066773891449,
      "learning_rate": 0.00019450008187146684,
      "loss": 0.1763,
      "step": 850
    },
    {
      "epoch": 0.27357998957790514,
      "grad_norm": 0.1178160235285759,
      "learning_rate": 0.00019407846739245415,
      "loss": 0.1543,
      "step": 875
    },
    {
      "epoch": 0.28139656070870245,
      "grad_norm": 0.12039966136217117,
      "learning_rate": 0.00019364177571613926,
      "loss": 0.1919,
      "step": 900
    },
    {
      "epoch": 0.28921313183949976,
      "grad_norm": 0.11229131370782852,
      "learning_rate": 0.00019319007682757556,
      "loss": 0.1404,
      "step": 925
    },
    {
      "epoch": 0.297029702970297,
      "grad_norm": 0.12833473086357117,
      "learning_rate": 0.0001927234431169014,
      "loss": 0.1682,
      "step": 950
    },
    {
      "epoch": 0.30484627410109433,
      "grad_norm": 0.13638420403003693,
      "learning_rate": 0.00019224194936773853,
      "loss": 0.1364,
      "step": 975
    },
    {
      "epoch": 0.3126628452318916,
      "grad_norm": 0.182381272315979,
      "learning_rate": 0.00019174567274520728,
      "loss": 0.1482,
      "step": 1000
    },
    {
      "epoch": 0.3204794163626889,
      "grad_norm": 0.13000649213790894,
      "learning_rate": 0.00019123469278355985,
      "loss": 0.134,
      "step": 1025
    },
    {
      "epoch": 0.3282959874934862,
      "grad_norm": 0.1716369390487671,
      "learning_rate": 0.00019070909137343408,
      "loss": 0.1496,
      "step": 1050
    },
    {
      "epoch": 0.33611255862428346,
      "grad_norm": 0.12828557193279266,
      "learning_rate": 0.0001901689527487294,
      "loss": 0.1236,
      "step": 1075
    },
    {
      "epoch": 0.3439291297550808,
      "grad_norm": 0.13589757680892944,
      "learning_rate": 0.0001896143634731074,
      "loss": 0.1437,
      "step": 1100
    },
    {
      "epoch": 0.3517457008858781,
      "grad_norm": 0.11323893815279007,
      "learning_rate": 0.00018904541242611902,
      "loss": 0.1415,
      "step": 1125
    },
    {
      "epoch": 0.35956227201667534,
      "grad_norm": 0.19907104969024658,
      "learning_rate": 0.00018846219078896037,
      "loss": 0.155,
      "step": 1150
    },
    {
      "epoch": 0.36737884314747266,
      "grad_norm": 0.11822272837162018,
      "learning_rate": 0.00018786479202986006,
      "loss": 0.1183,
      "step": 1175
    },
    {
      "epoch": 0.3751954142782699,
      "grad_norm": 0.1565147489309311,
      "learning_rate": 0.0001872533118890997,
      "loss": 0.1598,
      "step": 1200
    },
    {
      "epoch": 0.3830119854090672,
      "grad_norm": 0.13146431744098663,
      "learning_rate": 0.00018662784836367028,
      "loss": 0.1297,
      "step": 1225
    },
    {
      "epoch": 0.39082855653986454,
      "grad_norm": 0.143926203250885,
      "learning_rate": 0.00018598850169156722,
      "loss": 0.1463,
      "step": 1250
    },
    {
      "epoch": 0.3986451276706618,
      "grad_norm": 0.11255403608083725,
      "learning_rate": 0.00018533537433572581,
      "loss": 0.1321,
      "step": 1275
    },
    {
      "epoch": 0.4064616988014591,
      "grad_norm": 0.16874153912067413,
      "learning_rate": 0.00018466857096760046,
      "loss": 0.1368,
      "step": 1300
    },
    {
      "epoch": 0.41427826993225636,
      "grad_norm": 0.11725971847772598,
      "learning_rate": 0.00018398819845038972,
      "loss": 0.1179,
      "step": 1325
    },
    {
      "epoch": 0.42209484106305367,
      "grad_norm": 0.26376208662986755,
      "learning_rate": 0.0001832943658219103,
      "loss": 0.1518,
      "step": 1350
    },
    {
      "epoch": 0.429911412193851,
      "grad_norm": 0.14790816605091095,
      "learning_rate": 0.00018258718427712238,
      "loss": 0.1251,
      "step": 1375
    },
    {
      "epoch": 0.43772798332464824,
      "grad_norm": 0.1723167896270752,
      "learning_rate": 0.00018186676715030924,
      "loss": 0.141,
      "step": 1400
    },
    {
      "epoch": 0.44554455445544555,
      "grad_norm": 0.13394208252429962,
      "learning_rate": 0.0001811332298969142,
      "loss": 0.1208,
      "step": 1425
    },
    {
      "epoch": 0.4533611255862428,
      "grad_norm": 0.19469794631004333,
      "learning_rate": 0.0001803866900750376,
      "loss": 0.1524,
      "step": 1450
    },
    {
      "epoch": 0.4611776967170401,
      "grad_norm": 0.13278089463710785,
      "learning_rate": 0.0001796272673265963,
      "loss": 0.1113,
      "step": 1475
    },
    {
      "epoch": 0.46899426784783743,
      "grad_norm": 0.13124729692935944,
      "learning_rate": 0.00017885508335815014,
      "loss": 0.1263,
      "step": 1500
    },
    {
      "epoch": 0.4768108389786347,
      "grad_norm": 0.13141116499900818,
      "learning_rate": 0.0001780702619213967,
      "loss": 0.1212,
      "step": 1525
    },
    {
      "epoch": 0.484627410109432,
      "grad_norm": 0.17526577413082123,
      "learning_rate": 0.0001772729287933387,
      "loss": 0.12,
      "step": 1550
    },
    {
      "epoch": 0.4924439812402293,
      "grad_norm": 0.11748629063367844,
      "learning_rate": 0.00017646321175612668,
      "loss": 0.1043,
      "step": 1575
    },
    {
      "epoch": 0.5002605523710266,
      "grad_norm": 0.1497262865304947,
      "learning_rate": 0.00017564124057658056,
      "loss": 0.1465,
      "step": 1600
    },
    {
      "epoch": 0.5080771235018239,
      "grad_norm": 0.13054420053958893,
      "learning_rate": 0.00017480714698539266,
      "loss": 0.0966,
      "step": 1625
    },
    {
      "epoch": 0.5158936946326211,
      "grad_norm": 0.21636267006397247,
      "learning_rate": 0.00017396106465601663,
      "loss": 0.1255,
      "step": 1650
    },
    {
      "epoch": 0.5237102657634184,
      "grad_norm": 0.13989101350307465,
      "learning_rate": 0.0001731031291832444,
      "loss": 0.1015,
      "step": 1675
    },
    {
      "epoch": 0.5315268368942158,
      "grad_norm": 0.12669432163238525,
      "learning_rate": 0.0001722334780614756,
      "loss": 0.1312,
      "step": 1700
    },
    {
      "epoch": 0.539343408025013,
      "grad_norm": 0.1306009292602539,
      "learning_rate": 0.00017135225066268255,
      "loss": 0.1025,
      "step": 1725
    },
    {
      "epoch": 0.5471599791558103,
      "grad_norm": 0.2528972327709198,
      "learning_rate": 0.00017045958821407405,
      "loss": 0.1419,
      "step": 1750
    },
    {
      "epoch": 0.5549765502866076,
      "grad_norm": 0.12520478665828705,
      "learning_rate": 0.00016955563377546207,
      "loss": 0.1098,
      "step": 1775
    },
    {
      "epoch": 0.5627931214174049,
      "grad_norm": 0.2129993736743927,
      "learning_rate": 0.0001686405322163349,
      "loss": 0.1269,
      "step": 1800
    },
    {
      "epoch": 0.5706096925482022,
      "grad_norm": 0.12355776131153107,
      "learning_rate": 0.00016771443019263983,
      "loss": 0.1065,
      "step": 1825
    },
    {
      "epoch": 0.5784262636789995,
      "grad_norm": 0.16234388947486877,
      "learning_rate": 0.00016677747612327997,
      "loss": 0.1204,
      "step": 1850
    },
    {
      "epoch": 0.5862428348097968,
      "grad_norm": 0.11190716922283173,
      "learning_rate": 0.00016582982016632818,
      "loss": 0.093,
      "step": 1875
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 0.12065290659666061,
      "learning_rate": 0.00016487161419496263,
      "loss": 0.1153,
      "step": 1900
    },
    {
      "epoch": 0.6018759770713914,
      "grad_norm": 0.1138220727443695,
      "learning_rate": 0.00016390301177312722,
      "loss": 0.0928,
      "step": 1925
    },
    {
      "epoch": 0.6096925482021887,
      "grad_norm": 0.16219855844974518,
      "learning_rate": 0.00016292416813092105,
      "loss": 0.1256,
      "step": 1950
    },
    {
      "epoch": 0.6175091193329859,
      "grad_norm": 0.15289220213890076,
      "learning_rate": 0.00016193524013972114,
      "loss": 0.1035,
      "step": 1975
    },
    {
      "epoch": 0.6253256904637832,
      "grad_norm": 0.2328803688287735,
      "learning_rate": 0.00016093638628704167,
      "loss": 0.1217,
      "step": 2000
    },
    {
      "epoch": 0.6331422615945805,
      "grad_norm": 0.1326129287481308,
      "learning_rate": 0.0001599277666511347,
      "loss": 0.0928,
      "step": 2025
    },
    {
      "epoch": 0.6409588327253778,
      "grad_norm": 0.19925303757190704,
      "learning_rate": 0.00015890954287533555,
      "loss": 0.1145,
      "step": 2050
    },
    {
      "epoch": 0.648775403856175,
      "grad_norm": 0.10995218902826309,
      "learning_rate": 0.00015788187814215764,
      "loss": 0.0903,
      "step": 2075
    },
    {
      "epoch": 0.6565919749869724,
      "grad_norm": 0.14275571703910828,
      "learning_rate": 0.00015684493714714047,
      "loss": 0.1183,
      "step": 2100
    },
    {
      "epoch": 0.6644085461177697,
      "grad_norm": 0.12511374056339264,
      "learning_rate": 0.00015579888607245517,
      "loss": 0.0833,
      "step": 2125
    },
    {
      "epoch": 0.6722251172485669,
      "grad_norm": 0.17842432856559753,
      "learning_rate": 0.000154743892560272,
      "loss": 0.1228,
      "step": 2150
    },
    {
      "epoch": 0.6800416883793643,
      "grad_norm": 0.09889087826013565,
      "learning_rate": 0.00015368012568589342,
      "loss": 0.0826,
      "step": 2175
    },
    {
      "epoch": 0.6878582595101616,
      "grad_norm": 0.16230441629886627,
      "learning_rate": 0.00015260775593065802,
      "loss": 0.1186,
      "step": 2200
    },
    {
      "epoch": 0.6956748306409588,
      "grad_norm": 0.11392246931791306,
      "learning_rate": 0.00015152695515461865,
      "loss": 0.0776,
      "step": 2225
    },
    {
      "epoch": 0.7034914017717562,
      "grad_norm": 0.1406807005405426,
      "learning_rate": 0.00015043789656899988,
      "loss": 0.1148,
      "step": 2250
    },
    {
      "epoch": 0.7113079729025534,
      "grad_norm": 0.14356863498687744,
      "learning_rate": 0.00014934075470843887,
      "loss": 0.0773,
      "step": 2275
    },
    {
      "epoch": 0.7191245440333507,
      "grad_norm": 0.15840110182762146,
      "learning_rate": 0.00014823570540301408,
      "loss": 0.1118,
      "step": 2300
    },
    {
      "epoch": 0.7269411151641479,
      "grad_norm": 0.10787177085876465,
      "learning_rate": 0.00014712292575006633,
      "loss": 0.0898,
      "step": 2325
    },
    {
      "epoch": 0.7347576862949453,
      "grad_norm": 0.2164173275232315,
      "learning_rate": 0.00014600259408581687,
      "loss": 0.1248,
      "step": 2350
    },
    {
      "epoch": 0.7425742574257426,
      "grad_norm": 0.0803961306810379,
      "learning_rate": 0.00014487488995678708,
      "loss": 0.0708,
      "step": 2375
    },
    {
      "epoch": 0.7503908285565398,
      "grad_norm": 0.16202154755592346,
      "learning_rate": 0.00014373999409102362,
      "loss": 0.1041,
      "step": 2400
    },
    {
      "epoch": 0.7582073996873372,
      "grad_norm": 0.12513405084609985,
      "learning_rate": 0.00014259808836913492,
      "loss": 0.073,
      "step": 2425
    },
    {
      "epoch": 0.7660239708181344,
      "grad_norm": 0.21335402131080627,
      "learning_rate": 0.00014144935579514246,
      "loss": 0.119,
      "step": 2450
    },
    {
      "epoch": 0.7738405419489317,
      "grad_norm": 0.13123224675655365,
      "learning_rate": 0.00014029398046715223,
      "loss": 0.073,
      "step": 2475
    },
    {
      "epoch": 0.7816571130797291,
      "grad_norm": 0.13963523507118225,
      "learning_rate": 0.00013913214754785095,
      "loss": 0.0936,
      "step": 2500
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.12507574260234833,
      "learning_rate": 0.00013796404323483132,
      "loss": 0.0827,
      "step": 2525
    },
    {
      "epoch": 0.7972902553413236,
      "grad_norm": 0.12456454336643219,
      "learning_rate": 0.00013678985473075176,
      "loss": 0.087,
      "step": 2550
    },
    {
      "epoch": 0.805106826472121,
      "grad_norm": 0.12224282324314117,
      "learning_rate": 0.00013560977021333497,
      "loss": 0.0799,
      "step": 2575
    },
    {
      "epoch": 0.8129233976029182,
      "grad_norm": 0.16335850954055786,
      "learning_rate": 0.00013442397880521008,
      "loss": 0.1119,
      "step": 2600
    },
    {
      "epoch": 0.8207399687337155,
      "grad_norm": 0.12003367394208908,
      "learning_rate": 0.0001332326705436037,
      "loss": 0.0807,
      "step": 2625
    },
    {
      "epoch": 0.8285565398645127,
      "grad_norm": 0.17386946082115173,
      "learning_rate": 0.00013203603634988386,
      "loss": 0.1018,
      "step": 2650
    },
    {
      "epoch": 0.8363731109953101,
      "grad_norm": 0.1349707692861557,
      "learning_rate": 0.000130834267998963,
      "loss": 0.0751,
      "step": 2675
    },
    {
      "epoch": 0.8441896821261073,
      "grad_norm": 0.18134523928165436,
      "learning_rate": 0.00012962755808856342,
      "loss": 0.1086,
      "step": 2700
    },
    {
      "epoch": 0.8520062532569046,
      "grad_norm": 0.129630446434021,
      "learning_rate": 0.00012841610000835125,
      "loss": 0.0803,
      "step": 2725
    },
    {
      "epoch": 0.859822824387702,
      "grad_norm": 0.17309688031673431,
      "learning_rate": 0.00012720008790894366,
      "loss": 0.1004,
      "step": 2750
    },
    {
      "epoch": 0.8676393955184992,
      "grad_norm": 0.10843831300735474,
      "learning_rate": 0.00012597971667079361,
      "loss": 0.0777,
      "step": 2775
    },
    {
      "epoch": 0.8754559666492965,
      "grad_norm": 0.14617060124874115,
      "learning_rate": 0.0001247551818729582,
      "loss": 0.099,
      "step": 2800
    },
    {
      "epoch": 0.8832725377800938,
      "grad_norm": 0.11390377581119537,
      "learning_rate": 0.0001235266797617545,
      "loss": 0.0701,
      "step": 2825
    },
    {
      "epoch": 0.8910891089108911,
      "grad_norm": 0.14408794045448303,
      "learning_rate": 0.00012229440721930906,
      "loss": 0.0852,
      "step": 2850
    },
    {
      "epoch": 0.8989056800416884,
      "grad_norm": 0.09277956187725067,
      "learning_rate": 0.00012105856173200498,
      "loss": 0.0583,
      "step": 2875
    },
    {
      "epoch": 0.9067222511724856,
      "grad_norm": 0.14752984046936035,
      "learning_rate": 0.00011981934135883237,
      "loss": 0.0981,
      "step": 2900
    },
    {
      "epoch": 0.914538822303283,
      "grad_norm": 0.14049841463565826,
      "learning_rate": 0.00011857694469964715,
      "loss": 0.0906,
      "step": 2925
    },
    {
      "epoch": 0.9223553934340802,
      "grad_norm": 0.16831791400909424,
      "learning_rate": 0.00011733157086334294,
      "loss": 0.0896,
      "step": 2950
    },
    {
      "epoch": 0.9301719645648775,
      "grad_norm": 0.15764081478118896,
      "learning_rate": 0.0001160834194359416,
      "loss": 0.0684,
      "step": 2975
    },
    {
      "epoch": 0.9379885356956749,
      "grad_norm": 0.17426642775535583,
      "learning_rate": 0.00011483269044860705,
      "loss": 0.1113,
      "step": 3000
    },
    {
      "epoch": 0.9458051068264721,
      "grad_norm": 0.10094071924686432,
      "learning_rate": 0.000113579584345588,
      "loss": 0.0774,
      "step": 3025
    },
    {
      "epoch": 0.9536216779572694,
      "grad_norm": 0.16070006787776947,
      "learning_rate": 0.0001123243019520942,
      "loss": 0.0945,
      "step": 3050
    },
    {
      "epoch": 0.9614382490880667,
      "grad_norm": 0.18154111504554749,
      "learning_rate": 0.00011106704444211207,
      "loss": 0.0674,
      "step": 3075
    },
    {
      "epoch": 0.969254820218864,
      "grad_norm": 0.156692236661911,
      "learning_rate": 0.000109808013306164,
      "loss": 0.0879,
      "step": 3100
    },
    {
      "epoch": 0.9770713913496613,
      "grad_norm": 0.14553603529930115,
      "learning_rate": 0.00010854741031901703,
      "loss": 0.0709,
      "step": 3125
    },
    {
      "epoch": 0.9848879624804586,
      "grad_norm": 0.17945434153079987,
      "learning_rate": 0.00010728543750734622,
      "loss": 0.1098,
      "step": 3150
    },
    {
      "epoch": 0.9927045336112559,
      "grad_norm": 0.17188279330730438,
      "learning_rate": 0.00010602229711735726,
      "loss": 0.0707,
      "step": 3175
    },
    {
      "epoch": 1.0005211047420532,
      "grad_norm": 0.1285799741744995,
      "learning_rate": 0.00010475819158237425,
      "loss": 0.0873,
      "step": 3200
    },
    {
      "epoch": 1.0083376758728504,
      "grad_norm": 0.11610758304595947,
      "learning_rate": 0.0001034933234903973,
      "loss": 0.0596,
      "step": 3225
    },
    {
      "epoch": 1.0161542470036478,
      "grad_norm": 0.15578778088092804,
      "learning_rate": 0.0001022278955516354,
      "loss": 0.0921,
      "step": 3250
    },
    {
      "epoch": 1.0239708181344451,
      "grad_norm": 0.10335413366556168,
      "learning_rate": 0.00010096211056601958,
      "loss": 0.0653,
      "step": 3275
    },
    {
      "epoch": 1.0317873892652423,
      "grad_norm": 0.1463235765695572,
      "learning_rate": 9.969617139070202e-05,
      "loss": 0.0975,
      "step": 3300
    },
    {
      "epoch": 1.0396039603960396,
      "grad_norm": 0.0791129469871521,
      "learning_rate": 9.84302809075455e-05,
      "loss": 0.0611,
      "step": 3325
    },
    {
      "epoch": 1.047420531526837,
      "grad_norm": 0.16031472384929657,
      "learning_rate": 9.716464199060946e-05,
      "loss": 0.0838,
      "step": 3350
    },
    {
      "epoch": 1.0552371026576342,
      "grad_norm": 0.10740784555673599,
      "learning_rate": 9.589945747363667e-05,
      "loss": 0.0674,
      "step": 3375
    },
    {
      "epoch": 1.0630536737884315,
      "grad_norm": 0.12593664228916168,
      "learning_rate": 9.463493011754706e-05,
      "loss": 0.0899,
      "step": 3400
    },
    {
      "epoch": 1.0708702449192287,
      "grad_norm": 0.1360887885093689,
      "learning_rate": 9.337126257794255e-05,
      "loss": 0.0435,
      "step": 3425
    },
    {
      "epoch": 1.078686816050026,
      "grad_norm": 0.17487294971942902,
      "learning_rate": 9.210865737262924e-05,
      "loss": 0.068,
      "step": 3450
    },
    {
      "epoch": 1.0865033871808234,
      "grad_norm": 0.09997982531785965,
      "learning_rate": 9.084731684916151e-05,
      "loss": 0.0632,
      "step": 3475
    },
    {
      "epoch": 1.0943199583116205,
      "grad_norm": 0.08060628175735474,
      "learning_rate": 8.958744315241341e-05,
      "loss": 0.0868,
      "step": 3500
    },
    {
      "epoch": 1.102136529442418,
      "grad_norm": 0.10105565935373306,
      "learning_rate": 8.832923819218238e-05,
      "loss": 0.0651,
      "step": 3525
    },
    {
      "epoch": 1.1099531005732153,
      "grad_norm": 0.14751268923282623,
      "learning_rate": 8.707290361083107e-05,
      "loss": 0.0765,
      "step": 3550
    },
    {
      "epoch": 1.1177696717040124,
      "grad_norm": 0.1443415880203247,
      "learning_rate": 8.581864075097144e-05,
      "loss": 0.0557,
      "step": 3575
    },
    {
      "epoch": 1.1255862428348098,
      "grad_norm": 0.14357227087020874,
      "learning_rate": 8.456665062319742e-05,
      "loss": 0.0648,
      "step": 3600
    },
    {
      "epoch": 1.1334028139656072,
      "grad_norm": 0.1056608185172081,
      "learning_rate": 8.33171338738706e-05,
      "loss": 0.0627,
      "step": 3625
    },
    {
      "epoch": 1.1412193850964043,
      "grad_norm": 0.138380229473114,
      "learning_rate": 8.207029075296392e-05,
      "loss": 0.0894,
      "step": 3650
    },
    {
      "epoch": 1.1490359562272017,
      "grad_norm": 0.08892809599637985,
      "learning_rate": 8.082632108196969e-05,
      "loss": 0.0589,
      "step": 3675
    },
    {
      "epoch": 1.156852527357999,
      "grad_norm": 0.08757421374320984,
      "learning_rate": 7.958542422187538e-05,
      "loss": 0.0757,
      "step": 3700
    },
    {
      "epoch": 1.1646690984887962,
      "grad_norm": 0.13425061106681824,
      "learning_rate": 7.834779904121399e-05,
      "loss": 0.0589,
      "step": 3725
    },
    {
      "epoch": 1.1724856696195936,
      "grad_norm": 0.1496785432100296,
      "learning_rate": 7.711364388419278e-05,
      "loss": 0.076,
      "step": 3750
    },
    {
      "epoch": 1.180302240750391,
      "grad_norm": 0.12270303815603256,
      "learning_rate": 7.588315653890629e-05,
      "loss": 0.0578,
      "step": 3775
    },
    {
      "epoch": 1.188118811881188,
      "grad_norm": 0.11311302334070206,
      "learning_rate": 7.465653420563845e-05,
      "loss": 0.0634,
      "step": 3800
    },
    {
      "epoch": 1.1959353830119854,
      "grad_norm": 0.13983571529388428,
      "learning_rate": 7.343397346525888e-05,
      "loss": 0.0558,
      "step": 3825
    },
    {
      "epoch": 1.2037519541427826,
      "grad_norm": 0.13892263174057007,
      "learning_rate": 7.221567024771849e-05,
      "loss": 0.0699,
      "step": 3850
    },
    {
      "epoch": 1.21156852527358,
      "grad_norm": 0.11069196462631226,
      "learning_rate": 7.100181980064937e-05,
      "loss": 0.0471,
      "step": 3875
    },
    {
      "epoch": 1.2193850964043773,
      "grad_norm": 0.11397205293178558,
      "learning_rate": 6.979261665807389e-05,
      "loss": 0.0794,
      "step": 3900
    },
    {
      "epoch": 1.2272016675351747,
      "grad_norm": 0.08246912062168121,
      "learning_rate": 6.858825460922849e-05,
      "loss": 0.0548,
      "step": 3925
    },
    {
      "epoch": 1.2350182386659718,
      "grad_norm": 0.1177457794547081,
      "learning_rate": 6.738892666750651e-05,
      "loss": 0.0708,
      "step": 3950
    },
    {
      "epoch": 1.2428348097967692,
      "grad_norm": 0.07440993189811707,
      "learning_rate": 6.619482503952559e-05,
      "loss": 0.0384,
      "step": 3975
    },
    {
      "epoch": 1.2506513809275663,
      "grad_norm": 0.14986029267311096,
      "learning_rate": 6.500614109432419e-05,
      "loss": 0.0727,
      "step": 4000
    },
    {
      "epoch": 1.2584679520583637,
      "grad_norm": 0.11996316909790039,
      "learning_rate": 6.382306533269238e-05,
      "loss": 0.057,
      "step": 4025
    },
    {
      "epoch": 1.266284523189161,
      "grad_norm": 0.12583588063716888,
      "learning_rate": 6.264578735664194e-05,
      "loss": 0.072,
      "step": 4050
    },
    {
      "epoch": 1.2741010943199584,
      "grad_norm": 0.20531374216079712,
      "learning_rate": 6.147449583902036e-05,
      "loss": 0.0544,
      "step": 4075
    },
    {
      "epoch": 1.2819176654507556,
      "grad_norm": 0.13313372433185577,
      "learning_rate": 6.030937849327356e-05,
      "loss": 0.0564,
      "step": 4100
    },
    {
      "epoch": 1.289734236581553,
      "grad_norm": 0.15436576306819916,
      "learning_rate": 5.91506220433629e-05,
      "loss": 0.0426,
      "step": 4125
    },
    {
      "epoch": 1.29755080771235,
      "grad_norm": 0.1448550671339035,
      "learning_rate": 5.79984121938401e-05,
      "loss": 0.0817,
      "step": 4150
    },
    {
      "epoch": 1.3053673788431475,
      "grad_norm": 0.10370153933763504,
      "learning_rate": 5.6852933600086125e-05,
      "loss": 0.0416,
      "step": 4175
    },
    {
      "epoch": 1.3131839499739448,
      "grad_norm": 0.12043353170156479,
      "learning_rate": 5.5714369838717874e-05,
      "loss": 0.0753,
      "step": 4200
    },
    {
      "epoch": 1.321000521104742,
      "grad_norm": 0.1162615641951561,
      "learning_rate": 5.4582903378167716e-05,
      "loss": 0.053,
      "step": 4225
    },
    {
      "epoch": 1.3288170922355393,
      "grad_norm": 0.1076437309384346,
      "learning_rate": 5.3458715549440984e-05,
      "loss": 0.093,
      "step": 4250
    },
    {
      "epoch": 1.3366336633663367,
      "grad_norm": 0.0468624122440815,
      "learning_rate": 5.234198651705527e-05,
      "loss": 0.0552,
      "step": 4275
    },
    {
      "epoch": 1.3444502344971339,
      "grad_norm": 0.17811940610408783,
      "learning_rate": 5.12328952501671e-05,
      "loss": 0.0707,
      "step": 4300
    },
    {
      "epoch": 1.3522668056279312,
      "grad_norm": 0.11843479424715042,
      "learning_rate": 5.013161949388993e-05,
      "loss": 0.0478,
      "step": 4325
    },
    {
      "epoch": 1.3600833767587286,
      "grad_norm": 0.14972515404224396,
      "learning_rate": 4.903833574080825e-05,
      "loss": 0.073,
      "step": 4350
    },
    {
      "epoch": 1.3678999478895257,
      "grad_norm": 0.05959334224462509,
      "learning_rate": 4.795321920269279e-05,
      "loss": 0.0504,
      "step": 4375
    },
    {
      "epoch": 1.375716519020323,
      "grad_norm": 0.11737193167209625,
      "learning_rate": 4.687644378242044e-05,
      "loss": 0.0532,
      "step": 4400
    },
    {
      "epoch": 1.3835330901511202,
      "grad_norm": 0.10131950676441193,
      "learning_rate": 4.580818204610458e-05,
      "loss": 0.0488,
      "step": 4425
    },
    {
      "epoch": 1.3913496612819176,
      "grad_norm": 0.12758570909500122,
      "learning_rate": 4.4748605195438976e-05,
      "loss": 0.0742,
      "step": 4450
    },
    {
      "epoch": 1.399166232412715,
      "grad_norm": 0.09582394361495972,
      "learning_rate": 4.36978830402608e-05,
      "loss": 0.055,
      "step": 4475
    },
    {
      "epoch": 1.4069828035435124,
      "grad_norm": 0.13481608033180237,
      "learning_rate": 4.265618397133674e-05,
      "loss": 0.0738,
      "step": 4500
    },
    {
      "epoch": 1.4147993746743095,
      "grad_norm": 0.05680245906114578,
      "learning_rate": 4.162367493337601e-05,
      "loss": 0.0433,
      "step": 4525
    },
    {
      "epoch": 1.4226159458051069,
      "grad_norm": 0.1570988893508911,
      "learning_rate": 4.060052139827582e-05,
      "loss": 0.0715,
      "step": 4550
    },
    {
      "epoch": 1.430432516935904,
      "grad_norm": 0.09380832314491272,
      "learning_rate": 3.958688733860237e-05,
      "loss": 0.0405,
      "step": 4575
    },
    {
      "epoch": 1.4382490880667014,
      "grad_norm": 0.16131095588207245,
      "learning_rate": 3.858293520131221e-05,
      "loss": 0.056,
      "step": 4600
    },
    {
      "epoch": 1.4460656591974987,
      "grad_norm": 0.06745059788227081,
      "learning_rate": 3.758882588171837e-05,
      "loss": 0.0476,
      "step": 4625
    },
    {
      "epoch": 1.453882230328296,
      "grad_norm": 0.1174284964799881,
      "learning_rate": 3.660471869770474e-05,
      "loss": 0.0599,
      "step": 4650
    },
    {
      "epoch": 1.4616988014590933,
      "grad_norm": 0.09241286665201187,
      "learning_rate": 3.563077136419373e-05,
      "loss": 0.0528,
      "step": 4675
    },
    {
      "epoch": 1.4695153725898906,
      "grad_norm": 0.1354350745677948,
      "learning_rate": 3.466713996787039e-05,
      "loss": 0.0678,
      "step": 4700
    },
    {
      "epoch": 1.4773319437206878,
      "grad_norm": 0.11426115781068802,
      "learning_rate": 3.371397894216766e-05,
      "loss": 0.0609,
      "step": 4725
    },
    {
      "epoch": 1.4851485148514851,
      "grad_norm": 0.11279243230819702,
      "learning_rate": 3.277144104251669e-05,
      "loss": 0.0582,
      "step": 4750
    },
    {
      "epoch": 1.4929650859822825,
      "grad_norm": 0.12732049822807312,
      "learning_rate": 3.183967732186582e-05,
      "loss": 0.0368,
      "step": 4775
    },
    {
      "epoch": 1.5007816571130799,
      "grad_norm": 0.10426943004131317,
      "learning_rate": 3.0918837106472686e-05,
      "loss": 0.0724,
      "step": 4800
    },
    {
      "epoch": 1.508598228243877,
      "grad_norm": 0.1450219303369522,
      "learning_rate": 3.0009067971972716e-05,
      "loss": 0.0445,
      "step": 4825
    },
    {
      "epoch": 1.5164147993746742,
      "grad_norm": 0.12447300553321838,
      "learning_rate": 2.9110515719728594e-05,
      "loss": 0.0737,
      "step": 4850
    },
    {
      "epoch": 1.5242313705054715,
      "grad_norm": 0.10895777493715286,
      "learning_rate": 2.8223324353463644e-05,
      "loss": 0.0431,
      "step": 4875
    },
    {
      "epoch": 1.532047941636269,
      "grad_norm": 0.09013832360506058,
      "learning_rate": 2.73476360561837e-05,
      "loss": 0.0721,
      "step": 4900
    },
    {
      "epoch": 1.5398645127670663,
      "grad_norm": 0.07389712333679199,
      "learning_rate": 2.6483591167390407e-05,
      "loss": 0.029,
      "step": 4925
    },
    {
      "epoch": 1.5476810838978636,
      "grad_norm": 0.10212524980306625,
      "learning_rate": 2.5631328160590318e-05,
      "loss": 0.0803,
      "step": 4950
    },
    {
      "epoch": 1.5554976550286608,
      "grad_norm": 0.08793440461158752,
      "learning_rate": 2.479098362110267e-05,
      "loss": 0.0377,
      "step": 4975
    },
    {
      "epoch": 1.563314226159458,
      "grad_norm": 0.13979513943195343,
      "learning_rate": 2.3962692224170114e-05,
      "loss": 0.044,
      "step": 5000
    },
    {
      "epoch": 1.5711307972902553,
      "grad_norm": 0.06280594319105148,
      "learning_rate": 2.3146586713375395e-05,
      "loss": 0.0436,
      "step": 5025
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.08560126274824142,
      "learning_rate": 2.2342797879367418e-05,
      "loss": 0.0721,
      "step": 5050
    },
    {
      "epoch": 1.58676393955185,
      "grad_norm": 0.15116173028945923,
      "learning_rate": 2.155145453890076e-05,
      "loss": 0.065,
      "step": 5075
    },
    {
      "epoch": 1.5945805106826472,
      "grad_norm": 0.1250026822090149,
      "learning_rate": 2.0772683514191004e-05,
      "loss": 0.0728,
      "step": 5100
    },
    {
      "epoch": 1.6023970818134445,
      "grad_norm": 0.042572472244501114,
      "learning_rate": 2.0006609612590142e-05,
      "loss": 0.0486,
      "step": 5125
    },
    {
      "epoch": 1.6102136529442417,
      "grad_norm": 0.1309526115655899,
      "learning_rate": 1.9253355606584655e-05,
      "loss": 0.0669,
      "step": 5150
    },
    {
      "epoch": 1.618030224075039,
      "grad_norm": 0.12829063832759857,
      "learning_rate": 1.851304221411967e-05,
      "loss": 0.0458,
      "step": 5175
    },
    {
      "epoch": 1.6258467952058364,
      "grad_norm": 0.0859890878200531,
      "learning_rate": 1.778578807925253e-05,
      "loss": 0.0731,
      "step": 5200
    },
    {
      "epoch": 1.6336633663366338,
      "grad_norm": 0.0731671154499054,
      "learning_rate": 1.707170975313879e-05,
      "loss": 0.0416,
      "step": 5225
    },
    {
      "epoch": 1.641479937467431,
      "grad_norm": 0.1356511265039444,
      "learning_rate": 1.6370921675353223e-05,
      "loss": 0.0706,
      "step": 5250
    },
    {
      "epoch": 1.6492965085982283,
      "grad_norm": 0.035815607756376266,
      "learning_rate": 1.568353615554985e-05,
      "loss": 0.041,
      "step": 5275
    },
    {
      "epoch": 1.6571130797290254,
      "grad_norm": 0.13565154373645782,
      "learning_rate": 1.5009663355462655e-05,
      "loss": 0.0628,
      "step": 5300
    },
    {
      "epoch": 1.6649296508598228,
      "grad_norm": 0.04281824454665184,
      "learning_rate": 1.4349411271251134e-05,
      "loss": 0.0394,
      "step": 5325
    },
    {
      "epoch": 1.6727462219906202,
      "grad_norm": 0.12670378386974335,
      "learning_rate": 1.3702885716192348e-05,
      "loss": 0.046,
      "step": 5350
    },
    {
      "epoch": 1.6805627931214175,
      "grad_norm": 0.12649276852607727,
      "learning_rate": 1.3070190303723352e-05,
      "loss": 0.0362,
      "step": 5375
    },
    {
      "epoch": 1.6883793642522147,
      "grad_norm": 0.11440331488847733,
      "learning_rate": 1.2451426430835733e-05,
      "loss": 0.0658,
      "step": 5400
    },
    {
      "epoch": 1.6961959353830118,
      "grad_norm": 0.1305019110441208,
      "learning_rate": 1.1846693261825525e-05,
      "loss": 0.0436,
      "step": 5425
    },
    {
      "epoch": 1.7040125065138092,
      "grad_norm": 0.1532101333141327,
      "learning_rate": 1.1256087712401087e-05,
      "loss": 0.0737,
      "step": 5450
    },
    {
      "epoch": 1.7118290776446066,
      "grad_norm": 0.07082261145114899,
      "learning_rate": 1.0679704434151016e-05,
      "loss": 0.0425,
      "step": 5475
    },
    {
      "epoch": 1.719645648775404,
      "grad_norm": 0.1538669317960739,
      "learning_rate": 1.0117635799375291e-05,
      "loss": 0.0626,
      "step": 5500
    }
  ],
  "logging_steps": 25,
  "max_steps": 6396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.969493694742528e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
