{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.806866091146356,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015057217426219635,
      "grad_norm": 0.2961890697479248,
      "learning_rate": 5e-05,
      "loss": 1.379,
      "step": 25
    },
    {
      "epoch": 0.03011443485243927,
      "grad_norm": 0.6636962294578552,
      "learning_rate": 0.0001,
      "loss": 1.4167,
      "step": 50
    },
    {
      "epoch": 0.0451716522786589,
      "grad_norm": 0.21651805937290192,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.0197,
      "step": 75
    },
    {
      "epoch": 0.06022886970487854,
      "grad_norm": 0.1863177865743637,
      "learning_rate": 0.0002,
      "loss": 1.0776,
      "step": 100
    },
    {
      "epoch": 0.07528608713109818,
      "grad_norm": 0.097108393907547,
      "learning_rate": 0.00019997025482747441,
      "loss": 0.9272,
      "step": 125
    },
    {
      "epoch": 0.0903433045573178,
      "grad_norm": 0.17452095448970795,
      "learning_rate": 0.00019988103700540344,
      "loss": 1.0311,
      "step": 150
    },
    {
      "epoch": 0.10540052198353744,
      "grad_norm": 0.10890351235866547,
      "learning_rate": 0.0001997323996097772,
      "loss": 0.9086,
      "step": 175
    },
    {
      "epoch": 0.12045773940975708,
      "grad_norm": 0.3654226064682007,
      "learning_rate": 0.00019952443106549533,
      "loss": 1.0017,
      "step": 200
    },
    {
      "epoch": 0.13551495683597672,
      "grad_norm": 0.10100015252828598,
      "learning_rate": 0.00019925725509376235,
      "loss": 0.9648,
      "step": 225
    },
    {
      "epoch": 0.15057217426219635,
      "grad_norm": 0.1506478190422058,
      "learning_rate": 0.0001989310306384858,
      "loss": 0.991,
      "step": 250
    },
    {
      "epoch": 0.16562939168841598,
      "grad_norm": 0.11695495247840881,
      "learning_rate": 0.00019854595177171968,
      "loss": 0.9349,
      "step": 275
    },
    {
      "epoch": 0.1806866091146356,
      "grad_norm": 0.18351790308952332,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.9823,
      "step": 300
    },
    {
      "epoch": 0.19574382654085526,
      "grad_norm": 0.09779483824968338,
      "learning_rate": 0.00019760018201911433,
      "loss": 0.9479,
      "step": 325
    },
    {
      "epoch": 0.21080104396707489,
      "grad_norm": 0.16228154301643372,
      "learning_rate": 0.0001970400537749643,
      "loss": 0.9969,
      "step": 350
    },
    {
      "epoch": 0.2258582613932945,
      "grad_norm": 0.1045755073428154,
      "learning_rate": 0.00019642219606798566,
      "loss": 0.941,
      "step": 375
    },
    {
      "epoch": 0.24091547881951417,
      "grad_norm": 0.1740424782037735,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.9642,
      "step": 400
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 0.14508551359176636,
      "learning_rate": 0.00019501479665306047,
      "loss": 0.928,
      "step": 425
    },
    {
      "epoch": 0.27102991367195345,
      "grad_norm": 0.14822742342948914,
      "learning_rate": 0.00019422609221188207,
      "loss": 0.9982,
      "step": 450
    },
    {
      "epoch": 0.2860871310981731,
      "grad_norm": 0.10625546425580978,
      "learning_rate": 0.0001933813323433186,
      "loss": 0.9278,
      "step": 475
    },
    {
      "epoch": 0.3011443485243927,
      "grad_norm": 0.18999390304088593,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.9541,
      "step": 500
    },
    {
      "epoch": 0.31620156595061233,
      "grad_norm": 0.10875333845615387,
      "learning_rate": 0.00019152568957487708,
      "loss": 0.9557,
      "step": 525
    },
    {
      "epoch": 0.33125878337683196,
      "grad_norm": 0.17320197820663452,
      "learning_rate": 0.00019051591060328496,
      "loss": 0.9875,
      "step": 550
    },
    {
      "epoch": 0.3463160008030516,
      "grad_norm": 0.10924995690584183,
      "learning_rate": 0.0001894522834041487,
      "loss": 0.8763,
      "step": 575
    },
    {
      "epoch": 0.3613732182292712,
      "grad_norm": 0.17118243873119354,
      "learning_rate": 0.00018833544073295917,
      "loss": 1.0123,
      "step": 600
    },
    {
      "epoch": 0.3764304356554909,
      "grad_norm": 0.1365085393190384,
      "learning_rate": 0.00018716604700327514,
      "loss": 0.8976,
      "step": 625
    },
    {
      "epoch": 0.3914876530817105,
      "grad_norm": 0.14629442989826202,
      "learning_rate": 0.00018594479789146138,
      "loss": 0.9742,
      "step": 650
    },
    {
      "epoch": 0.40654487050793015,
      "grad_norm": 0.1184087023139,
      "learning_rate": 0.00018467241992282843,
      "loss": 0.9144,
      "step": 675
    },
    {
      "epoch": 0.42160208793414977,
      "grad_norm": 0.14778879284858704,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.9126,
      "step": 700
    },
    {
      "epoch": 0.4366593053603694,
      "grad_norm": 0.13982625305652618,
      "learning_rate": 0.00018197733514970654,
      "loss": 0.9024,
      "step": 725
    },
    {
      "epoch": 0.451716522786589,
      "grad_norm": 0.19106797873973846,
      "learning_rate": 0.00018055623166044854,
      "loss": 0.8939,
      "step": 750
    },
    {
      "epoch": 0.46677374021280865,
      "grad_norm": 0.1282384991645813,
      "learning_rate": 0.0001790872049910155,
      "loss": 0.908,
      "step": 775
    },
    {
      "epoch": 0.48183095763902833,
      "grad_norm": 0.1433194875717163,
      "learning_rate": 0.000177571129070442,
      "loss": 0.9319,
      "step": 800
    },
    {
      "epoch": 0.49688817506524796,
      "grad_norm": 0.13306665420532227,
      "learning_rate": 0.00017600890581752435,
      "loss": 0.8449,
      "step": 825
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 0.20412631332874298,
      "learning_rate": 0.0001744014646042663,
      "loss": 0.9463,
      "step": 850
    },
    {
      "epoch": 0.5270026099176872,
      "grad_norm": 0.11858269572257996,
      "learning_rate": 0.00017274976170299198,
      "loss": 0.8409,
      "step": 875
    },
    {
      "epoch": 0.5420598273439069,
      "grad_norm": 0.1924513727426529,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.9119,
      "step": 900
    },
    {
      "epoch": 0.5571170447701265,
      "grad_norm": 0.1166309118270874,
      "learning_rate": 0.00016931752699829208,
      "loss": 0.8816,
      "step": 925
    },
    {
      "epoch": 0.5721742621963462,
      "grad_norm": 0.17298103868961334,
      "learning_rate": 0.00016753903704313527,
      "loss": 0.9523,
      "step": 950
    },
    {
      "epoch": 0.5872314796225657,
      "grad_norm": 0.1646077185869217,
      "learning_rate": 0.00016572036788179727,
      "loss": 0.8832,
      "step": 975
    },
    {
      "epoch": 0.6022886970487854,
      "grad_norm": 0.2023872435092926,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.946,
      "step": 1000
    },
    {
      "epoch": 0.617345914475005,
      "grad_norm": 0.1416621208190918,
      "learning_rate": 0.00016196684292991826,
      "loss": 0.8679,
      "step": 1025
    },
    {
      "epoch": 0.6324031319012247,
      "grad_norm": 0.16117389500141144,
      "learning_rate": 0.00016003422012432275,
      "loss": 0.8826,
      "step": 1050
    },
    {
      "epoch": 0.6474603493274443,
      "grad_norm": 0.12506458163261414,
      "learning_rate": 0.0001580658827540265,
      "loss": 0.8674,
      "step": 1075
    },
    {
      "epoch": 0.6625175667536639,
      "grad_norm": 0.2026461809873581,
      "learning_rate": 0.00015606300178972287,
      "loss": 0.8971,
      "step": 1100
    },
    {
      "epoch": 0.6775747841798836,
      "grad_norm": 0.15363118052482605,
      "learning_rate": 0.00015402676875220846,
      "loss": 0.887,
      "step": 1125
    },
    {
      "epoch": 0.6926320016061032,
      "grad_norm": 0.2032802402973175,
      "learning_rate": 0.00015195839500354335,
      "loss": 0.9476,
      "step": 1150
    },
    {
      "epoch": 0.7076892190323228,
      "grad_norm": 0.13772650063037872,
      "learning_rate": 0.00014985911102640762,
      "loss": 0.8052,
      "step": 1175
    },
    {
      "epoch": 0.7227464364585424,
      "grad_norm": 0.15616199374198914,
      "learning_rate": 0.00014773016569208283,
      "loss": 0.9406,
      "step": 1200
    },
    {
      "epoch": 0.7378036538847621,
      "grad_norm": 0.13323275744915009,
      "learning_rate": 0.00014557282551749427,
      "loss": 0.8766,
      "step": 1225
    },
    {
      "epoch": 0.7528608713109818,
      "grad_norm": 0.1934213787317276,
      "learning_rate": 0.00014338837391175582,
      "loss": 0.9281,
      "step": 1250
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 0.14100565016269684,
      "learning_rate": 0.00014117811041266517,
      "loss": 0.8373,
      "step": 1275
    },
    {
      "epoch": 0.782975306163421,
      "grad_norm": 0.1811005026102066,
      "learning_rate": 0.00013894334991360448,
      "loss": 0.9116,
      "step": 1300
    },
    {
      "epoch": 0.7980325235896406,
      "grad_norm": 0.13991102576255798,
      "learning_rate": 0.00013668542188130566,
      "loss": 0.8609,
      "step": 1325
    },
    {
      "epoch": 0.8130897410158603,
      "grad_norm": 0.20529428124427795,
      "learning_rate": 0.0001344056695649462,
      "loss": 0.919,
      "step": 1350
    },
    {
      "epoch": 0.8281469584420799,
      "grad_norm": 0.13550446927547455,
      "learning_rate": 0.0001321054491970454,
      "loss": 0.8718,
      "step": 1375
    },
    {
      "epoch": 0.8432041758682995,
      "grad_norm": 0.18698446452617645,
      "learning_rate": 0.000129786129186637,
      "loss": 0.875,
      "step": 1400
    },
    {
      "epoch": 0.8582613932945192,
      "grad_norm": 0.12764360010623932,
      "learning_rate": 0.0001274490893051981,
      "loss": 0.8737,
      "step": 1425
    },
    {
      "epoch": 0.8733186107207388,
      "grad_norm": 0.1777505725622177,
      "learning_rate": 0.00012509571986581814,
      "loss": 0.8983,
      "step": 1450
    },
    {
      "epoch": 0.8883758281469585,
      "grad_norm": 0.13159339129924774,
      "learning_rate": 0.00012272742089609694,
      "loss": 0.8742,
      "step": 1475
    },
    {
      "epoch": 0.903433045573178,
      "grad_norm": 0.18094375729560852,
      "learning_rate": 0.0001203456013052634,
      "loss": 0.887,
      "step": 1500
    },
    {
      "epoch": 0.9184902629993977,
      "grad_norm": 0.13028877973556519,
      "learning_rate": 0.00011795167804601061,
      "loss": 0.8497,
      "step": 1525
    },
    {
      "epoch": 0.9335474804256173,
      "grad_norm": 0.19536074995994568,
      "learning_rate": 0.0001155470752715458,
      "loss": 0.8922,
      "step": 1550
    },
    {
      "epoch": 0.948604697851837,
      "grad_norm": 0.13831555843353271,
      "learning_rate": 0.00011313322348835658,
      "loss": 0.8672,
      "step": 1575
    },
    {
      "epoch": 0.9636619152780567,
      "grad_norm": 0.23589330911636353,
      "learning_rate": 0.00011071155870519777,
      "loss": 0.8999,
      "step": 1600
    },
    {
      "epoch": 0.9787191327042762,
      "grad_norm": 0.11648174375295639,
      "learning_rate": 0.00010828352157880488,
      "loss": 0.8537,
      "step": 1625
    },
    {
      "epoch": 0.9937763501304959,
      "grad_norm": 0.21864713728427887,
      "learning_rate": 0.0001058505565568424,
      "loss": 0.8811,
      "step": 1650
    },
    {
      "epoch": 1.0088335675567155,
      "grad_norm": 0.11655538529157639,
      "learning_rate": 0.00010341411101859679,
      "loss": 0.7987,
      "step": 1675
    },
    {
      "epoch": 1.023890784982935,
      "grad_norm": 0.15366236865520477,
      "learning_rate": 0.00010097563441392581,
      "loss": 0.8628,
      "step": 1700
    },
    {
      "epoch": 1.0389480024091549,
      "grad_norm": 0.12200002372264862,
      "learning_rate": 9.853657740097558e-05,
      "loss": 0.829,
      "step": 1725
    },
    {
      "epoch": 1.0540052198353744,
      "grad_norm": 0.16997253894805908,
      "learning_rate": 9.6098390983179e-05,
      "loss": 0.8578,
      "step": 1750
    },
    {
      "epoch": 1.069062437261594,
      "grad_norm": 0.13481763005256653,
      "learning_rate": 9.366252564604913e-05,
      "loss": 0.7821,
      "step": 1775
    },
    {
      "epoch": 1.0841196546878138,
      "grad_norm": 0.14238467812538147,
      "learning_rate": 9.123043049427995e-05,
      "loss": 0.8117,
      "step": 1800
    },
    {
      "epoch": 1.0991768721140334,
      "grad_norm": 0.14123357832431793,
      "learning_rate": 8.880355238966923e-05,
      "loss": 0.8182,
      "step": 1825
    },
    {
      "epoch": 1.114234089540253,
      "grad_norm": 0.17640164494514465,
      "learning_rate": 8.638333509037536e-05,
      "loss": 0.8107,
      "step": 1850
    },
    {
      "epoch": 1.1292913069664725,
      "grad_norm": 0.1663886159658432,
      "learning_rate": 8.39712183920207e-05,
      "loss": 0.8171,
      "step": 1875
    },
    {
      "epoch": 1.1443485243926923,
      "grad_norm": 0.16230948269367218,
      "learning_rate": 8.156863727115211e-05,
      "loss": 0.9097,
      "step": 1900
    },
    {
      "epoch": 1.1594057418189119,
      "grad_norm": 0.15511223673820496,
      "learning_rate": 7.91770210315685e-05,
      "loss": 0.8354,
      "step": 1925
    },
    {
      "epoch": 1.1744629592451314,
      "grad_norm": 0.18210750818252563,
      "learning_rate": 7.679779245402321e-05,
      "loss": 0.8227,
      "step": 1950
    },
    {
      "epoch": 1.1895201766713512,
      "grad_norm": 0.15813834965229034,
      "learning_rate": 7.443236694980649e-05,
      "loss": 0.8229,
      "step": 1975
    },
    {
      "epoch": 1.2045773940975708,
      "grad_norm": 0.21685752272605896,
      "learning_rate": 7.208215171871277e-05,
      "loss": 0.8381,
      "step": 2000
    },
    {
      "epoch": 1.2196346115237904,
      "grad_norm": 0.15697121620178223,
      "learning_rate": 6.974854491189243e-05,
      "loss": 0.8254,
      "step": 2025
    },
    {
      "epoch": 1.23469182895001,
      "grad_norm": 0.16922031342983246,
      "learning_rate": 6.743293480008702e-05,
      "loss": 0.8422,
      "step": 2050
    },
    {
      "epoch": 1.2497490463762297,
      "grad_norm": 0.14199766516685486,
      "learning_rate": 6.513669894774209e-05,
      "loss": 0.8072,
      "step": 2075
    },
    {
      "epoch": 1.2648062638024493,
      "grad_norm": 0.18612296879291534,
      "learning_rate": 6.286120339348935e-05,
      "loss": 0.7935,
      "step": 2100
    },
    {
      "epoch": 1.2798634812286689,
      "grad_norm": 0.13075241446495056,
      "learning_rate": 6.060780183748567e-05,
      "loss": 0.8233,
      "step": 2125
    },
    {
      "epoch": 1.2949206986548885,
      "grad_norm": 0.18149437010288239,
      "learning_rate": 5.8377834836092136e-05,
      "loss": 0.8147,
      "step": 2150
    },
    {
      "epoch": 1.3099779160811083,
      "grad_norm": 0.1835154891014099,
      "learning_rate": 5.617262900437239e-05,
      "loss": 0.8132,
      "step": 2175
    },
    {
      "epoch": 1.3250351335073278,
      "grad_norm": 0.1953057050704956,
      "learning_rate": 5.399349622688479e-05,
      "loss": 0.8202,
      "step": 2200
    },
    {
      "epoch": 1.3400923509335474,
      "grad_norm": 0.14253491163253784,
      "learning_rate": 5.184173287723781e-05,
      "loss": 0.8105,
      "step": 2225
    },
    {
      "epoch": 1.3551495683597672,
      "grad_norm": 0.20112018287181854,
      "learning_rate": 4.9718619046872825e-05,
      "loss": 0.8153,
      "step": 2250
    },
    {
      "epoch": 1.3702067857859868,
      "grad_norm": 0.18404234945774078,
      "learning_rate": 4.762541778353337e-05,
      "loss": 0.7961,
      "step": 2275
    },
    {
      "epoch": 1.3852640032122063,
      "grad_norm": 0.18910712003707886,
      "learning_rate": 4.556337433987359e-05,
      "loss": 0.8449,
      "step": 2300
    },
    {
      "epoch": 1.4003212206384261,
      "grad_norm": 0.15517272055149078,
      "learning_rate": 4.35337154326532e-05,
      "loss": 0.8409,
      "step": 2325
    },
    {
      "epoch": 1.4153784380646457,
      "grad_norm": 0.19545353949069977,
      "learning_rate": 4.153764851295954e-05,
      "loss": 0.8155,
      "step": 2350
    },
    {
      "epoch": 1.4304356554908653,
      "grad_norm": 0.15216684341430664,
      "learning_rate": 3.9576361047890554e-05,
      "loss": 0.7745,
      "step": 2375
    },
    {
      "epoch": 1.445492872917085,
      "grad_norm": 0.2118316888809204,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 0.8245,
      "step": 2400
    },
    {
      "epoch": 1.4605500903433046,
      "grad_norm": 0.1459702104330063,
      "learning_rate": 3.5762770203811225e-05,
      "loss": 0.7775,
      "step": 2425
    },
    {
      "epoch": 1.4756073077695242,
      "grad_norm": 0.2232191413640976,
      "learning_rate": 3.3912735543152864e-05,
      "loss": 0.8474,
      "step": 2450
    },
    {
      "epoch": 1.4906645251957438,
      "grad_norm": 0.14688050746917725,
      "learning_rate": 3.2102016424154766e-05,
      "loss": 0.801,
      "step": 2475
    },
    {
      "epoch": 1.5057217426219633,
      "grad_norm": 0.19938841462135315,
      "learning_rate": 3.033169004986873e-05,
      "loss": 0.8058,
      "step": 2500
    },
    {
      "epoch": 1.5207789600481831,
      "grad_norm": 0.13868874311447144,
      "learning_rate": 2.8602809593563364e-05,
      "loss": 0.7847,
      "step": 2525
    },
    {
      "epoch": 1.5358361774744027,
      "grad_norm": 0.16181352734565735,
      "learning_rate": 2.691640357218759e-05,
      "loss": 0.7906,
      "step": 2550
    },
    {
      "epoch": 1.5508933949006223,
      "grad_norm": 0.16018016636371613,
      "learning_rate": 2.5273475234502565e-05,
      "loss": 0.7636,
      "step": 2575
    },
    {
      "epoch": 1.565950612326842,
      "grad_norm": 0.17814849317073822,
      "learning_rate": 2.367500196424529e-05,
      "loss": 0.8252,
      "step": 2600
    },
    {
      "epoch": 1.5810078297530616,
      "grad_norm": 0.1486576795578003,
      "learning_rate": 2.212193469867979e-05,
      "loss": 0.7923,
      "step": 2625
    },
    {
      "epoch": 1.5960650471792812,
      "grad_norm": 0.20669296383857727,
      "learning_rate": 2.0615197362881234e-05,
      "loss": 0.8027,
      "step": 2650
    },
    {
      "epoch": 1.611122264605501,
      "grad_norm": 0.15332527458667755,
      "learning_rate": 1.9155686320089684e-05,
      "loss": 0.8083,
      "step": 2675
    },
    {
      "epoch": 1.6261794820317206,
      "grad_norm": 0.23270639777183533,
      "learning_rate": 1.774426983846058e-05,
      "loss": 0.7835,
      "step": 2700
    },
    {
      "epoch": 1.6412366994579402,
      "grad_norm": 0.15028224885463715,
      "learning_rate": 1.638178757452894e-05,
      "loss": 0.8086,
      "step": 2725
    },
    {
      "epoch": 1.65629391688416,
      "grad_norm": 0.18271537125110626,
      "learning_rate": 1.5069050073694813e-05,
      "loss": 0.8212,
      "step": 2750
    },
    {
      "epoch": 1.6713511343103793,
      "grad_norm": 0.16216376423835754,
      "learning_rate": 1.3806838288027113e-05,
      "loss": 0.7731,
      "step": 2775
    },
    {
      "epoch": 1.686408351736599,
      "grad_norm": 0.1994326263666153,
      "learning_rate": 1.259590311167238e-05,
      "loss": 0.8273,
      "step": 2800
    },
    {
      "epoch": 1.7014655691628187,
      "grad_norm": 0.17495936155319214,
      "learning_rate": 1.1436964934145389e-05,
      "loss": 0.8398,
      "step": 2825
    },
    {
      "epoch": 1.7165227865890382,
      "grad_norm": 0.20191985368728638,
      "learning_rate": 1.0330713211766863e-05,
      "loss": 0.8277,
      "step": 2850
    },
    {
      "epoch": 1.731580004015258,
      "grad_norm": 0.14184322953224182,
      "learning_rate": 9.27780605750359e-06,
      "loss": 0.7539,
      "step": 2875
    },
    {
      "epoch": 1.7466372214414776,
      "grad_norm": 0.27268797159194946,
      "learning_rate": 8.278869849454718e-06,
      "loss": 0.8014,
      "step": 2900
    },
    {
      "epoch": 1.7616944388676972,
      "grad_norm": 0.1434682309627533,
      "learning_rate": 7.3344988582172315e-06,
      "loss": 0.8076,
      "step": 2925
    },
    {
      "epoch": 1.776751656293917,
      "grad_norm": 0.200864776968956,
      "learning_rate": 6.4452548933523815e-06,
      "loss": 0.8086,
      "step": 2950
    },
    {
      "epoch": 1.7918088737201365,
      "grad_norm": 0.15919099748134613,
      "learning_rate": 5.611666969163243e-06,
      "loss": 0.7439,
      "step": 2975
    },
    {
      "epoch": 1.806866091146356,
      "grad_norm": 0.21835172176361084,
      "learning_rate": 4.834230989982213e-06,
      "loss": 0.8097,
      "step": 3000
    }
  ],
  "logging_steps": 25,
  "max_steps": 3320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5861633533856973e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
