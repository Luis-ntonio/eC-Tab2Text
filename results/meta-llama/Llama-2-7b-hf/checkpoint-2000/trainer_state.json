{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.2045773940975708,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015057217426219635,
      "grad_norm": 0.11013614386320114,
      "learning_rate": 5e-05,
      "loss": 1.2234,
      "step": 25
    },
    {
      "epoch": 0.03011443485243927,
      "grad_norm": 0.2801661193370819,
      "learning_rate": 0.0001,
      "loss": 1.2797,
      "step": 50
    },
    {
      "epoch": 0.0451716522786589,
      "grad_norm": 0.15786220133304596,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.8691,
      "step": 75
    },
    {
      "epoch": 0.06022886970487854,
      "grad_norm": 0.18243414163589478,
      "learning_rate": 0.0002,
      "loss": 0.9399,
      "step": 100
    },
    {
      "epoch": 0.07528608713109818,
      "grad_norm": 0.19626952707767487,
      "learning_rate": 0.00019997025482747441,
      "loss": 0.7853,
      "step": 125
    },
    {
      "epoch": 0.0903433045573178,
      "grad_norm": 0.20215673744678497,
      "learning_rate": 0.00019988103700540344,
      "loss": 0.8977,
      "step": 150
    },
    {
      "epoch": 0.10540052198353744,
      "grad_norm": 0.19582992792129517,
      "learning_rate": 0.0001997323996097772,
      "loss": 0.7447,
      "step": 175
    },
    {
      "epoch": 0.12045773940975708,
      "grad_norm": 0.22023449838161469,
      "learning_rate": 0.00019952443106549533,
      "loss": 0.8568,
      "step": 200
    },
    {
      "epoch": 0.13551495683597672,
      "grad_norm": 0.12788134813308716,
      "learning_rate": 0.00019925725509376235,
      "loss": 0.8106,
      "step": 225
    },
    {
      "epoch": 0.15057217426219635,
      "grad_norm": 0.20170921087265015,
      "learning_rate": 0.0001989310306384858,
      "loss": 0.8535,
      "step": 250
    },
    {
      "epoch": 0.16562939168841598,
      "grad_norm": 0.1611468642950058,
      "learning_rate": 0.00019854595177171968,
      "loss": 0.7872,
      "step": 275
    },
    {
      "epoch": 0.1806866091146356,
      "grad_norm": 0.2032822221517563,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.846,
      "step": 300
    },
    {
      "epoch": 0.19574382654085526,
      "grad_norm": 0.12180355191230774,
      "learning_rate": 0.00019760018201911433,
      "loss": 0.8082,
      "step": 325
    },
    {
      "epoch": 0.21080104396707489,
      "grad_norm": 0.1579548716545105,
      "learning_rate": 0.0001970400537749643,
      "loss": 0.869,
      "step": 350
    },
    {
      "epoch": 0.2258582613932945,
      "grad_norm": 0.14111171662807465,
      "learning_rate": 0.00019642219606798566,
      "loss": 0.7771,
      "step": 375
    },
    {
      "epoch": 0.24091547881951417,
      "grad_norm": 0.1635938137769699,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.8333,
      "step": 400
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 0.1461314558982849,
      "learning_rate": 0.00019501479665306047,
      "loss": 0.7811,
      "step": 425
    },
    {
      "epoch": 0.27102991367195345,
      "grad_norm": 0.16678526997566223,
      "learning_rate": 0.00019422609221188207,
      "loss": 0.8647,
      "step": 450
    },
    {
      "epoch": 0.2860871310981731,
      "grad_norm": 0.13775776326656342,
      "learning_rate": 0.0001933813323433186,
      "loss": 0.7756,
      "step": 475
    },
    {
      "epoch": 0.3011443485243927,
      "grad_norm": 0.1952275037765503,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.8348,
      "step": 500
    },
    {
      "epoch": 0.31620156595061233,
      "grad_norm": 0.13785801827907562,
      "learning_rate": 0.00019152568957487708,
      "loss": 0.7932,
      "step": 525
    },
    {
      "epoch": 0.33125878337683196,
      "grad_norm": 0.20806820690631866,
      "learning_rate": 0.00019051591060328496,
      "loss": 0.8539,
      "step": 550
    },
    {
      "epoch": 0.3463160008030516,
      "grad_norm": 0.12952503561973572,
      "learning_rate": 0.0001894522834041487,
      "loss": 0.7499,
      "step": 575
    },
    {
      "epoch": 0.3613732182292712,
      "grad_norm": 0.272885799407959,
      "learning_rate": 0.00018833544073295917,
      "loss": 0.8847,
      "step": 600
    },
    {
      "epoch": 0.3764304356554909,
      "grad_norm": 0.15567447245121002,
      "learning_rate": 0.00018716604700327514,
      "loss": 0.7352,
      "step": 625
    },
    {
      "epoch": 0.3914876530817105,
      "grad_norm": 0.22419008612632751,
      "learning_rate": 0.00018594479789146138,
      "loss": 0.8484,
      "step": 650
    },
    {
      "epoch": 0.40654487050793015,
      "grad_norm": 0.19648903608322144,
      "learning_rate": 0.00018467241992282843,
      "loss": 0.748,
      "step": 675
    },
    {
      "epoch": 0.42160208793414977,
      "grad_norm": 0.18287959694862366,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.7728,
      "step": 700
    },
    {
      "epoch": 0.4366593053603694,
      "grad_norm": 0.1666061282157898,
      "learning_rate": 0.00018197733514970654,
      "loss": 0.7555,
      "step": 725
    },
    {
      "epoch": 0.451716522786589,
      "grad_norm": 0.21363303065299988,
      "learning_rate": 0.00018055623166044854,
      "loss": 0.7848,
      "step": 750
    },
    {
      "epoch": 0.46677374021280865,
      "grad_norm": 0.1465834528207779,
      "learning_rate": 0.0001790872049910155,
      "loss": 0.7736,
      "step": 775
    },
    {
      "epoch": 0.48183095763902833,
      "grad_norm": 0.18512332439422607,
      "learning_rate": 0.000177571129070442,
      "loss": 0.8182,
      "step": 800
    },
    {
      "epoch": 0.49688817506524796,
      "grad_norm": 0.13444049656391144,
      "learning_rate": 0.00017600890581752435,
      "loss": 0.6948,
      "step": 825
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 0.21499446034431458,
      "learning_rate": 0.0001744014646042663,
      "loss": 0.8402,
      "step": 850
    },
    {
      "epoch": 0.5270026099176872,
      "grad_norm": 0.11599649488925934,
      "learning_rate": 0.00017274976170299198,
      "loss": 0.7076,
      "step": 875
    },
    {
      "epoch": 0.5420598273439069,
      "grad_norm": 0.1941194385290146,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.7883,
      "step": 900
    },
    {
      "epoch": 0.5571170447701265,
      "grad_norm": 0.14602157473564148,
      "learning_rate": 0.00016931752699829208,
      "loss": 0.7305,
      "step": 925
    },
    {
      "epoch": 0.5721742621963462,
      "grad_norm": 0.19380410015583038,
      "learning_rate": 0.00016753903704313527,
      "loss": 0.8301,
      "step": 950
    },
    {
      "epoch": 0.5872314796225657,
      "grad_norm": 0.1464550793170929,
      "learning_rate": 0.00016572036788179727,
      "loss": 0.7326,
      "step": 975
    },
    {
      "epoch": 0.6022886970487854,
      "grad_norm": 0.232082799077034,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.8177,
      "step": 1000
    },
    {
      "epoch": 0.617345914475005,
      "grad_norm": 0.14724576473236084,
      "learning_rate": 0.00016196684292991826,
      "loss": 0.7258,
      "step": 1025
    },
    {
      "epoch": 0.6324031319012247,
      "grad_norm": 0.1924816071987152,
      "learning_rate": 0.00016003422012432275,
      "loss": 0.7658,
      "step": 1050
    },
    {
      "epoch": 0.6474603493274443,
      "grad_norm": 0.1504662185907364,
      "learning_rate": 0.0001580658827540265,
      "loss": 0.7339,
      "step": 1075
    },
    {
      "epoch": 0.6625175667536639,
      "grad_norm": 0.23490294814109802,
      "learning_rate": 0.00015606300178972287,
      "loss": 0.7822,
      "step": 1100
    },
    {
      "epoch": 0.6775747841798836,
      "grad_norm": 0.13106325268745422,
      "learning_rate": 0.00015402676875220846,
      "loss": 0.7462,
      "step": 1125
    },
    {
      "epoch": 0.6926320016061032,
      "grad_norm": 0.20600776374340057,
      "learning_rate": 0.00015195839500354335,
      "loss": 0.8228,
      "step": 1150
    },
    {
      "epoch": 0.7076892190323228,
      "grad_norm": 0.15069414675235748,
      "learning_rate": 0.00014985911102640762,
      "loss": 0.6746,
      "step": 1175
    },
    {
      "epoch": 0.7227464364585424,
      "grad_norm": 0.17362672090530396,
      "learning_rate": 0.00014773016569208283,
      "loss": 0.822,
      "step": 1200
    },
    {
      "epoch": 0.7378036538847621,
      "grad_norm": 0.15546955168247223,
      "learning_rate": 0.00014557282551749427,
      "loss": 0.7281,
      "step": 1225
    },
    {
      "epoch": 0.7528608713109818,
      "grad_norm": 0.20062895119190216,
      "learning_rate": 0.00014338837391175582,
      "loss": 0.8028,
      "step": 1250
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 0.1566823571920395,
      "learning_rate": 0.00014117811041266517,
      "loss": 0.6655,
      "step": 1275
    },
    {
      "epoch": 0.782975306163421,
      "grad_norm": 0.21891185641288757,
      "learning_rate": 0.00013894334991360448,
      "loss": 0.7721,
      "step": 1300
    },
    {
      "epoch": 0.7980325235896406,
      "grad_norm": 0.1742217242717743,
      "learning_rate": 0.00013668542188130566,
      "loss": 0.7058,
      "step": 1325
    },
    {
      "epoch": 0.8130897410158603,
      "grad_norm": 0.2324668914079666,
      "learning_rate": 0.0001344056695649462,
      "loss": 0.8065,
      "step": 1350
    },
    {
      "epoch": 0.8281469584420799,
      "grad_norm": 0.1624840945005417,
      "learning_rate": 0.0001321054491970454,
      "loss": 0.726,
      "step": 1375
    },
    {
      "epoch": 0.8432041758682995,
      "grad_norm": 0.19276063144207,
      "learning_rate": 0.000129786129186637,
      "loss": 0.765,
      "step": 1400
    },
    {
      "epoch": 0.8582613932945192,
      "grad_norm": 0.14701327681541443,
      "learning_rate": 0.0001274490893051981,
      "loss": 0.7242,
      "step": 1425
    },
    {
      "epoch": 0.8733186107207388,
      "grad_norm": 0.22531239688396454,
      "learning_rate": 0.00012509571986581814,
      "loss": 0.7815,
      "step": 1450
    },
    {
      "epoch": 0.8883758281469585,
      "grad_norm": 0.13347850739955902,
      "learning_rate": 0.00012272742089609694,
      "loss": 0.7253,
      "step": 1475
    },
    {
      "epoch": 0.903433045573178,
      "grad_norm": 0.22945450246334076,
      "learning_rate": 0.0001203456013052634,
      "loss": 0.7562,
      "step": 1500
    },
    {
      "epoch": 0.9184902629993977,
      "grad_norm": 0.12353227287530899,
      "learning_rate": 0.00011795167804601061,
      "loss": 0.697,
      "step": 1525
    },
    {
      "epoch": 0.9335474804256173,
      "grad_norm": 0.18551377952098846,
      "learning_rate": 0.0001155470752715458,
      "loss": 0.7639,
      "step": 1550
    },
    {
      "epoch": 0.948604697851837,
      "grad_norm": 0.14672115445137024,
      "learning_rate": 0.00011313322348835658,
      "loss": 0.6966,
      "step": 1575
    },
    {
      "epoch": 0.9636619152780567,
      "grad_norm": 0.23328624665737152,
      "learning_rate": 0.00011071155870519777,
      "loss": 0.7699,
      "step": 1600
    },
    {
      "epoch": 0.9787191327042762,
      "grad_norm": 0.1494128704071045,
      "learning_rate": 0.00010828352157880488,
      "loss": 0.7112,
      "step": 1625
    },
    {
      "epoch": 0.9937763501304959,
      "grad_norm": 0.24157726764678955,
      "learning_rate": 0.0001058505565568424,
      "loss": 0.7653,
      "step": 1650
    },
    {
      "epoch": 1.0088335675567155,
      "grad_norm": 0.11806879192590714,
      "learning_rate": 0.00010341411101859679,
      "loss": 0.6388,
      "step": 1675
    },
    {
      "epoch": 1.023890784982935,
      "grad_norm": 0.1828938126564026,
      "learning_rate": 0.00010097563441392581,
      "loss": 0.7175,
      "step": 1700
    },
    {
      "epoch": 1.0389480024091549,
      "grad_norm": 0.13239790499210358,
      "learning_rate": 9.853657740097558e-05,
      "loss": 0.6868,
      "step": 1725
    },
    {
      "epoch": 1.0540052198353744,
      "grad_norm": 0.17090122401714325,
      "learning_rate": 9.6098390983179e-05,
      "loss": 0.7274,
      "step": 1750
    },
    {
      "epoch": 1.069062437261594,
      "grad_norm": 0.13684716820716858,
      "learning_rate": 9.366252564604913e-05,
      "loss": 0.6343,
      "step": 1775
    },
    {
      "epoch": 1.0841196546878138,
      "grad_norm": 0.14087924361228943,
      "learning_rate": 9.123043049427995e-05,
      "loss": 0.6825,
      "step": 1800
    },
    {
      "epoch": 1.0991768721140334,
      "grad_norm": 0.15722325444221497,
      "learning_rate": 8.880355238966923e-05,
      "loss": 0.6842,
      "step": 1825
    },
    {
      "epoch": 1.114234089540253,
      "grad_norm": 0.19183367490768433,
      "learning_rate": 8.638333509037536e-05,
      "loss": 0.6774,
      "step": 1850
    },
    {
      "epoch": 1.1292913069664725,
      "grad_norm": 0.1735725998878479,
      "learning_rate": 8.39712183920207e-05,
      "loss": 0.684,
      "step": 1875
    },
    {
      "epoch": 1.1443485243926923,
      "grad_norm": 0.1672748178243637,
      "learning_rate": 8.156863727115211e-05,
      "loss": 0.7696,
      "step": 1900
    },
    {
      "epoch": 1.1594057418189119,
      "grad_norm": 0.15313482284545898,
      "learning_rate": 7.91770210315685e-05,
      "loss": 0.6772,
      "step": 1925
    },
    {
      "epoch": 1.1744629592451314,
      "grad_norm": 0.1883510947227478,
      "learning_rate": 7.679779245402321e-05,
      "loss": 0.6857,
      "step": 1950
    },
    {
      "epoch": 1.1895201766713512,
      "grad_norm": 0.13231804966926575,
      "learning_rate": 7.443236694980649e-05,
      "loss": 0.6857,
      "step": 1975
    },
    {
      "epoch": 1.2045773940975708,
      "grad_norm": 0.21816420555114746,
      "learning_rate": 7.208215171871277e-05,
      "loss": 0.7145,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 3320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.726443695613788e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
