{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9995984742019675,
  "eval_steps": 500,
  "global_step": 3320,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015057217426219635,
      "grad_norm": 0.11013614386320114,
      "learning_rate": 5e-05,
      "loss": 1.2234,
      "step": 25
    },
    {
      "epoch": 0.03011443485243927,
      "grad_norm": 0.2801661193370819,
      "learning_rate": 0.0001,
      "loss": 1.2797,
      "step": 50
    },
    {
      "epoch": 0.0451716522786589,
      "grad_norm": 0.15786220133304596,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.8691,
      "step": 75
    },
    {
      "epoch": 0.06022886970487854,
      "grad_norm": 0.18243414163589478,
      "learning_rate": 0.0002,
      "loss": 0.9399,
      "step": 100
    },
    {
      "epoch": 0.07528608713109818,
      "grad_norm": 0.19626952707767487,
      "learning_rate": 0.00019997025482747441,
      "loss": 0.7853,
      "step": 125
    },
    {
      "epoch": 0.0903433045573178,
      "grad_norm": 0.20215673744678497,
      "learning_rate": 0.00019988103700540344,
      "loss": 0.8977,
      "step": 150
    },
    {
      "epoch": 0.10540052198353744,
      "grad_norm": 0.19582992792129517,
      "learning_rate": 0.0001997323996097772,
      "loss": 0.7447,
      "step": 175
    },
    {
      "epoch": 0.12045773940975708,
      "grad_norm": 0.22023449838161469,
      "learning_rate": 0.00019952443106549533,
      "loss": 0.8568,
      "step": 200
    },
    {
      "epoch": 0.13551495683597672,
      "grad_norm": 0.12788134813308716,
      "learning_rate": 0.00019925725509376235,
      "loss": 0.8106,
      "step": 225
    },
    {
      "epoch": 0.15057217426219635,
      "grad_norm": 0.20170921087265015,
      "learning_rate": 0.0001989310306384858,
      "loss": 0.8535,
      "step": 250
    },
    {
      "epoch": 0.16562939168841598,
      "grad_norm": 0.1611468642950058,
      "learning_rate": 0.00019854595177171968,
      "loss": 0.7872,
      "step": 275
    },
    {
      "epoch": 0.1806866091146356,
      "grad_norm": 0.2032822221517563,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.846,
      "step": 300
    },
    {
      "epoch": 0.19574382654085526,
      "grad_norm": 0.12180355191230774,
      "learning_rate": 0.00019760018201911433,
      "loss": 0.8082,
      "step": 325
    },
    {
      "epoch": 0.21080104396707489,
      "grad_norm": 0.1579548716545105,
      "learning_rate": 0.0001970400537749643,
      "loss": 0.869,
      "step": 350
    },
    {
      "epoch": 0.2258582613932945,
      "grad_norm": 0.14111171662807465,
      "learning_rate": 0.00019642219606798566,
      "loss": 0.7771,
      "step": 375
    },
    {
      "epoch": 0.24091547881951417,
      "grad_norm": 0.1635938137769699,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.8333,
      "step": 400
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 0.1461314558982849,
      "learning_rate": 0.00019501479665306047,
      "loss": 0.7811,
      "step": 425
    },
    {
      "epoch": 0.27102991367195345,
      "grad_norm": 0.16678526997566223,
      "learning_rate": 0.00019422609221188207,
      "loss": 0.8647,
      "step": 450
    },
    {
      "epoch": 0.2860871310981731,
      "grad_norm": 0.13775776326656342,
      "learning_rate": 0.0001933813323433186,
      "loss": 0.7756,
      "step": 475
    },
    {
      "epoch": 0.3011443485243927,
      "grad_norm": 0.1952275037765503,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.8348,
      "step": 500
    },
    {
      "epoch": 0.31620156595061233,
      "grad_norm": 0.13785801827907562,
      "learning_rate": 0.00019152568957487708,
      "loss": 0.7932,
      "step": 525
    },
    {
      "epoch": 0.33125878337683196,
      "grad_norm": 0.20806820690631866,
      "learning_rate": 0.00019051591060328496,
      "loss": 0.8539,
      "step": 550
    },
    {
      "epoch": 0.3463160008030516,
      "grad_norm": 0.12952503561973572,
      "learning_rate": 0.0001894522834041487,
      "loss": 0.7499,
      "step": 575
    },
    {
      "epoch": 0.3613732182292712,
      "grad_norm": 0.272885799407959,
      "learning_rate": 0.00018833544073295917,
      "loss": 0.8847,
      "step": 600
    },
    {
      "epoch": 0.3764304356554909,
      "grad_norm": 0.15567447245121002,
      "learning_rate": 0.00018716604700327514,
      "loss": 0.7352,
      "step": 625
    },
    {
      "epoch": 0.3914876530817105,
      "grad_norm": 0.22419008612632751,
      "learning_rate": 0.00018594479789146138,
      "loss": 0.8484,
      "step": 650
    },
    {
      "epoch": 0.40654487050793015,
      "grad_norm": 0.19648903608322144,
      "learning_rate": 0.00018467241992282843,
      "loss": 0.748,
      "step": 675
    },
    {
      "epoch": 0.42160208793414977,
      "grad_norm": 0.18287959694862366,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.7728,
      "step": 700
    },
    {
      "epoch": 0.4366593053603694,
      "grad_norm": 0.1666061282157898,
      "learning_rate": 0.00018197733514970654,
      "loss": 0.7555,
      "step": 725
    },
    {
      "epoch": 0.451716522786589,
      "grad_norm": 0.21363303065299988,
      "learning_rate": 0.00018055623166044854,
      "loss": 0.7848,
      "step": 750
    },
    {
      "epoch": 0.46677374021280865,
      "grad_norm": 0.1465834528207779,
      "learning_rate": 0.0001790872049910155,
      "loss": 0.7736,
      "step": 775
    },
    {
      "epoch": 0.48183095763902833,
      "grad_norm": 0.18512332439422607,
      "learning_rate": 0.000177571129070442,
      "loss": 0.8182,
      "step": 800
    },
    {
      "epoch": 0.49688817506524796,
      "grad_norm": 0.13444049656391144,
      "learning_rate": 0.00017600890581752435,
      "loss": 0.6948,
      "step": 825
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 0.21499446034431458,
      "learning_rate": 0.0001744014646042663,
      "loss": 0.8402,
      "step": 850
    },
    {
      "epoch": 0.5270026099176872,
      "grad_norm": 0.11599649488925934,
      "learning_rate": 0.00017274976170299198,
      "loss": 0.7076,
      "step": 875
    },
    {
      "epoch": 0.5420598273439069,
      "grad_norm": 0.1941194385290146,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.7883,
      "step": 900
    },
    {
      "epoch": 0.5571170447701265,
      "grad_norm": 0.14602157473564148,
      "learning_rate": 0.00016931752699829208,
      "loss": 0.7305,
      "step": 925
    },
    {
      "epoch": 0.5721742621963462,
      "grad_norm": 0.19380410015583038,
      "learning_rate": 0.00016753903704313527,
      "loss": 0.8301,
      "step": 950
    },
    {
      "epoch": 0.5872314796225657,
      "grad_norm": 0.1464550793170929,
      "learning_rate": 0.00016572036788179727,
      "loss": 0.7326,
      "step": 975
    },
    {
      "epoch": 0.6022886970487854,
      "grad_norm": 0.232082799077034,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.8177,
      "step": 1000
    },
    {
      "epoch": 0.617345914475005,
      "grad_norm": 0.14724576473236084,
      "learning_rate": 0.00016196684292991826,
      "loss": 0.7258,
      "step": 1025
    },
    {
      "epoch": 0.6324031319012247,
      "grad_norm": 0.1924816071987152,
      "learning_rate": 0.00016003422012432275,
      "loss": 0.7658,
      "step": 1050
    },
    {
      "epoch": 0.6474603493274443,
      "grad_norm": 0.1504662185907364,
      "learning_rate": 0.0001580658827540265,
      "loss": 0.7339,
      "step": 1075
    },
    {
      "epoch": 0.6625175667536639,
      "grad_norm": 0.23490294814109802,
      "learning_rate": 0.00015606300178972287,
      "loss": 0.7822,
      "step": 1100
    },
    {
      "epoch": 0.6775747841798836,
      "grad_norm": 0.13106325268745422,
      "learning_rate": 0.00015402676875220846,
      "loss": 0.7462,
      "step": 1125
    },
    {
      "epoch": 0.6926320016061032,
      "grad_norm": 0.20600776374340057,
      "learning_rate": 0.00015195839500354335,
      "loss": 0.8228,
      "step": 1150
    },
    {
      "epoch": 0.7076892190323228,
      "grad_norm": 0.15069414675235748,
      "learning_rate": 0.00014985911102640762,
      "loss": 0.6746,
      "step": 1175
    },
    {
      "epoch": 0.7227464364585424,
      "grad_norm": 0.17362672090530396,
      "learning_rate": 0.00014773016569208283,
      "loss": 0.822,
      "step": 1200
    },
    {
      "epoch": 0.7378036538847621,
      "grad_norm": 0.15546955168247223,
      "learning_rate": 0.00014557282551749427,
      "loss": 0.7281,
      "step": 1225
    },
    {
      "epoch": 0.7528608713109818,
      "grad_norm": 0.20062895119190216,
      "learning_rate": 0.00014338837391175582,
      "loss": 0.8028,
      "step": 1250
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 0.1566823571920395,
      "learning_rate": 0.00014117811041266517,
      "loss": 0.6655,
      "step": 1275
    },
    {
      "epoch": 0.782975306163421,
      "grad_norm": 0.21891185641288757,
      "learning_rate": 0.00013894334991360448,
      "loss": 0.7721,
      "step": 1300
    },
    {
      "epoch": 0.7980325235896406,
      "grad_norm": 0.1742217242717743,
      "learning_rate": 0.00013668542188130566,
      "loss": 0.7058,
      "step": 1325
    },
    {
      "epoch": 0.8130897410158603,
      "grad_norm": 0.2324668914079666,
      "learning_rate": 0.0001344056695649462,
      "loss": 0.8065,
      "step": 1350
    },
    {
      "epoch": 0.8281469584420799,
      "grad_norm": 0.1624840945005417,
      "learning_rate": 0.0001321054491970454,
      "loss": 0.726,
      "step": 1375
    },
    {
      "epoch": 0.8432041758682995,
      "grad_norm": 0.19276063144207,
      "learning_rate": 0.000129786129186637,
      "loss": 0.765,
      "step": 1400
    },
    {
      "epoch": 0.8582613932945192,
      "grad_norm": 0.14701327681541443,
      "learning_rate": 0.0001274490893051981,
      "loss": 0.7242,
      "step": 1425
    },
    {
      "epoch": 0.8733186107207388,
      "grad_norm": 0.22531239688396454,
      "learning_rate": 0.00012509571986581814,
      "loss": 0.7815,
      "step": 1450
    },
    {
      "epoch": 0.8883758281469585,
      "grad_norm": 0.13347850739955902,
      "learning_rate": 0.00012272742089609694,
      "loss": 0.7253,
      "step": 1475
    },
    {
      "epoch": 0.903433045573178,
      "grad_norm": 0.22945450246334076,
      "learning_rate": 0.0001203456013052634,
      "loss": 0.7562,
      "step": 1500
    },
    {
      "epoch": 0.9184902629993977,
      "grad_norm": 0.12353227287530899,
      "learning_rate": 0.00011795167804601061,
      "loss": 0.697,
      "step": 1525
    },
    {
      "epoch": 0.9335474804256173,
      "grad_norm": 0.18551377952098846,
      "learning_rate": 0.0001155470752715458,
      "loss": 0.7639,
      "step": 1550
    },
    {
      "epoch": 0.948604697851837,
      "grad_norm": 0.14672115445137024,
      "learning_rate": 0.00011313322348835658,
      "loss": 0.6966,
      "step": 1575
    },
    {
      "epoch": 0.9636619152780567,
      "grad_norm": 0.23328624665737152,
      "learning_rate": 0.00011071155870519777,
      "loss": 0.7699,
      "step": 1600
    },
    {
      "epoch": 0.9787191327042762,
      "grad_norm": 0.1494128704071045,
      "learning_rate": 0.00010828352157880488,
      "loss": 0.7112,
      "step": 1625
    },
    {
      "epoch": 0.9937763501304959,
      "grad_norm": 0.24157726764678955,
      "learning_rate": 0.0001058505565568424,
      "loss": 0.7653,
      "step": 1650
    },
    {
      "epoch": 1.0088335675567155,
      "grad_norm": 0.11806879192590714,
      "learning_rate": 0.00010341411101859679,
      "loss": 0.6388,
      "step": 1675
    },
    {
      "epoch": 1.023890784982935,
      "grad_norm": 0.1828938126564026,
      "learning_rate": 0.00010097563441392581,
      "loss": 0.7175,
      "step": 1700
    },
    {
      "epoch": 1.0389480024091549,
      "grad_norm": 0.13239790499210358,
      "learning_rate": 9.853657740097558e-05,
      "loss": 0.6868,
      "step": 1725
    },
    {
      "epoch": 1.0540052198353744,
      "grad_norm": 0.17090122401714325,
      "learning_rate": 9.6098390983179e-05,
      "loss": 0.7274,
      "step": 1750
    },
    {
      "epoch": 1.069062437261594,
      "grad_norm": 0.13684716820716858,
      "learning_rate": 9.366252564604913e-05,
      "loss": 0.6343,
      "step": 1775
    },
    {
      "epoch": 1.0841196546878138,
      "grad_norm": 0.14087924361228943,
      "learning_rate": 9.123043049427995e-05,
      "loss": 0.6825,
      "step": 1800
    },
    {
      "epoch": 1.0991768721140334,
      "grad_norm": 0.15722325444221497,
      "learning_rate": 8.880355238966923e-05,
      "loss": 0.6842,
      "step": 1825
    },
    {
      "epoch": 1.114234089540253,
      "grad_norm": 0.19183367490768433,
      "learning_rate": 8.638333509037536e-05,
      "loss": 0.6774,
      "step": 1850
    },
    {
      "epoch": 1.1292913069664725,
      "grad_norm": 0.1735725998878479,
      "learning_rate": 8.39712183920207e-05,
      "loss": 0.684,
      "step": 1875
    },
    {
      "epoch": 1.1443485243926923,
      "grad_norm": 0.1672748178243637,
      "learning_rate": 8.156863727115211e-05,
      "loss": 0.7696,
      "step": 1900
    },
    {
      "epoch": 1.1594057418189119,
      "grad_norm": 0.15313482284545898,
      "learning_rate": 7.91770210315685e-05,
      "loss": 0.6772,
      "step": 1925
    },
    {
      "epoch": 1.1744629592451314,
      "grad_norm": 0.1883510947227478,
      "learning_rate": 7.679779245402321e-05,
      "loss": 0.6857,
      "step": 1950
    },
    {
      "epoch": 1.1895201766713512,
      "grad_norm": 0.13231804966926575,
      "learning_rate": 7.443236694980649e-05,
      "loss": 0.6857,
      "step": 1975
    },
    {
      "epoch": 1.2045773940975708,
      "grad_norm": 0.21816420555114746,
      "learning_rate": 7.208215171871277e-05,
      "loss": 0.7145,
      "step": 2000
    },
    {
      "epoch": 1.2196346115237904,
      "grad_norm": 0.1559579074382782,
      "learning_rate": 6.974854491189243e-05,
      "loss": 0.6776,
      "step": 2025
    },
    {
      "epoch": 1.23469182895001,
      "grad_norm": 0.16602614521980286,
      "learning_rate": 6.743293480008702e-05,
      "loss": 0.7092,
      "step": 2050
    },
    {
      "epoch": 1.2497490463762297,
      "grad_norm": 0.14069198071956635,
      "learning_rate": 6.513669894774209e-05,
      "loss": 0.6686,
      "step": 2075
    },
    {
      "epoch": 1.2648062638024493,
      "grad_norm": 0.20356278121471405,
      "learning_rate": 6.286120339348935e-05,
      "loss": 0.671,
      "step": 2100
    },
    {
      "epoch": 1.2798634812286689,
      "grad_norm": 0.1372448205947876,
      "learning_rate": 6.060780183748567e-05,
      "loss": 0.6737,
      "step": 2125
    },
    {
      "epoch": 1.2949206986548885,
      "grad_norm": 0.21101903915405273,
      "learning_rate": 5.8377834836092136e-05,
      "loss": 0.6839,
      "step": 2150
    },
    {
      "epoch": 1.3099779160811083,
      "grad_norm": 0.21371886134147644,
      "learning_rate": 5.617262900437239e-05,
      "loss": 0.6744,
      "step": 2175
    },
    {
      "epoch": 1.3250351335073278,
      "grad_norm": 0.1940847933292389,
      "learning_rate": 5.399349622688479e-05,
      "loss": 0.6971,
      "step": 2200
    },
    {
      "epoch": 1.3400923509335474,
      "grad_norm": 0.1397043913602829,
      "learning_rate": 5.184173287723781e-05,
      "loss": 0.6723,
      "step": 2225
    },
    {
      "epoch": 1.3551495683597672,
      "grad_norm": 0.21823495626449585,
      "learning_rate": 4.9718619046872825e-05,
      "loss": 0.6853,
      "step": 2250
    },
    {
      "epoch": 1.3702067857859868,
      "grad_norm": 0.16094593703746796,
      "learning_rate": 4.762541778353337e-05,
      "loss": 0.6471,
      "step": 2275
    },
    {
      "epoch": 1.3852640032122063,
      "grad_norm": 0.1909114569425583,
      "learning_rate": 4.556337433987359e-05,
      "loss": 0.7146,
      "step": 2300
    },
    {
      "epoch": 1.4003212206384261,
      "grad_norm": 0.16469332575798035,
      "learning_rate": 4.35337154326532e-05,
      "loss": 0.6876,
      "step": 2325
    },
    {
      "epoch": 1.4153784380646457,
      "grad_norm": 0.19387288391590118,
      "learning_rate": 4.153764851295954e-05,
      "loss": 0.6884,
      "step": 2350
    },
    {
      "epoch": 1.4304356554908653,
      "grad_norm": 0.16549929976463318,
      "learning_rate": 3.9576361047890554e-05,
      "loss": 0.6271,
      "step": 2375
    },
    {
      "epoch": 1.445492872917085,
      "grad_norm": 0.18384027481079102,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 0.6835,
      "step": 2400
    },
    {
      "epoch": 1.4605500903433046,
      "grad_norm": 0.13693006336688995,
      "learning_rate": 3.5762770203811225e-05,
      "loss": 0.6379,
      "step": 2425
    },
    {
      "epoch": 1.4756073077695242,
      "grad_norm": 0.2602981925010681,
      "learning_rate": 3.3912735543152864e-05,
      "loss": 0.7057,
      "step": 2450
    },
    {
      "epoch": 1.4906645251957438,
      "grad_norm": 0.14892935752868652,
      "learning_rate": 3.2102016424154766e-05,
      "loss": 0.6482,
      "step": 2475
    },
    {
      "epoch": 1.5057217426219633,
      "grad_norm": 0.18509525060653687,
      "learning_rate": 3.033169004986873e-05,
      "loss": 0.6739,
      "step": 2500
    },
    {
      "epoch": 1.5207789600481831,
      "grad_norm": 0.16237793862819672,
      "learning_rate": 2.8602809593563364e-05,
      "loss": 0.6556,
      "step": 2525
    },
    {
      "epoch": 1.5358361774744027,
      "grad_norm": 0.17518356442451477,
      "learning_rate": 2.691640357218759e-05,
      "loss": 0.6701,
      "step": 2550
    },
    {
      "epoch": 1.5508933949006223,
      "grad_norm": 0.12177848070859909,
      "learning_rate": 2.5273475234502565e-05,
      "loss": 0.6101,
      "step": 2575
    },
    {
      "epoch": 1.565950612326842,
      "grad_norm": 0.1997895985841751,
      "learning_rate": 2.367500196424529e-05,
      "loss": 0.6894,
      "step": 2600
    },
    {
      "epoch": 1.5810078297530616,
      "grad_norm": 0.15951640903949738,
      "learning_rate": 2.212193469867979e-05,
      "loss": 0.6526,
      "step": 2625
    },
    {
      "epoch": 1.5960650471792812,
      "grad_norm": 0.257192999124527,
      "learning_rate": 2.0615197362881234e-05,
      "loss": 0.6754,
      "step": 2650
    },
    {
      "epoch": 1.611122264605501,
      "grad_norm": 0.14921441674232483,
      "learning_rate": 1.9155686320089684e-05,
      "loss": 0.6791,
      "step": 2675
    },
    {
      "epoch": 1.6261794820317206,
      "grad_norm": 0.23727498948574066,
      "learning_rate": 1.774426983846058e-05,
      "loss": 0.6566,
      "step": 2700
    },
    {
      "epoch": 1.6412366994579402,
      "grad_norm": 0.17983543872833252,
      "learning_rate": 1.638178757452894e-05,
      "loss": 0.6635,
      "step": 2725
    },
    {
      "epoch": 1.65629391688416,
      "grad_norm": 0.22753208875656128,
      "learning_rate": 1.5069050073694813e-05,
      "loss": 0.696,
      "step": 2750
    },
    {
      "epoch": 1.6713511343103793,
      "grad_norm": 0.16153721511363983,
      "learning_rate": 1.3806838288027113e-05,
      "loss": 0.6374,
      "step": 2775
    },
    {
      "epoch": 1.686408351736599,
      "grad_norm": 0.19240863621234894,
      "learning_rate": 1.259590311167238e-05,
      "loss": 0.6944,
      "step": 2800
    },
    {
      "epoch": 1.7014655691628187,
      "grad_norm": 0.19349850714206696,
      "learning_rate": 1.1436964934145389e-05,
      "loss": 0.6698,
      "step": 2825
    },
    {
      "epoch": 1.7165227865890382,
      "grad_norm": 0.19590699672698975,
      "learning_rate": 1.0330713211766863e-05,
      "loss": 0.705,
      "step": 2850
    },
    {
      "epoch": 1.731580004015258,
      "grad_norm": 0.15776844322681427,
      "learning_rate": 9.27780605750359e-06,
      "loss": 0.6283,
      "step": 2875
    },
    {
      "epoch": 1.7466372214414776,
      "grad_norm": 0.23149152100086212,
      "learning_rate": 8.278869849454718e-06,
      "loss": 0.6708,
      "step": 2900
    },
    {
      "epoch": 1.7616944388676972,
      "grad_norm": 0.14771752059459686,
      "learning_rate": 7.3344988582172315e-06,
      "loss": 0.6645,
      "step": 2925
    },
    {
      "epoch": 1.776751656293917,
      "grad_norm": 0.2216007262468338,
      "learning_rate": 6.4452548933523815e-06,
      "loss": 0.6757,
      "step": 2950
    },
    {
      "epoch": 1.7918088737201365,
      "grad_norm": 0.17032021284103394,
      "learning_rate": 5.611666969163243e-06,
      "loss": 0.6093,
      "step": 2975
    },
    {
      "epoch": 1.806866091146356,
      "grad_norm": 0.2491343915462494,
      "learning_rate": 4.834230989982213e-06,
      "loss": 0.6847,
      "step": 3000
    },
    {
      "epoch": 1.821923308572576,
      "grad_norm": 0.17823541164398193,
      "learning_rate": 4.113409455155837e-06,
      "loss": 0.6351,
      "step": 3025
    },
    {
      "epoch": 1.8369805259987955,
      "grad_norm": 0.19402362406253815,
      "learning_rate": 3.449631183902413e-06,
      "loss": 0.6784,
      "step": 3050
    },
    {
      "epoch": 1.852037743425015,
      "grad_norm": 0.15654800832271576,
      "learning_rate": 2.843291060205855e-06,
      "loss": 0.64,
      "step": 3075
    },
    {
      "epoch": 1.8670949608512348,
      "grad_norm": 0.20657846331596375,
      "learning_rate": 2.294749797897955e-06,
      "loss": 0.6674,
      "step": 3100
    },
    {
      "epoch": 1.8821521782774542,
      "grad_norm": 0.17084382474422455,
      "learning_rate": 1.8043337260684078e-06,
      "loss": 0.6564,
      "step": 3125
    },
    {
      "epoch": 1.897209395703674,
      "grad_norm": 0.20469407737255096,
      "learning_rate": 1.3723345949305245e-06,
      "loss": 0.7003,
      "step": 3150
    },
    {
      "epoch": 1.9122666131298935,
      "grad_norm": 0.18438468873500824,
      "learning_rate": 9.990094022580332e-07,
      "loss": 0.6544,
      "step": 3175
    },
    {
      "epoch": 1.9273238305561131,
      "grad_norm": 0.19850961863994598,
      "learning_rate": 6.845802404962243e-07,
      "loss": 0.6737,
      "step": 3200
    },
    {
      "epoch": 1.942381047982333,
      "grad_norm": 0.14920176565647125,
      "learning_rate": 4.2923416463838126e-07,
      "loss": 0.6461,
      "step": 3225
    },
    {
      "epoch": 1.9574382654085525,
      "grad_norm": 0.18049806356430054,
      "learning_rate": 2.3312308094607382e-07,
      "loss": 0.71,
      "step": 3250
    },
    {
      "epoch": 1.972495482834772,
      "grad_norm": 0.16378895938396454,
      "learning_rate": 9.636365657971214e-08,
      "loss": 0.6516,
      "step": 3275
    },
    {
      "epoch": 1.9875527002609918,
      "grad_norm": 0.22965465486049652,
      "learning_rate": 1.9037250192732726e-08,
      "loss": 0.6403,
      "step": 3300
    }
  ],
  "logging_steps": 25,
  "max_steps": 3320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8620727242173645e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
