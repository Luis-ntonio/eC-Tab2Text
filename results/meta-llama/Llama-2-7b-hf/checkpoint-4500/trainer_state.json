{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4069828035435124,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007816571130797291,
      "grad_norm": 0.07372236251831055,
      "learning_rate": 2.604166666666667e-05,
      "loss": 1.0168,
      "step": 25
    },
    {
      "epoch": 0.015633142261594582,
      "grad_norm": 0.20700715482234955,
      "learning_rate": 5.208333333333334e-05,
      "loss": 1.0042,
      "step": 50
    },
    {
      "epoch": 0.02344971339239187,
      "grad_norm": 0.19536544382572174,
      "learning_rate": 7.8125e-05,
      "loss": 0.562,
      "step": 75
    },
    {
      "epoch": 0.031266284523189164,
      "grad_norm": 0.5842965841293335,
      "learning_rate": 0.00010416666666666667,
      "loss": 0.3159,
      "step": 100
    },
    {
      "epoch": 0.03908285565398645,
      "grad_norm": 0.1421627402305603,
      "learning_rate": 0.00013020833333333333,
      "loss": 0.2085,
      "step": 125
    },
    {
      "epoch": 0.04689942678478374,
      "grad_norm": 0.3209313750267029,
      "learning_rate": 0.00015625,
      "loss": 0.1915,
      "step": 150
    },
    {
      "epoch": 0.05471599791558103,
      "grad_norm": 0.20539532601833344,
      "learning_rate": 0.00018229166666666667,
      "loss": 0.1508,
      "step": 175
    },
    {
      "epoch": 0.06253256904637833,
      "grad_norm": 0.44632020592689514,
      "learning_rate": 0.00019999917944905216,
      "loss": 0.192,
      "step": 200
    },
    {
      "epoch": 0.07034914017717561,
      "grad_norm": 0.11595966666936874,
      "learning_rate": 0.00019998603811858571,
      "loss": 0.1521,
      "step": 225
    },
    {
      "epoch": 0.0781657113079729,
      "grad_norm": 0.17256402969360352,
      "learning_rate": 0.00019995687283209658,
      "loss": 0.1838,
      "step": 250
    },
    {
      "epoch": 0.0859822824387702,
      "grad_norm": 0.09807442128658295,
      "learning_rate": 0.00019991168826367011,
      "loss": 0.1369,
      "step": 275
    },
    {
      "epoch": 0.09379885356956748,
      "grad_norm": 0.2529987096786499,
      "learning_rate": 0.00019985049165467257,
      "loss": 0.1522,
      "step": 300
    },
    {
      "epoch": 0.10161542470036478,
      "grad_norm": 0.12034878879785538,
      "learning_rate": 0.00019977329281259108,
      "loss": 0.1232,
      "step": 325
    },
    {
      "epoch": 0.10943199583116206,
      "grad_norm": 0.23607578873634338,
      "learning_rate": 0.00019968010410946154,
      "loss": 0.1607,
      "step": 350
    },
    {
      "epoch": 0.11724856696195936,
      "grad_norm": 0.12443778663873672,
      "learning_rate": 0.00019957094047988582,
      "loss": 0.1228,
      "step": 375
    },
    {
      "epoch": 0.12506513809275666,
      "grad_norm": 0.17415718734264374,
      "learning_rate": 0.00019944581941863857,
      "loss": 0.1352,
      "step": 400
    },
    {
      "epoch": 0.13288170922355394,
      "grad_norm": 0.1217331513762474,
      "learning_rate": 0.00019930476097786327,
      "loss": 0.1161,
      "step": 425
    },
    {
      "epoch": 0.14069828035435122,
      "grad_norm": 0.3952060341835022,
      "learning_rate": 0.0001991477877638587,
      "loss": 0.1501,
      "step": 450
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 0.14330002665519714,
      "learning_rate": 0.00019897492493345598,
      "loss": 0.1235,
      "step": 475
    },
    {
      "epoch": 0.1563314226159458,
      "grad_norm": 0.11016341298818588,
      "learning_rate": 0.00019878620018998696,
      "loss": 0.1307,
      "step": 500
    },
    {
      "epoch": 0.1641479937467431,
      "grad_norm": 0.10635470598936081,
      "learning_rate": 0.00019858164377884436,
      "loss": 0.111,
      "step": 525
    },
    {
      "epoch": 0.1719645648775404,
      "grad_norm": 0.11806108802556992,
      "learning_rate": 0.00019836128848263465,
      "loss": 0.1326,
      "step": 550
    },
    {
      "epoch": 0.17978113600833767,
      "grad_norm": 0.09999821335077286,
      "learning_rate": 0.0001981251696159241,
      "loss": 0.1028,
      "step": 575
    },
    {
      "epoch": 0.18759770713913496,
      "grad_norm": 0.14281988143920898,
      "learning_rate": 0.00019787332501957941,
      "loss": 0.1288,
      "step": 600
    },
    {
      "epoch": 0.19541427826993227,
      "grad_norm": 0.11818540841341019,
      "learning_rate": 0.0001976057950547031,
      "loss": 0.1119,
      "step": 625
    },
    {
      "epoch": 0.20323084940072955,
      "grad_norm": 0.10373816639184952,
      "learning_rate": 0.00019732262259616523,
      "loss": 0.1374,
      "step": 650
    },
    {
      "epoch": 0.21104742053152684,
      "grad_norm": 0.13401280343532562,
      "learning_rate": 0.0001970238530257322,
      "loss": 0.0974,
      "step": 675
    },
    {
      "epoch": 0.21886399166232412,
      "grad_norm": 0.09350785613059998,
      "learning_rate": 0.00019670953422479368,
      "loss": 0.1041,
      "step": 700
    },
    {
      "epoch": 0.2266805627931214,
      "grad_norm": 0.09239175170660019,
      "learning_rate": 0.00019637971656668918,
      "loss": 0.0886,
      "step": 725
    },
    {
      "epoch": 0.23449713392391872,
      "grad_norm": 0.2101534754037857,
      "learning_rate": 0.0001960344529086351,
      "loss": 0.1213,
      "step": 750
    },
    {
      "epoch": 0.242313705054716,
      "grad_norm": 0.12314482778310776,
      "learning_rate": 0.00019567379858325356,
      "loss": 0.1081,
      "step": 775
    },
    {
      "epoch": 0.2501302761855133,
      "grad_norm": 0.2207559049129486,
      "learning_rate": 0.000195297811389705,
      "loss": 0.1094,
      "step": 800
    },
    {
      "epoch": 0.25794684731631057,
      "grad_norm": 0.09047196060419083,
      "learning_rate": 0.00019490655158442484,
      "loss": 0.0986,
      "step": 825
    },
    {
      "epoch": 0.2657634184471079,
      "grad_norm": 0.12040792405605316,
      "learning_rate": 0.00019450008187146684,
      "loss": 0.1142,
      "step": 850
    },
    {
      "epoch": 0.27357998957790514,
      "grad_norm": 0.08893821388483047,
      "learning_rate": 0.00019407846739245415,
      "loss": 0.0994,
      "step": 875
    },
    {
      "epoch": 0.28139656070870245,
      "grad_norm": 0.11084236204624176,
      "learning_rate": 0.00019364177571613926,
      "loss": 0.1136,
      "step": 900
    },
    {
      "epoch": 0.28921313183949976,
      "grad_norm": 0.13034236431121826,
      "learning_rate": 0.00019319007682757556,
      "loss": 0.097,
      "step": 925
    },
    {
      "epoch": 0.297029702970297,
      "grad_norm": 0.1325632780790329,
      "learning_rate": 0.0001927234431169014,
      "loss": 0.0933,
      "step": 950
    },
    {
      "epoch": 0.30484627410109433,
      "grad_norm": 0.1000635102391243,
      "learning_rate": 0.00019224194936773853,
      "loss": 0.0756,
      "step": 975
    },
    {
      "epoch": 0.3126628452318916,
      "grad_norm": 0.22215475142002106,
      "learning_rate": 0.00019174567274520728,
      "loss": 0.0923,
      "step": 1000
    },
    {
      "epoch": 0.3204794163626889,
      "grad_norm": 0.125279501080513,
      "learning_rate": 0.00019123469278355985,
      "loss": 0.0739,
      "step": 1025
    },
    {
      "epoch": 0.3282959874934862,
      "grad_norm": 0.19598177075386047,
      "learning_rate": 0.00019070909137343408,
      "loss": 0.0919,
      "step": 1050
    },
    {
      "epoch": 0.33611255862428346,
      "grad_norm": 0.1032618060708046,
      "learning_rate": 0.0001901689527487294,
      "loss": 0.074,
      "step": 1075
    },
    {
      "epoch": 0.3439291297550808,
      "grad_norm": 0.10973244160413742,
      "learning_rate": 0.0001896143634731074,
      "loss": 0.0913,
      "step": 1100
    },
    {
      "epoch": 0.3517457008858781,
      "grad_norm": 0.10300366580486298,
      "learning_rate": 0.00018904541242611902,
      "loss": 0.0829,
      "step": 1125
    },
    {
      "epoch": 0.35956227201667534,
      "grad_norm": 0.15103451907634735,
      "learning_rate": 0.00018846219078896037,
      "loss": 0.1052,
      "step": 1150
    },
    {
      "epoch": 0.36737884314747266,
      "grad_norm": 0.09712079912424088,
      "learning_rate": 0.00018786479202986006,
      "loss": 0.0842,
      "step": 1175
    },
    {
      "epoch": 0.3751954142782699,
      "grad_norm": 0.14048095047473907,
      "learning_rate": 0.0001872533118890997,
      "loss": 0.0976,
      "step": 1200
    },
    {
      "epoch": 0.3830119854090672,
      "grad_norm": 0.10973868519067764,
      "learning_rate": 0.00018662784836367028,
      "loss": 0.0767,
      "step": 1225
    },
    {
      "epoch": 0.39082855653986454,
      "grad_norm": 0.13113722205162048,
      "learning_rate": 0.00018598850169156722,
      "loss": 0.0878,
      "step": 1250
    },
    {
      "epoch": 0.3986451276706618,
      "grad_norm": 0.09953539073467255,
      "learning_rate": 0.00018533537433572581,
      "loss": 0.0796,
      "step": 1275
    },
    {
      "epoch": 0.4064616988014591,
      "grad_norm": 0.15510617196559906,
      "learning_rate": 0.00018466857096760046,
      "loss": 0.0862,
      "step": 1300
    },
    {
      "epoch": 0.41427826993225636,
      "grad_norm": 0.07445394992828369,
      "learning_rate": 0.00018398819845038972,
      "loss": 0.0759,
      "step": 1325
    },
    {
      "epoch": 0.42209484106305367,
      "grad_norm": 0.247817263007164,
      "learning_rate": 0.0001832943658219103,
      "loss": 0.0925,
      "step": 1350
    },
    {
      "epoch": 0.429911412193851,
      "grad_norm": 0.11674395948648453,
      "learning_rate": 0.00018258718427712238,
      "loss": 0.0732,
      "step": 1375
    },
    {
      "epoch": 0.43772798332464824,
      "grad_norm": 0.14407627284526825,
      "learning_rate": 0.00018186676715030924,
      "loss": 0.0865,
      "step": 1400
    },
    {
      "epoch": 0.44554455445544555,
      "grad_norm": 0.08160194009542465,
      "learning_rate": 0.0001811332298969142,
      "loss": 0.0748,
      "step": 1425
    },
    {
      "epoch": 0.4533611255862428,
      "grad_norm": 0.14886535704135895,
      "learning_rate": 0.0001803866900750376,
      "loss": 0.0981,
      "step": 1450
    },
    {
      "epoch": 0.4611776967170401,
      "grad_norm": 0.09281537681818008,
      "learning_rate": 0.0001796272673265963,
      "loss": 0.0717,
      "step": 1475
    },
    {
      "epoch": 0.46899426784783743,
      "grad_norm": 0.09734966605901718,
      "learning_rate": 0.00017885508335815014,
      "loss": 0.0792,
      "step": 1500
    },
    {
      "epoch": 0.4768108389786347,
      "grad_norm": 0.10651493072509766,
      "learning_rate": 0.0001780702619213967,
      "loss": 0.0679,
      "step": 1525
    },
    {
      "epoch": 0.484627410109432,
      "grad_norm": 0.19400672614574432,
      "learning_rate": 0.0001772729287933387,
      "loss": 0.0817,
      "step": 1550
    },
    {
      "epoch": 0.4924439812402293,
      "grad_norm": 0.10392797738313675,
      "learning_rate": 0.00017646321175612668,
      "loss": 0.0701,
      "step": 1575
    },
    {
      "epoch": 0.5002605523710266,
      "grad_norm": 0.17100906372070312,
      "learning_rate": 0.00017564124057658056,
      "loss": 0.0874,
      "step": 1600
    },
    {
      "epoch": 0.5080771235018239,
      "grad_norm": 0.14439144730567932,
      "learning_rate": 0.00017480714698539266,
      "loss": 0.0655,
      "step": 1625
    },
    {
      "epoch": 0.5158936946326211,
      "grad_norm": 0.09884030371904373,
      "learning_rate": 0.00017396106465601663,
      "loss": 0.0772,
      "step": 1650
    },
    {
      "epoch": 0.5237102657634184,
      "grad_norm": 0.07561030238866806,
      "learning_rate": 0.0001731031291832444,
      "loss": 0.0736,
      "step": 1675
    },
    {
      "epoch": 0.5315268368942158,
      "grad_norm": 0.14098410308361053,
      "learning_rate": 0.0001722334780614756,
      "loss": 0.0824,
      "step": 1700
    },
    {
      "epoch": 0.539343408025013,
      "grad_norm": 0.09904792904853821,
      "learning_rate": 0.00017135225066268255,
      "loss": 0.0731,
      "step": 1725
    },
    {
      "epoch": 0.5471599791558103,
      "grad_norm": 0.21149154007434845,
      "learning_rate": 0.00017045958821407405,
      "loss": 0.0811,
      "step": 1750
    },
    {
      "epoch": 0.5549765502866076,
      "grad_norm": 0.08569848537445068,
      "learning_rate": 0.00016955563377546207,
      "loss": 0.0708,
      "step": 1775
    },
    {
      "epoch": 0.5627931214174049,
      "grad_norm": 0.1469348818063736,
      "learning_rate": 0.0001686405322163349,
      "loss": 0.0802,
      "step": 1800
    },
    {
      "epoch": 0.5706096925482022,
      "grad_norm": 0.10753300040960312,
      "learning_rate": 0.00016771443019263983,
      "loss": 0.0636,
      "step": 1825
    },
    {
      "epoch": 0.5784262636789995,
      "grad_norm": 0.15582260489463806,
      "learning_rate": 0.00016677747612327997,
      "loss": 0.0729,
      "step": 1850
    },
    {
      "epoch": 0.5862428348097968,
      "grad_norm": 0.11182352900505066,
      "learning_rate": 0.00016582982016632818,
      "loss": 0.0646,
      "step": 1875
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 0.10339730232954025,
      "learning_rate": 0.00016487161419496263,
      "loss": 0.0685,
      "step": 1900
    },
    {
      "epoch": 0.6018759770713914,
      "grad_norm": 0.13226759433746338,
      "learning_rate": 0.00016390301177312722,
      "loss": 0.0571,
      "step": 1925
    },
    {
      "epoch": 0.6096925482021887,
      "grad_norm": 0.14834819734096527,
      "learning_rate": 0.00016292416813092105,
      "loss": 0.0801,
      "step": 1950
    },
    {
      "epoch": 0.6175091193329859,
      "grad_norm": 0.09808413684368134,
      "learning_rate": 0.00016193524013972114,
      "loss": 0.0648,
      "step": 1975
    },
    {
      "epoch": 0.6253256904637832,
      "grad_norm": 0.15677288174629211,
      "learning_rate": 0.00016093638628704167,
      "loss": 0.0843,
      "step": 2000
    },
    {
      "epoch": 0.6331422615945805,
      "grad_norm": 0.0766884908080101,
      "learning_rate": 0.0001599277666511347,
      "loss": 0.0514,
      "step": 2025
    },
    {
      "epoch": 0.6409588327253778,
      "grad_norm": 0.20364819467067719,
      "learning_rate": 0.00015890954287533555,
      "loss": 0.0767,
      "step": 2050
    },
    {
      "epoch": 0.648775403856175,
      "grad_norm": 0.12740683555603027,
      "learning_rate": 0.00015788187814215764,
      "loss": 0.0568,
      "step": 2075
    },
    {
      "epoch": 0.6565919749869724,
      "grad_norm": 0.12899045646190643,
      "learning_rate": 0.00015684493714714047,
      "loss": 0.076,
      "step": 2100
    },
    {
      "epoch": 0.6644085461177697,
      "grad_norm": 0.1087249293923378,
      "learning_rate": 0.00015579888607245517,
      "loss": 0.0509,
      "step": 2125
    },
    {
      "epoch": 0.6722251172485669,
      "grad_norm": 0.14588384330272675,
      "learning_rate": 0.000154743892560272,
      "loss": 0.078,
      "step": 2150
    },
    {
      "epoch": 0.6800416883793643,
      "grad_norm": 0.08713212609291077,
      "learning_rate": 0.00015368012568589342,
      "loss": 0.0506,
      "step": 2175
    },
    {
      "epoch": 0.6878582595101616,
      "grad_norm": 0.1444116085767746,
      "learning_rate": 0.00015260775593065802,
      "loss": 0.0713,
      "step": 2200
    },
    {
      "epoch": 0.6956748306409588,
      "grad_norm": 0.08425400406122208,
      "learning_rate": 0.00015152695515461865,
      "loss": 0.0571,
      "step": 2225
    },
    {
      "epoch": 0.7034914017717562,
      "grad_norm": 0.12301599234342575,
      "learning_rate": 0.00015043789656899988,
      "loss": 0.071,
      "step": 2250
    },
    {
      "epoch": 0.7113079729025534,
      "grad_norm": 0.15080828964710236,
      "learning_rate": 0.00014934075470843887,
      "loss": 0.0466,
      "step": 2275
    },
    {
      "epoch": 0.7191245440333507,
      "grad_norm": 0.15468105673789978,
      "learning_rate": 0.00014823570540301408,
      "loss": 0.0717,
      "step": 2300
    },
    {
      "epoch": 0.7269411151641479,
      "grad_norm": 0.09826921671628952,
      "learning_rate": 0.00014712292575006633,
      "loss": 0.053,
      "step": 2325
    },
    {
      "epoch": 0.7347576862949453,
      "grad_norm": 0.2159779816865921,
      "learning_rate": 0.00014600259408581687,
      "loss": 0.084,
      "step": 2350
    },
    {
      "epoch": 0.7425742574257426,
      "grad_norm": 0.08869534730911255,
      "learning_rate": 0.00014487488995678708,
      "loss": 0.0489,
      "step": 2375
    },
    {
      "epoch": 0.7503908285565398,
      "grad_norm": 0.13357573747634888,
      "learning_rate": 0.00014373999409102362,
      "loss": 0.0568,
      "step": 2400
    },
    {
      "epoch": 0.7582073996873372,
      "grad_norm": 0.07367324084043503,
      "learning_rate": 0.00014259808836913492,
      "loss": 0.0526,
      "step": 2425
    },
    {
      "epoch": 0.7660239708181344,
      "grad_norm": 0.15547014772891998,
      "learning_rate": 0.00014144935579514246,
      "loss": 0.0809,
      "step": 2450
    },
    {
      "epoch": 0.7738405419489317,
      "grad_norm": 0.12713147699832916,
      "learning_rate": 0.00014029398046715223,
      "loss": 0.0513,
      "step": 2475
    },
    {
      "epoch": 0.7816571130797291,
      "grad_norm": 0.11993339657783508,
      "learning_rate": 0.00013913214754785095,
      "loss": 0.0559,
      "step": 2500
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.09020290523767471,
      "learning_rate": 0.00013796404323483132,
      "loss": 0.0521,
      "step": 2525
    },
    {
      "epoch": 0.7972902553413236,
      "grad_norm": 0.08147749304771423,
      "learning_rate": 0.00013678985473075176,
      "loss": 0.0541,
      "step": 2550
    },
    {
      "epoch": 0.805106826472121,
      "grad_norm": 0.07862571626901627,
      "learning_rate": 0.00013560977021333497,
      "loss": 0.0498,
      "step": 2575
    },
    {
      "epoch": 0.8129233976029182,
      "grad_norm": 0.19405068457126617,
      "learning_rate": 0.00013442397880521008,
      "loss": 0.0748,
      "step": 2600
    },
    {
      "epoch": 0.8207399687337155,
      "grad_norm": 0.11760378628969193,
      "learning_rate": 0.0001332326705436037,
      "loss": 0.0538,
      "step": 2625
    },
    {
      "epoch": 0.8285565398645127,
      "grad_norm": 0.12941712141036987,
      "learning_rate": 0.00013203603634988386,
      "loss": 0.0618,
      "step": 2650
    },
    {
      "epoch": 0.8363731109953101,
      "grad_norm": 0.10309737920761108,
      "learning_rate": 0.000130834267998963,
      "loss": 0.0564,
      "step": 2675
    },
    {
      "epoch": 0.8441896821261073,
      "grad_norm": 0.22142913937568665,
      "learning_rate": 0.00012962755808856342,
      "loss": 0.0593,
      "step": 2700
    },
    {
      "epoch": 0.8520062532569046,
      "grad_norm": 0.08934997767210007,
      "learning_rate": 0.00012841610000835125,
      "loss": 0.0439,
      "step": 2725
    },
    {
      "epoch": 0.859822824387702,
      "grad_norm": 0.17143645882606506,
      "learning_rate": 0.00012720008790894366,
      "loss": 0.0663,
      "step": 2750
    },
    {
      "epoch": 0.8676393955184992,
      "grad_norm": 0.13781222701072693,
      "learning_rate": 0.00012597971667079361,
      "loss": 0.0399,
      "step": 2775
    },
    {
      "epoch": 0.8754559666492965,
      "grad_norm": 0.16726554930210114,
      "learning_rate": 0.0001247551818729582,
      "loss": 0.0672,
      "step": 2800
    },
    {
      "epoch": 0.8832725377800938,
      "grad_norm": 0.1105312705039978,
      "learning_rate": 0.0001235266797617545,
      "loss": 0.0437,
      "step": 2825
    },
    {
      "epoch": 0.8910891089108911,
      "grad_norm": 0.11321337521076202,
      "learning_rate": 0.00012229440721930906,
      "loss": 0.0566,
      "step": 2850
    },
    {
      "epoch": 0.8989056800416884,
      "grad_norm": 0.12500178813934326,
      "learning_rate": 0.00012105856173200498,
      "loss": 0.047,
      "step": 2875
    },
    {
      "epoch": 0.9067222511724856,
      "grad_norm": 0.13301007449626923,
      "learning_rate": 0.00011981934135883237,
      "loss": 0.0607,
      "step": 2900
    },
    {
      "epoch": 0.914538822303283,
      "grad_norm": 0.10338349640369415,
      "learning_rate": 0.00011857694469964715,
      "loss": 0.0532,
      "step": 2925
    },
    {
      "epoch": 0.9223553934340802,
      "grad_norm": 0.14267335832118988,
      "learning_rate": 0.00011733157086334294,
      "loss": 0.057,
      "step": 2950
    },
    {
      "epoch": 0.9301719645648775,
      "grad_norm": 0.1078609824180603,
      "learning_rate": 0.0001160834194359416,
      "loss": 0.0459,
      "step": 2975
    },
    {
      "epoch": 0.9379885356956749,
      "grad_norm": 0.1461758017539978,
      "learning_rate": 0.00011483269044860705,
      "loss": 0.0766,
      "step": 3000
    },
    {
      "epoch": 0.9458051068264721,
      "grad_norm": 0.12601222097873688,
      "learning_rate": 0.000113579584345588,
      "loss": 0.0429,
      "step": 3025
    },
    {
      "epoch": 0.9536216779572694,
      "grad_norm": 0.10900402814149857,
      "learning_rate": 0.0001123243019520942,
      "loss": 0.0665,
      "step": 3050
    },
    {
      "epoch": 0.9614382490880667,
      "grad_norm": 0.12857025861740112,
      "learning_rate": 0.00011106704444211207,
      "loss": 0.0425,
      "step": 3075
    },
    {
      "epoch": 0.969254820218864,
      "grad_norm": 0.1640956550836563,
      "learning_rate": 0.000109808013306164,
      "loss": 0.053,
      "step": 3100
    },
    {
      "epoch": 0.9770713913496613,
      "grad_norm": 0.11999285221099854,
      "learning_rate": 0.00010854741031901703,
      "loss": 0.043,
      "step": 3125
    },
    {
      "epoch": 0.9848879624804586,
      "grad_norm": 0.14193956553936005,
      "learning_rate": 0.00010728543750734622,
      "loss": 0.0738,
      "step": 3150
    },
    {
      "epoch": 0.9927045336112559,
      "grad_norm": 0.09917745739221573,
      "learning_rate": 0.00010602229711735726,
      "loss": 0.037,
      "step": 3175
    },
    {
      "epoch": 1.0005211047420532,
      "grad_norm": 0.07736478000879288,
      "learning_rate": 0.00010475819158237425,
      "loss": 0.0597,
      "step": 3200
    },
    {
      "epoch": 1.0083376758728504,
      "grad_norm": 0.08551782369613647,
      "learning_rate": 0.0001034933234903973,
      "loss": 0.0338,
      "step": 3225
    },
    {
      "epoch": 1.0161542470036478,
      "grad_norm": 0.1320209801197052,
      "learning_rate": 0.0001022278955516354,
      "loss": 0.0571,
      "step": 3250
    },
    {
      "epoch": 1.0239708181344451,
      "grad_norm": 0.07304678112268448,
      "learning_rate": 0.00010096211056601958,
      "loss": 0.0452,
      "step": 3275
    },
    {
      "epoch": 1.0317873892652423,
      "grad_norm": 0.1066020131111145,
      "learning_rate": 9.969617139070202e-05,
      "loss": 0.0534,
      "step": 3300
    },
    {
      "epoch": 1.0396039603960396,
      "grad_norm": 0.14709720015525818,
      "learning_rate": 9.84302809075455e-05,
      "loss": 0.0367,
      "step": 3325
    },
    {
      "epoch": 1.047420531526837,
      "grad_norm": 0.10040151327848434,
      "learning_rate": 9.716464199060946e-05,
      "loss": 0.0551,
      "step": 3350
    },
    {
      "epoch": 1.0552371026576342,
      "grad_norm": 0.10246758162975311,
      "learning_rate": 9.589945747363667e-05,
      "loss": 0.041,
      "step": 3375
    },
    {
      "epoch": 1.0630536737884315,
      "grad_norm": 0.09503686428070068,
      "learning_rate": 9.463493011754706e-05,
      "loss": 0.0536,
      "step": 3400
    },
    {
      "epoch": 1.0708702449192287,
      "grad_norm": 0.09478604793548584,
      "learning_rate": 9.337126257794255e-05,
      "loss": 0.0306,
      "step": 3425
    },
    {
      "epoch": 1.078686816050026,
      "grad_norm": 0.12112786620855331,
      "learning_rate": 9.210865737262924e-05,
      "loss": 0.0411,
      "step": 3450
    },
    {
      "epoch": 1.0865033871808234,
      "grad_norm": 0.17108869552612305,
      "learning_rate": 9.084731684916151e-05,
      "loss": 0.0405,
      "step": 3475
    },
    {
      "epoch": 1.0943199583116205,
      "grad_norm": 0.04287311062216759,
      "learning_rate": 8.958744315241341e-05,
      "loss": 0.0469,
      "step": 3500
    },
    {
      "epoch": 1.102136529442418,
      "grad_norm": 0.06616378575563431,
      "learning_rate": 8.832923819218238e-05,
      "loss": 0.0392,
      "step": 3525
    },
    {
      "epoch": 1.1099531005732153,
      "grad_norm": 0.08639610558748245,
      "learning_rate": 8.707290361083107e-05,
      "loss": 0.0429,
      "step": 3550
    },
    {
      "epoch": 1.1177696717040124,
      "grad_norm": 0.09512147307395935,
      "learning_rate": 8.581864075097144e-05,
      "loss": 0.0373,
      "step": 3575
    },
    {
      "epoch": 1.1255862428348098,
      "grad_norm": 0.0561474934220314,
      "learning_rate": 8.456665062319742e-05,
      "loss": 0.0384,
      "step": 3600
    },
    {
      "epoch": 1.1334028139656072,
      "grad_norm": 0.06767480820417404,
      "learning_rate": 8.33171338738706e-05,
      "loss": 0.0401,
      "step": 3625
    },
    {
      "epoch": 1.1412193850964043,
      "grad_norm": 0.08025548607110977,
      "learning_rate": 8.207029075296392e-05,
      "loss": 0.0522,
      "step": 3650
    },
    {
      "epoch": 1.1490359562272017,
      "grad_norm": 0.06865951418876648,
      "learning_rate": 8.082632108196969e-05,
      "loss": 0.035,
      "step": 3675
    },
    {
      "epoch": 1.156852527357999,
      "grad_norm": 0.08558903634548187,
      "learning_rate": 7.958542422187538e-05,
      "loss": 0.0503,
      "step": 3700
    },
    {
      "epoch": 1.1646690984887962,
      "grad_norm": 0.061024345457553864,
      "learning_rate": 7.834779904121399e-05,
      "loss": 0.0324,
      "step": 3725
    },
    {
      "epoch": 1.1724856696195936,
      "grad_norm": 0.07680206745862961,
      "learning_rate": 7.711364388419278e-05,
      "loss": 0.0493,
      "step": 3750
    },
    {
      "epoch": 1.180302240750391,
      "grad_norm": 0.11576440930366516,
      "learning_rate": 7.588315653890629e-05,
      "loss": 0.0326,
      "step": 3775
    },
    {
      "epoch": 1.188118811881188,
      "grad_norm": 0.08361730724573135,
      "learning_rate": 7.465653420563845e-05,
      "loss": 0.0385,
      "step": 3800
    },
    {
      "epoch": 1.1959353830119854,
      "grad_norm": 0.10096333175897598,
      "learning_rate": 7.343397346525888e-05,
      "loss": 0.0348,
      "step": 3825
    },
    {
      "epoch": 1.2037519541427826,
      "grad_norm": 0.07992786169052124,
      "learning_rate": 7.221567024771849e-05,
      "loss": 0.0479,
      "step": 3850
    },
    {
      "epoch": 1.21156852527358,
      "grad_norm": 0.10847412049770355,
      "learning_rate": 7.100181980064937e-05,
      "loss": 0.0332,
      "step": 3875
    },
    {
      "epoch": 1.2193850964043773,
      "grad_norm": 0.14536519348621368,
      "learning_rate": 6.979261665807389e-05,
      "loss": 0.0467,
      "step": 3900
    },
    {
      "epoch": 1.2272016675351747,
      "grad_norm": 0.03416386991739273,
      "learning_rate": 6.858825460922849e-05,
      "loss": 0.036,
      "step": 3925
    },
    {
      "epoch": 1.2350182386659718,
      "grad_norm": 0.074139803647995,
      "learning_rate": 6.738892666750651e-05,
      "loss": 0.0433,
      "step": 3950
    },
    {
      "epoch": 1.2428348097967692,
      "grad_norm": 0.12245995551347733,
      "learning_rate": 6.619482503952559e-05,
      "loss": 0.0269,
      "step": 3975
    },
    {
      "epoch": 1.2506513809275663,
      "grad_norm": 0.02719786763191223,
      "learning_rate": 6.500614109432419e-05,
      "loss": 0.0453,
      "step": 4000
    },
    {
      "epoch": 1.2584679520583637,
      "grad_norm": 0.07890438288450241,
      "learning_rate": 6.382306533269238e-05,
      "loss": 0.0361,
      "step": 4025
    },
    {
      "epoch": 1.266284523189161,
      "grad_norm": 0.17288175225257874,
      "learning_rate": 6.264578735664194e-05,
      "loss": 0.0407,
      "step": 4050
    },
    {
      "epoch": 1.2741010943199584,
      "grad_norm": 0.06969442963600159,
      "learning_rate": 6.147449583902036e-05,
      "loss": 0.0297,
      "step": 4075
    },
    {
      "epoch": 1.2819176654507556,
      "grad_norm": 0.1062152162194252,
      "learning_rate": 6.030937849327356e-05,
      "loss": 0.0374,
      "step": 4100
    },
    {
      "epoch": 1.289734236581553,
      "grad_norm": 0.16284960508346558,
      "learning_rate": 5.91506220433629e-05,
      "loss": 0.0349,
      "step": 4125
    },
    {
      "epoch": 1.29755080771235,
      "grad_norm": 0.08115194737911224,
      "learning_rate": 5.79984121938401e-05,
      "loss": 0.0504,
      "step": 4150
    },
    {
      "epoch": 1.3053673788431475,
      "grad_norm": 0.061517901718616486,
      "learning_rate": 5.6852933600086125e-05,
      "loss": 0.0352,
      "step": 4175
    },
    {
      "epoch": 1.3131839499739448,
      "grad_norm": 0.10849671065807343,
      "learning_rate": 5.5714369838717874e-05,
      "loss": 0.0396,
      "step": 4200
    },
    {
      "epoch": 1.321000521104742,
      "grad_norm": 0.1651451587677002,
      "learning_rate": 5.4582903378167716e-05,
      "loss": 0.0448,
      "step": 4225
    },
    {
      "epoch": 1.3288170922355393,
      "grad_norm": 0.08405693620443344,
      "learning_rate": 5.3458715549440984e-05,
      "loss": 0.0501,
      "step": 4250
    },
    {
      "epoch": 1.3366336633663367,
      "grad_norm": 0.12146975100040436,
      "learning_rate": 5.234198651705527e-05,
      "loss": 0.0362,
      "step": 4275
    },
    {
      "epoch": 1.3444502344971339,
      "grad_norm": 0.05690561607480049,
      "learning_rate": 5.12328952501671e-05,
      "loss": 0.0364,
      "step": 4300
    },
    {
      "epoch": 1.3522668056279312,
      "grad_norm": 0.16917158663272858,
      "learning_rate": 5.013161949388993e-05,
      "loss": 0.0394,
      "step": 4325
    },
    {
      "epoch": 1.3600833767587286,
      "grad_norm": 0.08387745916843414,
      "learning_rate": 4.903833574080825e-05,
      "loss": 0.0408,
      "step": 4350
    },
    {
      "epoch": 1.3678999478895257,
      "grad_norm": 0.04665641486644745,
      "learning_rate": 4.795321920269279e-05,
      "loss": 0.0287,
      "step": 4375
    },
    {
      "epoch": 1.375716519020323,
      "grad_norm": 0.1157321110367775,
      "learning_rate": 4.687644378242044e-05,
      "loss": 0.0396,
      "step": 4400
    },
    {
      "epoch": 1.3835330901511202,
      "grad_norm": 0.06476232409477234,
      "learning_rate": 4.580818204610458e-05,
      "loss": 0.0329,
      "step": 4425
    },
    {
      "epoch": 1.3913496612819176,
      "grad_norm": 0.06882144510746002,
      "learning_rate": 4.4748605195438976e-05,
      "loss": 0.0476,
      "step": 4450
    },
    {
      "epoch": 1.399166232412715,
      "grad_norm": 0.08675823360681534,
      "learning_rate": 4.36978830402608e-05,
      "loss": 0.0317,
      "step": 4475
    },
    {
      "epoch": 1.4069828035435124,
      "grad_norm": 0.08124297112226486,
      "learning_rate": 4.265618397133674e-05,
      "loss": 0.0494,
      "step": 4500
    }
  ],
  "logging_steps": 25,
  "max_steps": 6396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.300097677295698e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
