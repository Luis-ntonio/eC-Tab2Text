{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6022886970487854,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015057217426219635,
      "grad_norm": 0.11013614386320114,
      "learning_rate": 5e-05,
      "loss": 1.2234,
      "step": 25
    },
    {
      "epoch": 0.03011443485243927,
      "grad_norm": 0.2801661193370819,
      "learning_rate": 0.0001,
      "loss": 1.2797,
      "step": 50
    },
    {
      "epoch": 0.0451716522786589,
      "grad_norm": 0.15786220133304596,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.8691,
      "step": 75
    },
    {
      "epoch": 0.06022886970487854,
      "grad_norm": 0.18243414163589478,
      "learning_rate": 0.0002,
      "loss": 0.9399,
      "step": 100
    },
    {
      "epoch": 0.07528608713109818,
      "grad_norm": 0.19626952707767487,
      "learning_rate": 0.00019997025482747441,
      "loss": 0.7853,
      "step": 125
    },
    {
      "epoch": 0.0903433045573178,
      "grad_norm": 0.20215673744678497,
      "learning_rate": 0.00019988103700540344,
      "loss": 0.8977,
      "step": 150
    },
    {
      "epoch": 0.10540052198353744,
      "grad_norm": 0.19582992792129517,
      "learning_rate": 0.0001997323996097772,
      "loss": 0.7447,
      "step": 175
    },
    {
      "epoch": 0.12045773940975708,
      "grad_norm": 0.22023449838161469,
      "learning_rate": 0.00019952443106549533,
      "loss": 0.8568,
      "step": 200
    },
    {
      "epoch": 0.13551495683597672,
      "grad_norm": 0.12788134813308716,
      "learning_rate": 0.00019925725509376235,
      "loss": 0.8106,
      "step": 225
    },
    {
      "epoch": 0.15057217426219635,
      "grad_norm": 0.20170921087265015,
      "learning_rate": 0.0001989310306384858,
      "loss": 0.8535,
      "step": 250
    },
    {
      "epoch": 0.16562939168841598,
      "grad_norm": 0.1611468642950058,
      "learning_rate": 0.00019854595177171968,
      "loss": 0.7872,
      "step": 275
    },
    {
      "epoch": 0.1806866091146356,
      "grad_norm": 0.2032822221517563,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.846,
      "step": 300
    },
    {
      "epoch": 0.19574382654085526,
      "grad_norm": 0.12180355191230774,
      "learning_rate": 0.00019760018201911433,
      "loss": 0.8082,
      "step": 325
    },
    {
      "epoch": 0.21080104396707489,
      "grad_norm": 0.1579548716545105,
      "learning_rate": 0.0001970400537749643,
      "loss": 0.869,
      "step": 350
    },
    {
      "epoch": 0.2258582613932945,
      "grad_norm": 0.14111171662807465,
      "learning_rate": 0.00019642219606798566,
      "loss": 0.7771,
      "step": 375
    },
    {
      "epoch": 0.24091547881951417,
      "grad_norm": 0.1635938137769699,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.8333,
      "step": 400
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 0.1461314558982849,
      "learning_rate": 0.00019501479665306047,
      "loss": 0.7811,
      "step": 425
    },
    {
      "epoch": 0.27102991367195345,
      "grad_norm": 0.16678526997566223,
      "learning_rate": 0.00019422609221188207,
      "loss": 0.8647,
      "step": 450
    },
    {
      "epoch": 0.2860871310981731,
      "grad_norm": 0.13775776326656342,
      "learning_rate": 0.0001933813323433186,
      "loss": 0.7756,
      "step": 475
    },
    {
      "epoch": 0.3011443485243927,
      "grad_norm": 0.1952275037765503,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.8348,
      "step": 500
    },
    {
      "epoch": 0.31620156595061233,
      "grad_norm": 0.13785801827907562,
      "learning_rate": 0.00019152568957487708,
      "loss": 0.7932,
      "step": 525
    },
    {
      "epoch": 0.33125878337683196,
      "grad_norm": 0.20806820690631866,
      "learning_rate": 0.00019051591060328496,
      "loss": 0.8539,
      "step": 550
    },
    {
      "epoch": 0.3463160008030516,
      "grad_norm": 0.12952503561973572,
      "learning_rate": 0.0001894522834041487,
      "loss": 0.7499,
      "step": 575
    },
    {
      "epoch": 0.3613732182292712,
      "grad_norm": 0.272885799407959,
      "learning_rate": 0.00018833544073295917,
      "loss": 0.8847,
      "step": 600
    },
    {
      "epoch": 0.3764304356554909,
      "grad_norm": 0.15567447245121002,
      "learning_rate": 0.00018716604700327514,
      "loss": 0.7352,
      "step": 625
    },
    {
      "epoch": 0.3914876530817105,
      "grad_norm": 0.22419008612632751,
      "learning_rate": 0.00018594479789146138,
      "loss": 0.8484,
      "step": 650
    },
    {
      "epoch": 0.40654487050793015,
      "grad_norm": 0.19648903608322144,
      "learning_rate": 0.00018467241992282843,
      "loss": 0.748,
      "step": 675
    },
    {
      "epoch": 0.42160208793414977,
      "grad_norm": 0.18287959694862366,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.7728,
      "step": 700
    },
    {
      "epoch": 0.4366593053603694,
      "grad_norm": 0.1666061282157898,
      "learning_rate": 0.00018197733514970654,
      "loss": 0.7555,
      "step": 725
    },
    {
      "epoch": 0.451716522786589,
      "grad_norm": 0.21363303065299988,
      "learning_rate": 0.00018055623166044854,
      "loss": 0.7848,
      "step": 750
    },
    {
      "epoch": 0.46677374021280865,
      "grad_norm": 0.1465834528207779,
      "learning_rate": 0.0001790872049910155,
      "loss": 0.7736,
      "step": 775
    },
    {
      "epoch": 0.48183095763902833,
      "grad_norm": 0.18512332439422607,
      "learning_rate": 0.000177571129070442,
      "loss": 0.8182,
      "step": 800
    },
    {
      "epoch": 0.49688817506524796,
      "grad_norm": 0.13444049656391144,
      "learning_rate": 0.00017600890581752435,
      "loss": 0.6948,
      "step": 825
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 0.21499446034431458,
      "learning_rate": 0.0001744014646042663,
      "loss": 0.8402,
      "step": 850
    },
    {
      "epoch": 0.5270026099176872,
      "grad_norm": 0.11599649488925934,
      "learning_rate": 0.00017274976170299198,
      "loss": 0.7076,
      "step": 875
    },
    {
      "epoch": 0.5420598273439069,
      "grad_norm": 0.1941194385290146,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.7883,
      "step": 900
    },
    {
      "epoch": 0.5571170447701265,
      "grad_norm": 0.14602157473564148,
      "learning_rate": 0.00016931752699829208,
      "loss": 0.7305,
      "step": 925
    },
    {
      "epoch": 0.5721742621963462,
      "grad_norm": 0.19380410015583038,
      "learning_rate": 0.00016753903704313527,
      "loss": 0.8301,
      "step": 950
    },
    {
      "epoch": 0.5872314796225657,
      "grad_norm": 0.1464550793170929,
      "learning_rate": 0.00016572036788179727,
      "loss": 0.7326,
      "step": 975
    },
    {
      "epoch": 0.6022886970487854,
      "grad_norm": 0.232082799077034,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.8177,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 3320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.617664949996749e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
