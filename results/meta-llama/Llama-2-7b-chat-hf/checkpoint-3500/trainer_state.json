{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0943199583116205,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007816571130797291,
      "grad_norm": 0.16461588442325592,
      "learning_rate": 2.604166666666667e-05,
      "loss": 1.3284,
      "step": 25
    },
    {
      "epoch": 0.015633142261594582,
      "grad_norm": 0.237275630235672,
      "learning_rate": 5.208333333333334e-05,
      "loss": 1.2095,
      "step": 50
    },
    {
      "epoch": 0.02344971339239187,
      "grad_norm": 0.2465115338563919,
      "learning_rate": 7.8125e-05,
      "loss": 0.7133,
      "step": 75
    },
    {
      "epoch": 0.031266284523189164,
      "grad_norm": 0.5179443955421448,
      "learning_rate": 0.00010416666666666667,
      "loss": 0.3775,
      "step": 100
    },
    {
      "epoch": 0.03908285565398645,
      "grad_norm": 0.16486196219921112,
      "learning_rate": 0.00013020833333333333,
      "loss": 0.2465,
      "step": 125
    },
    {
      "epoch": 0.04689942678478374,
      "grad_norm": 0.3671402931213379,
      "learning_rate": 0.00015625,
      "loss": 0.2246,
      "step": 150
    },
    {
      "epoch": 0.05471599791558103,
      "grad_norm": 0.29935628175735474,
      "learning_rate": 0.00018229166666666667,
      "loss": 0.1762,
      "step": 175
    },
    {
      "epoch": 0.06253256904637833,
      "grad_norm": 0.2401837855577469,
      "learning_rate": 0.00019999917944905216,
      "loss": 0.2089,
      "step": 200
    },
    {
      "epoch": 0.07034914017717561,
      "grad_norm": 0.12683165073394775,
      "learning_rate": 0.00019998603811858571,
      "loss": 0.165,
      "step": 225
    },
    {
      "epoch": 0.0781657113079729,
      "grad_norm": 0.18932399153709412,
      "learning_rate": 0.00019995687283209658,
      "loss": 0.1902,
      "step": 250
    },
    {
      "epoch": 0.0859822824387702,
      "grad_norm": 0.114593505859375,
      "learning_rate": 0.00019991168826367011,
      "loss": 0.1478,
      "step": 275
    },
    {
      "epoch": 0.09379885356956748,
      "grad_norm": 0.16413745284080505,
      "learning_rate": 0.00019985049165467257,
      "loss": 0.1579,
      "step": 300
    },
    {
      "epoch": 0.10161542470036478,
      "grad_norm": 0.1298794448375702,
      "learning_rate": 0.00019977329281259108,
      "loss": 0.1304,
      "step": 325
    },
    {
      "epoch": 0.10943199583116206,
      "grad_norm": 0.23028533160686493,
      "learning_rate": 0.00019968010410946154,
      "loss": 0.1668,
      "step": 350
    },
    {
      "epoch": 0.11724856696195936,
      "grad_norm": 0.1291658729314804,
      "learning_rate": 0.00019957094047988582,
      "loss": 0.1287,
      "step": 375
    },
    {
      "epoch": 0.12506513809275666,
      "grad_norm": 0.21002337336540222,
      "learning_rate": 0.00019944581941863857,
      "loss": 0.1407,
      "step": 400
    },
    {
      "epoch": 0.13288170922355394,
      "grad_norm": 0.1347612887620926,
      "learning_rate": 0.00019930476097786327,
      "loss": 0.1215,
      "step": 425
    },
    {
      "epoch": 0.14069828035435122,
      "grad_norm": 0.3085630238056183,
      "learning_rate": 0.0001991477877638587,
      "loss": 0.1548,
      "step": 450
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 0.15279293060302734,
      "learning_rate": 0.00019897492493345598,
      "loss": 0.1316,
      "step": 475
    },
    {
      "epoch": 0.1563314226159458,
      "grad_norm": 0.12289269268512726,
      "learning_rate": 0.00019878620018998696,
      "loss": 0.1344,
      "step": 500
    },
    {
      "epoch": 0.1641479937467431,
      "grad_norm": 0.12440578639507294,
      "learning_rate": 0.00019858164377884436,
      "loss": 0.1158,
      "step": 525
    },
    {
      "epoch": 0.1719645648775404,
      "grad_norm": 0.13387973606586456,
      "learning_rate": 0.00019836128848263465,
      "loss": 0.1374,
      "step": 550
    },
    {
      "epoch": 0.17978113600833767,
      "grad_norm": 0.09615334868431091,
      "learning_rate": 0.0001981251696159241,
      "loss": 0.1059,
      "step": 575
    },
    {
      "epoch": 0.18759770713913496,
      "grad_norm": 0.15349221229553223,
      "learning_rate": 0.00019787332501957941,
      "loss": 0.1334,
      "step": 600
    },
    {
      "epoch": 0.19541427826993227,
      "grad_norm": 0.13743956387043,
      "learning_rate": 0.0001976057950547031,
      "loss": 0.118,
      "step": 625
    },
    {
      "epoch": 0.20323084940072955,
      "grad_norm": 0.13537879288196564,
      "learning_rate": 0.00019732262259616523,
      "loss": 0.1417,
      "step": 650
    },
    {
      "epoch": 0.21104742053152684,
      "grad_norm": 0.1496138572692871,
      "learning_rate": 0.0001970238530257322,
      "loss": 0.103,
      "step": 675
    },
    {
      "epoch": 0.21886399166232412,
      "grad_norm": 0.1049102246761322,
      "learning_rate": 0.00019670953422479368,
      "loss": 0.107,
      "step": 700
    },
    {
      "epoch": 0.2266805627931214,
      "grad_norm": 0.10400135070085526,
      "learning_rate": 0.00019637971656668918,
      "loss": 0.0909,
      "step": 725
    },
    {
      "epoch": 0.23449713392391872,
      "grad_norm": 0.22638899087905884,
      "learning_rate": 0.0001960344529086351,
      "loss": 0.1247,
      "step": 750
    },
    {
      "epoch": 0.242313705054716,
      "grad_norm": 0.12680000066757202,
      "learning_rate": 0.00019567379858325356,
      "loss": 0.1132,
      "step": 775
    },
    {
      "epoch": 0.2501302761855133,
      "grad_norm": 0.21582889556884766,
      "learning_rate": 0.000195297811389705,
      "loss": 0.113,
      "step": 800
    },
    {
      "epoch": 0.25794684731631057,
      "grad_norm": 0.11152087152004242,
      "learning_rate": 0.00019490655158442484,
      "loss": 0.1005,
      "step": 825
    },
    {
      "epoch": 0.2657634184471079,
      "grad_norm": 0.115557000041008,
      "learning_rate": 0.00019450008187146684,
      "loss": 0.1161,
      "step": 850
    },
    {
      "epoch": 0.27357998957790514,
      "grad_norm": 0.12924060225486755,
      "learning_rate": 0.00019407846739245415,
      "loss": 0.1023,
      "step": 875
    },
    {
      "epoch": 0.28139656070870245,
      "grad_norm": 0.1220051571726799,
      "learning_rate": 0.00019364177571613926,
      "loss": 0.1145,
      "step": 900
    },
    {
      "epoch": 0.28921313183949976,
      "grad_norm": 0.1157776266336441,
      "learning_rate": 0.00019319007682757556,
      "loss": 0.099,
      "step": 925
    },
    {
      "epoch": 0.297029702970297,
      "grad_norm": 0.15037314593791962,
      "learning_rate": 0.0001927234431169014,
      "loss": 0.0953,
      "step": 950
    },
    {
      "epoch": 0.30484627410109433,
      "grad_norm": 0.11677601933479309,
      "learning_rate": 0.00019224194936773853,
      "loss": 0.0785,
      "step": 975
    },
    {
      "epoch": 0.3126628452318916,
      "grad_norm": 0.1857115626335144,
      "learning_rate": 0.00019174567274520728,
      "loss": 0.0964,
      "step": 1000
    },
    {
      "epoch": 0.3204794163626889,
      "grad_norm": 0.13954727351665497,
      "learning_rate": 0.00019123469278355985,
      "loss": 0.0766,
      "step": 1025
    },
    {
      "epoch": 0.3282959874934862,
      "grad_norm": 0.19866567850112915,
      "learning_rate": 0.00019070909137343408,
      "loss": 0.0948,
      "step": 1050
    },
    {
      "epoch": 0.33611255862428346,
      "grad_norm": 0.12323533743619919,
      "learning_rate": 0.0001901689527487294,
      "loss": 0.0758,
      "step": 1075
    },
    {
      "epoch": 0.3439291297550808,
      "grad_norm": 0.1211128756403923,
      "learning_rate": 0.0001896143634731074,
      "loss": 0.0931,
      "step": 1100
    },
    {
      "epoch": 0.3517457008858781,
      "grad_norm": 0.10732097178697586,
      "learning_rate": 0.00018904541242611902,
      "loss": 0.0843,
      "step": 1125
    },
    {
      "epoch": 0.35956227201667534,
      "grad_norm": 0.18020175397396088,
      "learning_rate": 0.00018846219078896037,
      "loss": 0.1081,
      "step": 1150
    },
    {
      "epoch": 0.36737884314747266,
      "grad_norm": 0.1062532439827919,
      "learning_rate": 0.00018786479202986006,
      "loss": 0.0859,
      "step": 1175
    },
    {
      "epoch": 0.3751954142782699,
      "grad_norm": 0.15130512416362762,
      "learning_rate": 0.0001872533118890997,
      "loss": 0.0994,
      "step": 1200
    },
    {
      "epoch": 0.3830119854090672,
      "grad_norm": 0.11984367668628693,
      "learning_rate": 0.00018662784836367028,
      "loss": 0.0788,
      "step": 1225
    },
    {
      "epoch": 0.39082855653986454,
      "grad_norm": 0.12687352299690247,
      "learning_rate": 0.00018598850169156722,
      "loss": 0.0906,
      "step": 1250
    },
    {
      "epoch": 0.3986451276706618,
      "grad_norm": 0.11364774405956268,
      "learning_rate": 0.00018533537433572581,
      "loss": 0.0824,
      "step": 1275
    },
    {
      "epoch": 0.4064616988014591,
      "grad_norm": 0.18850114941596985,
      "learning_rate": 0.00018466857096760046,
      "loss": 0.0883,
      "step": 1300
    },
    {
      "epoch": 0.41427826993225636,
      "grad_norm": 0.08917820453643799,
      "learning_rate": 0.00018398819845038972,
      "loss": 0.0786,
      "step": 1325
    },
    {
      "epoch": 0.42209484106305367,
      "grad_norm": 0.2518673837184906,
      "learning_rate": 0.0001832943658219103,
      "loss": 0.0954,
      "step": 1350
    },
    {
      "epoch": 0.429911412193851,
      "grad_norm": 0.11351489275693893,
      "learning_rate": 0.00018258718427712238,
      "loss": 0.0752,
      "step": 1375
    },
    {
      "epoch": 0.43772798332464824,
      "grad_norm": 0.18976137042045593,
      "learning_rate": 0.00018186676715030924,
      "loss": 0.0878,
      "step": 1400
    },
    {
      "epoch": 0.44554455445544555,
      "grad_norm": 0.08672059327363968,
      "learning_rate": 0.0001811332298969142,
      "loss": 0.0777,
      "step": 1425
    },
    {
      "epoch": 0.4533611255862428,
      "grad_norm": 0.17647337913513184,
      "learning_rate": 0.0001803866900750376,
      "loss": 0.1,
      "step": 1450
    },
    {
      "epoch": 0.4611776967170401,
      "grad_norm": 0.10212672501802444,
      "learning_rate": 0.0001796272673265963,
      "loss": 0.0729,
      "step": 1475
    },
    {
      "epoch": 0.46899426784783743,
      "grad_norm": 0.12904827296733856,
      "learning_rate": 0.00017885508335815014,
      "loss": 0.0809,
      "step": 1500
    },
    {
      "epoch": 0.4768108389786347,
      "grad_norm": 0.09842263162136078,
      "learning_rate": 0.0001780702619213967,
      "loss": 0.071,
      "step": 1525
    },
    {
      "epoch": 0.484627410109432,
      "grad_norm": 0.44641193747520447,
      "learning_rate": 0.0001772729287933387,
      "loss": 0.0849,
      "step": 1550
    },
    {
      "epoch": 0.4924439812402293,
      "grad_norm": 0.11430712789297104,
      "learning_rate": 0.00017646321175612668,
      "loss": 0.0724,
      "step": 1575
    },
    {
      "epoch": 0.5002605523710266,
      "grad_norm": 0.18171948194503784,
      "learning_rate": 0.00017564124057658056,
      "loss": 0.0897,
      "step": 1600
    },
    {
      "epoch": 0.5080771235018239,
      "grad_norm": 0.11830407381057739,
      "learning_rate": 0.00017480714698539266,
      "loss": 0.067,
      "step": 1625
    },
    {
      "epoch": 0.5158936946326211,
      "grad_norm": 0.13029517233371735,
      "learning_rate": 0.00017396106465601663,
      "loss": 0.0766,
      "step": 1650
    },
    {
      "epoch": 0.5237102657634184,
      "grad_norm": 0.0899861752986908,
      "learning_rate": 0.0001731031291832444,
      "loss": 0.0742,
      "step": 1675
    },
    {
      "epoch": 0.5315268368942158,
      "grad_norm": 0.12723049521446228,
      "learning_rate": 0.0001722334780614756,
      "loss": 0.0824,
      "step": 1700
    },
    {
      "epoch": 0.539343408025013,
      "grad_norm": 0.10397988557815552,
      "learning_rate": 0.00017135225066268255,
      "loss": 0.0736,
      "step": 1725
    },
    {
      "epoch": 0.5471599791558103,
      "grad_norm": 0.2177278697490692,
      "learning_rate": 0.00017045958821407405,
      "loss": 0.0823,
      "step": 1750
    },
    {
      "epoch": 0.5549765502866076,
      "grad_norm": 0.09467151015996933,
      "learning_rate": 0.00016955563377546207,
      "loss": 0.0715,
      "step": 1775
    },
    {
      "epoch": 0.5627931214174049,
      "grad_norm": 0.20167994499206543,
      "learning_rate": 0.0001686405322163349,
      "loss": 0.0812,
      "step": 1800
    },
    {
      "epoch": 0.5706096925482022,
      "grad_norm": 0.12881746888160706,
      "learning_rate": 0.00016771443019263983,
      "loss": 0.0665,
      "step": 1825
    },
    {
      "epoch": 0.5784262636789995,
      "grad_norm": 0.18849557638168335,
      "learning_rate": 0.00016677747612327997,
      "loss": 0.0745,
      "step": 1850
    },
    {
      "epoch": 0.5862428348097968,
      "grad_norm": 0.11694695800542831,
      "learning_rate": 0.00016582982016632818,
      "loss": 0.067,
      "step": 1875
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 0.10969908535480499,
      "learning_rate": 0.00016487161419496263,
      "loss": 0.0692,
      "step": 1900
    },
    {
      "epoch": 0.6018759770713914,
      "grad_norm": 0.1440378725528717,
      "learning_rate": 0.00016390301177312722,
      "loss": 0.0586,
      "step": 1925
    },
    {
      "epoch": 0.6096925482021887,
      "grad_norm": 0.18102584779262543,
      "learning_rate": 0.00016292416813092105,
      "loss": 0.0819,
      "step": 1950
    },
    {
      "epoch": 0.6175091193329859,
      "grad_norm": 0.10760992020368576,
      "learning_rate": 0.00016193524013972114,
      "loss": 0.0666,
      "step": 1975
    },
    {
      "epoch": 0.6253256904637832,
      "grad_norm": 0.18939076364040375,
      "learning_rate": 0.00016093638628704167,
      "loss": 0.0836,
      "step": 2000
    },
    {
      "epoch": 0.6331422615945805,
      "grad_norm": 0.080052949488163,
      "learning_rate": 0.0001599277666511347,
      "loss": 0.0521,
      "step": 2025
    },
    {
      "epoch": 0.6409588327253778,
      "grad_norm": 0.22862310707569122,
      "learning_rate": 0.00015890954287533555,
      "loss": 0.0776,
      "step": 2050
    },
    {
      "epoch": 0.648775403856175,
      "grad_norm": 0.1328810453414917,
      "learning_rate": 0.00015788187814215764,
      "loss": 0.0585,
      "step": 2075
    },
    {
      "epoch": 0.6565919749869724,
      "grad_norm": 0.1510317474603653,
      "learning_rate": 0.00015684493714714047,
      "loss": 0.0781,
      "step": 2100
    },
    {
      "epoch": 0.6644085461177697,
      "grad_norm": 0.1198466494679451,
      "learning_rate": 0.00015579888607245517,
      "loss": 0.0519,
      "step": 2125
    },
    {
      "epoch": 0.6722251172485669,
      "grad_norm": 0.20313912630081177,
      "learning_rate": 0.000154743892560272,
      "loss": 0.0783,
      "step": 2150
    },
    {
      "epoch": 0.6800416883793643,
      "grad_norm": 0.11452645808458328,
      "learning_rate": 0.00015368012568589342,
      "loss": 0.0502,
      "step": 2175
    },
    {
      "epoch": 0.6878582595101616,
      "grad_norm": 0.14314495027065277,
      "learning_rate": 0.00015260775593065802,
      "loss": 0.0727,
      "step": 2200
    },
    {
      "epoch": 0.6956748306409588,
      "grad_norm": 0.06434272974729538,
      "learning_rate": 0.00015152695515461865,
      "loss": 0.057,
      "step": 2225
    },
    {
      "epoch": 0.7034914017717562,
      "grad_norm": 0.1614643782377243,
      "learning_rate": 0.00015043789656899988,
      "loss": 0.071,
      "step": 2250
    },
    {
      "epoch": 0.7113079729025534,
      "grad_norm": 0.13058045506477356,
      "learning_rate": 0.00014934075470843887,
      "loss": 0.0486,
      "step": 2275
    },
    {
      "epoch": 0.7191245440333507,
      "grad_norm": 0.18131287395954132,
      "learning_rate": 0.00014823570540301408,
      "loss": 0.0719,
      "step": 2300
    },
    {
      "epoch": 0.7269411151641479,
      "grad_norm": 0.0917607769370079,
      "learning_rate": 0.00014712292575006633,
      "loss": 0.0547,
      "step": 2325
    },
    {
      "epoch": 0.7347576862949453,
      "grad_norm": 0.18416103720664978,
      "learning_rate": 0.00014600259408581687,
      "loss": 0.0851,
      "step": 2350
    },
    {
      "epoch": 0.7425742574257426,
      "grad_norm": 0.1413326859474182,
      "learning_rate": 0.00014487488995678708,
      "loss": 0.0515,
      "step": 2375
    },
    {
      "epoch": 0.7503908285565398,
      "grad_norm": 0.13125142455101013,
      "learning_rate": 0.00014373999409102362,
      "loss": 0.0572,
      "step": 2400
    },
    {
      "epoch": 0.7582073996873372,
      "grad_norm": 0.09877472370862961,
      "learning_rate": 0.00014259808836913492,
      "loss": 0.0553,
      "step": 2425
    },
    {
      "epoch": 0.7660239708181344,
      "grad_norm": 0.1793230026960373,
      "learning_rate": 0.00014144935579514246,
      "loss": 0.081,
      "step": 2450
    },
    {
      "epoch": 0.7738405419489317,
      "grad_norm": 0.12175089120864868,
      "learning_rate": 0.00014029398046715223,
      "loss": 0.0512,
      "step": 2475
    },
    {
      "epoch": 0.7816571130797291,
      "grad_norm": 0.13215778768062592,
      "learning_rate": 0.00013913214754785095,
      "loss": 0.0558,
      "step": 2500
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.09808023273944855,
      "learning_rate": 0.00013796404323483132,
      "loss": 0.0535,
      "step": 2525
    },
    {
      "epoch": 0.7972902553413236,
      "grad_norm": 0.1036866307258606,
      "learning_rate": 0.00013678985473075176,
      "loss": 0.0545,
      "step": 2550
    },
    {
      "epoch": 0.805106826472121,
      "grad_norm": 0.08988085389137268,
      "learning_rate": 0.00013560977021333497,
      "loss": 0.0505,
      "step": 2575
    },
    {
      "epoch": 0.8129233976029182,
      "grad_norm": 0.19154533743858337,
      "learning_rate": 0.00013442397880521008,
      "loss": 0.0761,
      "step": 2600
    },
    {
      "epoch": 0.8207399687337155,
      "grad_norm": 0.12072727084159851,
      "learning_rate": 0.0001332326705436037,
      "loss": 0.0569,
      "step": 2625
    },
    {
      "epoch": 0.8285565398645127,
      "grad_norm": 0.14147798717021942,
      "learning_rate": 0.00013203603634988386,
      "loss": 0.0628,
      "step": 2650
    },
    {
      "epoch": 0.8363731109953101,
      "grad_norm": 0.12975828349590302,
      "learning_rate": 0.000130834267998963,
      "loss": 0.0558,
      "step": 2675
    },
    {
      "epoch": 0.8441896821261073,
      "grad_norm": 0.19969676434993744,
      "learning_rate": 0.00012962755808856342,
      "loss": 0.0596,
      "step": 2700
    },
    {
      "epoch": 0.8520062532569046,
      "grad_norm": 0.08512550592422485,
      "learning_rate": 0.00012841610000835125,
      "loss": 0.0451,
      "step": 2725
    },
    {
      "epoch": 0.859822824387702,
      "grad_norm": 0.1487194150686264,
      "learning_rate": 0.00012720008790894366,
      "loss": 0.066,
      "step": 2750
    },
    {
      "epoch": 0.8676393955184992,
      "grad_norm": 0.11497163027524948,
      "learning_rate": 0.00012597971667079361,
      "loss": 0.0397,
      "step": 2775
    },
    {
      "epoch": 0.8754559666492965,
      "grad_norm": 0.1517353653907776,
      "learning_rate": 0.0001247551818729582,
      "loss": 0.067,
      "step": 2800
    },
    {
      "epoch": 0.8832725377800938,
      "grad_norm": 0.10019470006227493,
      "learning_rate": 0.0001235266797617545,
      "loss": 0.0441,
      "step": 2825
    },
    {
      "epoch": 0.8910891089108911,
      "grad_norm": 0.11631037294864655,
      "learning_rate": 0.00012229440721930906,
      "loss": 0.0578,
      "step": 2850
    },
    {
      "epoch": 0.8989056800416884,
      "grad_norm": 0.13269539177417755,
      "learning_rate": 0.00012105856173200498,
      "loss": 0.0458,
      "step": 2875
    },
    {
      "epoch": 0.9067222511724856,
      "grad_norm": 0.14545674622058868,
      "learning_rate": 0.00011981934135883237,
      "loss": 0.0606,
      "step": 2900
    },
    {
      "epoch": 0.914538822303283,
      "grad_norm": 0.1214185357093811,
      "learning_rate": 0.00011857694469964715,
      "loss": 0.0549,
      "step": 2925
    },
    {
      "epoch": 0.9223553934340802,
      "grad_norm": 0.16503901779651642,
      "learning_rate": 0.00011733157086334294,
      "loss": 0.0578,
      "step": 2950
    },
    {
      "epoch": 0.9301719645648775,
      "grad_norm": 0.11620346456766129,
      "learning_rate": 0.0001160834194359416,
      "loss": 0.0465,
      "step": 2975
    },
    {
      "epoch": 0.9379885356956749,
      "grad_norm": 0.16109348833560944,
      "learning_rate": 0.00011483269044860705,
      "loss": 0.0766,
      "step": 3000
    },
    {
      "epoch": 0.9458051068264721,
      "grad_norm": 0.12791192531585693,
      "learning_rate": 0.000113579584345588,
      "loss": 0.044,
      "step": 3025
    },
    {
      "epoch": 0.9536216779572694,
      "grad_norm": 0.12485138326883316,
      "learning_rate": 0.0001123243019520942,
      "loss": 0.0675,
      "step": 3050
    },
    {
      "epoch": 0.9614382490880667,
      "grad_norm": 0.14500558376312256,
      "learning_rate": 0.00011106704444211207,
      "loss": 0.0448,
      "step": 3075
    },
    {
      "epoch": 0.969254820218864,
      "grad_norm": 0.14029914140701294,
      "learning_rate": 0.000109808013306164,
      "loss": 0.0523,
      "step": 3100
    },
    {
      "epoch": 0.9770713913496613,
      "grad_norm": 0.12966245412826538,
      "learning_rate": 0.00010854741031901703,
      "loss": 0.0437,
      "step": 3125
    },
    {
      "epoch": 0.9848879624804586,
      "grad_norm": 0.17107540369033813,
      "learning_rate": 0.00010728543750734622,
      "loss": 0.0751,
      "step": 3150
    },
    {
      "epoch": 0.9927045336112559,
      "grad_norm": 0.09135702252388,
      "learning_rate": 0.00010602229711735726,
      "loss": 0.0365,
      "step": 3175
    },
    {
      "epoch": 1.0005211047420532,
      "grad_norm": 0.08210639655590057,
      "learning_rate": 0.00010475819158237425,
      "loss": 0.0607,
      "step": 3200
    },
    {
      "epoch": 1.0083376758728504,
      "grad_norm": 0.11569935828447342,
      "learning_rate": 0.0001034933234903973,
      "loss": 0.0339,
      "step": 3225
    },
    {
      "epoch": 1.0161542470036478,
      "grad_norm": 0.14199353754520416,
      "learning_rate": 0.0001022278955516354,
      "loss": 0.0552,
      "step": 3250
    },
    {
      "epoch": 1.0239708181344451,
      "grad_norm": 0.05054362490773201,
      "learning_rate": 0.00010096211056601958,
      "loss": 0.046,
      "step": 3275
    },
    {
      "epoch": 1.0317873892652423,
      "grad_norm": 0.0896683856844902,
      "learning_rate": 9.969617139070202e-05,
      "loss": 0.0535,
      "step": 3300
    },
    {
      "epoch": 1.0396039603960396,
      "grad_norm": 0.12672972679138184,
      "learning_rate": 9.84302809075455e-05,
      "loss": 0.0371,
      "step": 3325
    },
    {
      "epoch": 1.047420531526837,
      "grad_norm": 0.0811162069439888,
      "learning_rate": 9.716464199060946e-05,
      "loss": 0.0542,
      "step": 3350
    },
    {
      "epoch": 1.0552371026576342,
      "grad_norm": 0.14638996124267578,
      "learning_rate": 9.589945747363667e-05,
      "loss": 0.0422,
      "step": 3375
    },
    {
      "epoch": 1.0630536737884315,
      "grad_norm": 0.10969869047403336,
      "learning_rate": 9.463493011754706e-05,
      "loss": 0.0551,
      "step": 3400
    },
    {
      "epoch": 1.0708702449192287,
      "grad_norm": 0.10893837362527847,
      "learning_rate": 9.337126257794255e-05,
      "loss": 0.0313,
      "step": 3425
    },
    {
      "epoch": 1.078686816050026,
      "grad_norm": 0.11091223359107971,
      "learning_rate": 9.210865737262924e-05,
      "loss": 0.0406,
      "step": 3450
    },
    {
      "epoch": 1.0865033871808234,
      "grad_norm": 0.07989752292633057,
      "learning_rate": 9.084731684916151e-05,
      "loss": 0.0403,
      "step": 3475
    },
    {
      "epoch": 1.0943199583116205,
      "grad_norm": 0.04963237792253494,
      "learning_rate": 8.958744315241341e-05,
      "loss": 0.0476,
      "step": 3500
    }
  ],
  "logging_steps": 25,
  "max_steps": 6396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.123264931117384e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
