{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6253256904637832,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007816571130797291,
      "grad_norm": 0.16461588442325592,
      "learning_rate": 2.604166666666667e-05,
      "loss": 1.3284,
      "step": 25
    },
    {
      "epoch": 0.015633142261594582,
      "grad_norm": 0.237275630235672,
      "learning_rate": 5.208333333333334e-05,
      "loss": 1.2095,
      "step": 50
    },
    {
      "epoch": 0.02344971339239187,
      "grad_norm": 0.2465115338563919,
      "learning_rate": 7.8125e-05,
      "loss": 0.7133,
      "step": 75
    },
    {
      "epoch": 0.031266284523189164,
      "grad_norm": 0.5179443955421448,
      "learning_rate": 0.00010416666666666667,
      "loss": 0.3775,
      "step": 100
    },
    {
      "epoch": 0.03908285565398645,
      "grad_norm": 0.16486196219921112,
      "learning_rate": 0.00013020833333333333,
      "loss": 0.2465,
      "step": 125
    },
    {
      "epoch": 0.04689942678478374,
      "grad_norm": 0.3671402931213379,
      "learning_rate": 0.00015625,
      "loss": 0.2246,
      "step": 150
    },
    {
      "epoch": 0.05471599791558103,
      "grad_norm": 0.29935628175735474,
      "learning_rate": 0.00018229166666666667,
      "loss": 0.1762,
      "step": 175
    },
    {
      "epoch": 0.06253256904637833,
      "grad_norm": 0.2401837855577469,
      "learning_rate": 0.00019999917944905216,
      "loss": 0.2089,
      "step": 200
    },
    {
      "epoch": 0.07034914017717561,
      "grad_norm": 0.12683165073394775,
      "learning_rate": 0.00019998603811858571,
      "loss": 0.165,
      "step": 225
    },
    {
      "epoch": 0.0781657113079729,
      "grad_norm": 0.18932399153709412,
      "learning_rate": 0.00019995687283209658,
      "loss": 0.1902,
      "step": 250
    },
    {
      "epoch": 0.0859822824387702,
      "grad_norm": 0.114593505859375,
      "learning_rate": 0.00019991168826367011,
      "loss": 0.1478,
      "step": 275
    },
    {
      "epoch": 0.09379885356956748,
      "grad_norm": 0.16413745284080505,
      "learning_rate": 0.00019985049165467257,
      "loss": 0.1579,
      "step": 300
    },
    {
      "epoch": 0.10161542470036478,
      "grad_norm": 0.1298794448375702,
      "learning_rate": 0.00019977329281259108,
      "loss": 0.1304,
      "step": 325
    },
    {
      "epoch": 0.10943199583116206,
      "grad_norm": 0.23028533160686493,
      "learning_rate": 0.00019968010410946154,
      "loss": 0.1668,
      "step": 350
    },
    {
      "epoch": 0.11724856696195936,
      "grad_norm": 0.1291658729314804,
      "learning_rate": 0.00019957094047988582,
      "loss": 0.1287,
      "step": 375
    },
    {
      "epoch": 0.12506513809275666,
      "grad_norm": 0.21002337336540222,
      "learning_rate": 0.00019944581941863857,
      "loss": 0.1407,
      "step": 400
    },
    {
      "epoch": 0.13288170922355394,
      "grad_norm": 0.1347612887620926,
      "learning_rate": 0.00019930476097786327,
      "loss": 0.1215,
      "step": 425
    },
    {
      "epoch": 0.14069828035435122,
      "grad_norm": 0.3085630238056183,
      "learning_rate": 0.0001991477877638587,
      "loss": 0.1548,
      "step": 450
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 0.15279293060302734,
      "learning_rate": 0.00019897492493345598,
      "loss": 0.1316,
      "step": 475
    },
    {
      "epoch": 0.1563314226159458,
      "grad_norm": 0.12289269268512726,
      "learning_rate": 0.00019878620018998696,
      "loss": 0.1344,
      "step": 500
    },
    {
      "epoch": 0.1641479937467431,
      "grad_norm": 0.12440578639507294,
      "learning_rate": 0.00019858164377884436,
      "loss": 0.1158,
      "step": 525
    },
    {
      "epoch": 0.1719645648775404,
      "grad_norm": 0.13387973606586456,
      "learning_rate": 0.00019836128848263465,
      "loss": 0.1374,
      "step": 550
    },
    {
      "epoch": 0.17978113600833767,
      "grad_norm": 0.09615334868431091,
      "learning_rate": 0.0001981251696159241,
      "loss": 0.1059,
      "step": 575
    },
    {
      "epoch": 0.18759770713913496,
      "grad_norm": 0.15349221229553223,
      "learning_rate": 0.00019787332501957941,
      "loss": 0.1334,
      "step": 600
    },
    {
      "epoch": 0.19541427826993227,
      "grad_norm": 0.13743956387043,
      "learning_rate": 0.0001976057950547031,
      "loss": 0.118,
      "step": 625
    },
    {
      "epoch": 0.20323084940072955,
      "grad_norm": 0.13537879288196564,
      "learning_rate": 0.00019732262259616523,
      "loss": 0.1417,
      "step": 650
    },
    {
      "epoch": 0.21104742053152684,
      "grad_norm": 0.1496138572692871,
      "learning_rate": 0.0001970238530257322,
      "loss": 0.103,
      "step": 675
    },
    {
      "epoch": 0.21886399166232412,
      "grad_norm": 0.1049102246761322,
      "learning_rate": 0.00019670953422479368,
      "loss": 0.107,
      "step": 700
    },
    {
      "epoch": 0.2266805627931214,
      "grad_norm": 0.10400135070085526,
      "learning_rate": 0.00019637971656668918,
      "loss": 0.0909,
      "step": 725
    },
    {
      "epoch": 0.23449713392391872,
      "grad_norm": 0.22638899087905884,
      "learning_rate": 0.0001960344529086351,
      "loss": 0.1247,
      "step": 750
    },
    {
      "epoch": 0.242313705054716,
      "grad_norm": 0.12680000066757202,
      "learning_rate": 0.00019567379858325356,
      "loss": 0.1132,
      "step": 775
    },
    {
      "epoch": 0.2501302761855133,
      "grad_norm": 0.21582889556884766,
      "learning_rate": 0.000195297811389705,
      "loss": 0.113,
      "step": 800
    },
    {
      "epoch": 0.25794684731631057,
      "grad_norm": 0.11152087152004242,
      "learning_rate": 0.00019490655158442484,
      "loss": 0.1005,
      "step": 825
    },
    {
      "epoch": 0.2657634184471079,
      "grad_norm": 0.115557000041008,
      "learning_rate": 0.00019450008187146684,
      "loss": 0.1161,
      "step": 850
    },
    {
      "epoch": 0.27357998957790514,
      "grad_norm": 0.12924060225486755,
      "learning_rate": 0.00019407846739245415,
      "loss": 0.1023,
      "step": 875
    },
    {
      "epoch": 0.28139656070870245,
      "grad_norm": 0.1220051571726799,
      "learning_rate": 0.00019364177571613926,
      "loss": 0.1145,
      "step": 900
    },
    {
      "epoch": 0.28921313183949976,
      "grad_norm": 0.1157776266336441,
      "learning_rate": 0.00019319007682757556,
      "loss": 0.099,
      "step": 925
    },
    {
      "epoch": 0.297029702970297,
      "grad_norm": 0.15037314593791962,
      "learning_rate": 0.0001927234431169014,
      "loss": 0.0953,
      "step": 950
    },
    {
      "epoch": 0.30484627410109433,
      "grad_norm": 0.11677601933479309,
      "learning_rate": 0.00019224194936773853,
      "loss": 0.0785,
      "step": 975
    },
    {
      "epoch": 0.3126628452318916,
      "grad_norm": 0.1857115626335144,
      "learning_rate": 0.00019174567274520728,
      "loss": 0.0964,
      "step": 1000
    },
    {
      "epoch": 0.3204794163626889,
      "grad_norm": 0.13954727351665497,
      "learning_rate": 0.00019123469278355985,
      "loss": 0.0766,
      "step": 1025
    },
    {
      "epoch": 0.3282959874934862,
      "grad_norm": 0.19866567850112915,
      "learning_rate": 0.00019070909137343408,
      "loss": 0.0948,
      "step": 1050
    },
    {
      "epoch": 0.33611255862428346,
      "grad_norm": 0.12323533743619919,
      "learning_rate": 0.0001901689527487294,
      "loss": 0.0758,
      "step": 1075
    },
    {
      "epoch": 0.3439291297550808,
      "grad_norm": 0.1211128756403923,
      "learning_rate": 0.0001896143634731074,
      "loss": 0.0931,
      "step": 1100
    },
    {
      "epoch": 0.3517457008858781,
      "grad_norm": 0.10732097178697586,
      "learning_rate": 0.00018904541242611902,
      "loss": 0.0843,
      "step": 1125
    },
    {
      "epoch": 0.35956227201667534,
      "grad_norm": 0.18020175397396088,
      "learning_rate": 0.00018846219078896037,
      "loss": 0.1081,
      "step": 1150
    },
    {
      "epoch": 0.36737884314747266,
      "grad_norm": 0.1062532439827919,
      "learning_rate": 0.00018786479202986006,
      "loss": 0.0859,
      "step": 1175
    },
    {
      "epoch": 0.3751954142782699,
      "grad_norm": 0.15130512416362762,
      "learning_rate": 0.0001872533118890997,
      "loss": 0.0994,
      "step": 1200
    },
    {
      "epoch": 0.3830119854090672,
      "grad_norm": 0.11984367668628693,
      "learning_rate": 0.00018662784836367028,
      "loss": 0.0788,
      "step": 1225
    },
    {
      "epoch": 0.39082855653986454,
      "grad_norm": 0.12687352299690247,
      "learning_rate": 0.00018598850169156722,
      "loss": 0.0906,
      "step": 1250
    },
    {
      "epoch": 0.3986451276706618,
      "grad_norm": 0.11364774405956268,
      "learning_rate": 0.00018533537433572581,
      "loss": 0.0824,
      "step": 1275
    },
    {
      "epoch": 0.4064616988014591,
      "grad_norm": 0.18850114941596985,
      "learning_rate": 0.00018466857096760046,
      "loss": 0.0883,
      "step": 1300
    },
    {
      "epoch": 0.41427826993225636,
      "grad_norm": 0.08917820453643799,
      "learning_rate": 0.00018398819845038972,
      "loss": 0.0786,
      "step": 1325
    },
    {
      "epoch": 0.42209484106305367,
      "grad_norm": 0.2518673837184906,
      "learning_rate": 0.0001832943658219103,
      "loss": 0.0954,
      "step": 1350
    },
    {
      "epoch": 0.429911412193851,
      "grad_norm": 0.11351489275693893,
      "learning_rate": 0.00018258718427712238,
      "loss": 0.0752,
      "step": 1375
    },
    {
      "epoch": 0.43772798332464824,
      "grad_norm": 0.18976137042045593,
      "learning_rate": 0.00018186676715030924,
      "loss": 0.0878,
      "step": 1400
    },
    {
      "epoch": 0.44554455445544555,
      "grad_norm": 0.08672059327363968,
      "learning_rate": 0.0001811332298969142,
      "loss": 0.0777,
      "step": 1425
    },
    {
      "epoch": 0.4533611255862428,
      "grad_norm": 0.17647337913513184,
      "learning_rate": 0.0001803866900750376,
      "loss": 0.1,
      "step": 1450
    },
    {
      "epoch": 0.4611776967170401,
      "grad_norm": 0.10212672501802444,
      "learning_rate": 0.0001796272673265963,
      "loss": 0.0729,
      "step": 1475
    },
    {
      "epoch": 0.46899426784783743,
      "grad_norm": 0.12904827296733856,
      "learning_rate": 0.00017885508335815014,
      "loss": 0.0809,
      "step": 1500
    },
    {
      "epoch": 0.4768108389786347,
      "grad_norm": 0.09842263162136078,
      "learning_rate": 0.0001780702619213967,
      "loss": 0.071,
      "step": 1525
    },
    {
      "epoch": 0.484627410109432,
      "grad_norm": 0.44641193747520447,
      "learning_rate": 0.0001772729287933387,
      "loss": 0.0849,
      "step": 1550
    },
    {
      "epoch": 0.4924439812402293,
      "grad_norm": 0.11430712789297104,
      "learning_rate": 0.00017646321175612668,
      "loss": 0.0724,
      "step": 1575
    },
    {
      "epoch": 0.5002605523710266,
      "grad_norm": 0.18171948194503784,
      "learning_rate": 0.00017564124057658056,
      "loss": 0.0897,
      "step": 1600
    },
    {
      "epoch": 0.5080771235018239,
      "grad_norm": 0.11830407381057739,
      "learning_rate": 0.00017480714698539266,
      "loss": 0.067,
      "step": 1625
    },
    {
      "epoch": 0.5158936946326211,
      "grad_norm": 0.13029517233371735,
      "learning_rate": 0.00017396106465601663,
      "loss": 0.0766,
      "step": 1650
    },
    {
      "epoch": 0.5237102657634184,
      "grad_norm": 0.0899861752986908,
      "learning_rate": 0.0001731031291832444,
      "loss": 0.0742,
      "step": 1675
    },
    {
      "epoch": 0.5315268368942158,
      "grad_norm": 0.12723049521446228,
      "learning_rate": 0.0001722334780614756,
      "loss": 0.0824,
      "step": 1700
    },
    {
      "epoch": 0.539343408025013,
      "grad_norm": 0.10397988557815552,
      "learning_rate": 0.00017135225066268255,
      "loss": 0.0736,
      "step": 1725
    },
    {
      "epoch": 0.5471599791558103,
      "grad_norm": 0.2177278697490692,
      "learning_rate": 0.00017045958821407405,
      "loss": 0.0823,
      "step": 1750
    },
    {
      "epoch": 0.5549765502866076,
      "grad_norm": 0.09467151015996933,
      "learning_rate": 0.00016955563377546207,
      "loss": 0.0715,
      "step": 1775
    },
    {
      "epoch": 0.5627931214174049,
      "grad_norm": 0.20167994499206543,
      "learning_rate": 0.0001686405322163349,
      "loss": 0.0812,
      "step": 1800
    },
    {
      "epoch": 0.5706096925482022,
      "grad_norm": 0.12881746888160706,
      "learning_rate": 0.00016771443019263983,
      "loss": 0.0665,
      "step": 1825
    },
    {
      "epoch": 0.5784262636789995,
      "grad_norm": 0.18849557638168335,
      "learning_rate": 0.00016677747612327997,
      "loss": 0.0745,
      "step": 1850
    },
    {
      "epoch": 0.5862428348097968,
      "grad_norm": 0.11694695800542831,
      "learning_rate": 0.00016582982016632818,
      "loss": 0.067,
      "step": 1875
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 0.10969908535480499,
      "learning_rate": 0.00016487161419496263,
      "loss": 0.0692,
      "step": 1900
    },
    {
      "epoch": 0.6018759770713914,
      "grad_norm": 0.1440378725528717,
      "learning_rate": 0.00016390301177312722,
      "loss": 0.0586,
      "step": 1925
    },
    {
      "epoch": 0.6096925482021887,
      "grad_norm": 0.18102584779262543,
      "learning_rate": 0.00016292416813092105,
      "loss": 0.0819,
      "step": 1950
    },
    {
      "epoch": 0.6175091193329859,
      "grad_norm": 0.10760992020368576,
      "learning_rate": 0.00016193524013972114,
      "loss": 0.0666,
      "step": 1975
    },
    {
      "epoch": 0.6253256904637832,
      "grad_norm": 0.18939076364040375,
      "learning_rate": 0.00016093638628704167,
      "loss": 0.0836,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 6396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3575671527777894e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
