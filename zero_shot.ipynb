{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "API_KEY = []\n",
    "API_KEY.append(os.getenv(\"API_KEY2\"))\n",
    "API_KEY.append(os.getenv(\"API_KEY3\"))\n",
    "API_KEY.append(os.getenv(\"API_KEY4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"kokujin/prompts_1\"\n",
    "model_name = \"Gemini_1.5_Flash\"\n",
    "output_dir = f\"./results/{model_name}/\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "opt = model_name\n",
    "dic = {opt: []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "log_filename = f\"logs.txt\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Example log messages\n",
    "logging.info(\"Started processing the dataset.\")\n",
    "logging.info(f\"Dataset name: {dataset_name}\")\n",
    "logging.info(f\"Model name: {model_name}\")\n",
    "logging.info(\"Finished processing the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1299it [3:13:54,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1765it [4:24:12,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1766it [4:24:13,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2399it [5:58:59,  8.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "err_ = []\n",
    "start = time.time()\n",
    "opt_ = 0\n",
    "for i, prompt in tqdm(enumerate(test)):\n",
    "    if i%1000 == 0 and i != 0:\n",
    "        opt_ += 1\n",
    "        logging.info(f\"Switched to API key {opt_}\")\n",
    "    url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={API_KEY[opt_]}'\n",
    "    if i%10 == 0 and i != 0:\n",
    "        end = time.time()\n",
    "        time.sleep(90 - (end - start))\n",
    "        start = time.time()\n",
    "\n",
    "    tmp = {\n",
    "        \"Prompt\": \"\",\n",
    "        \"Original\": \"\",\n",
    "        \"Prediction\": \"\"\n",
    "    }\n",
    "    resp = prompt[\"Text\"].split('### Output: ')\n",
    "    prompt = resp[0]\n",
    "    payload = '{\"contents\": [{\"parts\":[{\"text\":\"' + prompt + '\"}]}]}'\n",
    "    #print(payload)\n",
    "\n",
    "    res = requests.post(url, data=payload, headers=headers)\n",
    "    logging.info(f\"Prompt: {res}\")\n",
    "    resp_ = json.loads(res.text)\n",
    "    if 'error' in resp_:\n",
    "        if resp_['error']['code'] == 429:\n",
    "            opt_ += 1\n",
    "            if opt_ == 3:\n",
    "                opt_ = 0\n",
    "            url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={API_KEY[opt_]}'\n",
    "            res = requests.post(url, data=pa    yload, headers=headers)\n",
    "            resp_ = json.loads(res.text)\n",
    "        else:\n",
    "            print(resp_)\n",
    "            err_.append(resp_)\n",
    "            continue\n",
    "    logging.info(f\"Prompt: {resp_}\")\n",
    "    #print(resp_['candidates'][0]['content']['parts'][0]['text'])\n",
    "    result = resp_['candidates'][0]['content']['parts'][0]['text']\n",
    "    tmp[\"Prompt\"] = prompt\n",
    "    tmp[\"Original\"] = resp[1]\n",
    "    tmp[\"Prediction\"] = result\n",
    "    dic[opt].append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Prompt\": [],\n",
    "    \"Original\": [],\n",
    "    \"Prediction\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(val):\n",
    "    val = val.replace(\"'\", '\"')\n",
    "    #    val = '\"' + val + '\"'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 606 (char 605)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m val \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(val)\n\u001b[1;32m---> 15\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(val, '\\n aca termina la review')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_p)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 606 (char 605)"
     ]
    }
   ],
   "source": [
    "\n",
    "ommited = []\n",
    "a = []\n",
    "for i, t in enumerate(dic[opt]):\n",
    "    try:\n",
    "        val_p = t[\"Prediction\"]\n",
    "\n",
    "        val_p = json.loads(\"}\".join(('{' + \"{\".join(val_p.split('{')[1:])).split('}')[:-1]) + '}')\n",
    "        \n",
    "        #print(val_p, '\\n aca termina la review')\n",
    "        #val_p = format(val_p)\n",
    "        #val_p = val_p + \"\\\"}\" if \"\\\"}\" not in val_p else val_p\n",
    "\n",
    "        val = t[\"Original\"]\n",
    "        val = format(val)\n",
    "        val = json.loads(val)\n",
    "        #print(val, '\\n aca termina la review')\n",
    "        results[\"Prediction\"].append(val_p)\n",
    "        results[\"Original\"].append(val)\n",
    "        results[\"Prompt\"].append(t[\"Prompt\"])\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        ommited.append(i)\n",
    "        #print(e)\n",
    "        a.append(t[\"Prediction\"])\n",
    "\n",
    "print(len(ommited), ommited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['```json\\n{\\n  \"Design and Display\": {\\n    \"Display Size\": \"5.5 inches (13.97 cm)\",\\n    \"Resolution\": \"1080 x 1920 pixels\",\\n    \"Pixel Density\": \"401ppi\",\\n    \"Display Type\": \"P-OLED\",\\n    \"Screen Protection\": \"Corning Gorilla Glass v3\",\\n    \"Dimensions\": \"149.1mm x 75.3mm x 7.1mm\",\\n    \"Weight\": \"152g\",\\n    \"Colour Options\": [\"Red\", \"Silver\"]\\n  },\\n  \"Battery and Connectivity\": {\\n    \"Battery Capacity\": \"3000 mAh\",\\n    \"Battery Type\": \"Li-Polymer\",\\n    \"Fast Charging\": \"Yes, Quick, v2.0\",\\n    \"Network\": [\"2G\", \"3G\"],\\n    \"SIM Card Type\": \"Micro\",\\n    \"Wi-Fi\": \"Wi-Fi 802.11, a/ac/b/g/n, Direct, Mobile Hotspot\",\\n    \"Bluetooth\": \"Bluetooth 4.1\",\\n    \"NFC\": \"Yes\",\\n    \"GPS\": \"Yes with A-GPS, Glonass\",\\n    \"FM Radio\": \"Yes\",\\n    \"3.5mm Headphone Jack\": \"Yes\",\\n    \"Charging Port\": \"microUSB 2.0\"\\n  }\\n}\\n```\\n', '```json\\n{\\n  \"Design and Display\": {\\n    \"Display Size\": \"6.78 inches (17.22 cm)\",\\n    \"Resolution\": \"1440 x 3200 pixels\",\\n    \"Pixel Density\": \"518ppi\",\\n    \"Display Type\": \"AMOLED, Curved Display, HDR 10+\",\\n    \"Refresh Rate\": \"120Hz\",\\n    \"Screen Protection\": \"Unspecified\",\\n    \"Design\": \"Punch-hole display\",\\n    \"Screen to Body Ratio\": \"92.2%\",\\n    \"Aspect Ratio\": \"20:9\",\\n    \"Color Options\": [\"Enigma Black\"]\\n  }\\n}\\n```\\n']\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2239\n"
     ]
    }
   ],
   "source": [
    "print(len(results['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Outputs/{model_name}/{model_name}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
